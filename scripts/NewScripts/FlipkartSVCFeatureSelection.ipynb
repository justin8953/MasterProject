{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os \n",
    "import json\n",
    "from math import ceil, floor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest,chi2\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder,scale\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  \n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 11})\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Conv1D, Dense, Embedding, Flatten, Input, Dropout, GlobalMaxPooling1D\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.callbacks import  EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;-]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "Number_RE = re.compile('[*^0-9]')\n",
    "Bad_underline = re.compile('[*_*]')\n",
    "RemoveTag = re.compile('&lt;|br&gt;|b&gt;|ul&gt;|li&gt;')\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = text.lower() # lowercase text\n",
    "    text = RemoveTag.sub('',text)\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = Number_RE.sub(' ', text) # replace Number symbols by space in text\n",
    "    text = Bad_underline.sub(' ', text) # replace Underline symbols by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
    "    return text\n",
    "RemoveLastSpace = re.compile(' $')\n",
    "\n",
    "def clean_text_category(text):\n",
    "    text = RemoveLastSpace.sub('',text)\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classNumberThreshold(arr):\n",
    "    dropCategory = []\n",
    "\n",
    "    for key,value in arr.items():\n",
    "        if(value<=30):\n",
    "            dropCategory.append(key)\n",
    "    return dropCategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../example/fliptkart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[pd.notnull(df['description'])]\n",
    "df.description = df.description.apply(clean_text)\n",
    "df = df[pd.notnull(df['category_main'])]\n",
    "df = df[pd.notnull(df['pid'])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropCategoryCode  = classNumberThreshold(df.category_main.value_counts())\n",
    "dropSubCategoryCode  = classNumberThreshold(df.category_sub1.value_counts())\n",
    "\n",
    "for i in dropCategoryCode:\n",
    "    df = df[df.category_main!=i]\n",
    "    \n",
    "for i in dropSubCategoryCode:\n",
    "    df = df[df.category_sub1!=i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(df.category_main)\n",
    "target = le.classes_\n",
    "labels = le.transform(df.category_main)\n",
    "\n",
    "le.fit(df.category_sub1)\n",
    "subtarget = le.classes_\n",
    "sublabels = le.transform(df.category_sub1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfconverter = TfidfVectorizer(min_df=5, max_df=0.7)\n",
    "X = tfidfconverter.fit_transform(df.description)\n",
    "featureNames = tfidfconverter.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train_info, y_test_info = train_test_split(X, pd.DataFrame({'index':df.index, 'label':labels}), \n",
    "                                                    test_size=0.1, random_state = 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train_info.label\n",
    "y_test = y_test_info.label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearSVC(random_state=42,class_weight=\"balanced\")\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BestSize  = [ele for ele in range(100, len(featureNames), 100) ]\n",
    "Models = []\n",
    "Scores = []\n",
    "SelectModels  = []\n",
    "for ele in range(100, len(featureNames), 100):\n",
    "    print(\"--- Best \"+ str(ele) + \" features \\n\")\n",
    "    selectBest = SelectKBest(chi2, k= ele)\n",
    "    model = LinearSVC(random_state=42,class_weight=\"balanced\")\n",
    "    K_best_linearsvc = Pipeline([('SelectBest', selectBest), ('linearSVC', model)])\n",
    "    K_best_linearsvc.fit(X_train,y_train)\n",
    "    score = K_best_linearsvc.score(X_test,y_test)\n",
    "    Models.append(K_best_linearsvc)\n",
    "    Scores.append(score)\n",
    "\n",
    "bestModel = Models[np.argmax(Scores)]\n",
    "bestSize = BestSize[np.argmax(Scores)]\n",
    "\n",
    "# save the model to disk\n",
    "filename = 'Flipkart/'+str(bestSize)+'BestLinearSVC.sav'\n",
    "joblib.dump(bestModel, filename)\n",
    "\n",
    "\n",
    "\n",
    "yConfidence = bestModel.decision_function(X_test)\n",
    "\n",
    "yPred = bestModel.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectBest = bestModel.get_params()['SelectBest']\n",
    "\n",
    "originScore = selectBest.scores_\n",
    "supportsList = selectBest.get_support()\n",
    "Max = ceil(max(originScore))\n",
    "Min = floor(min(originScore))\n",
    "Normscores = [round((ele-Min)/(Max-Min),2) for ele in originScore]\n",
    "scoreDict = dict(zip(featureNames,\n",
    "                     list(zip(supportsList, Normscores))))\n",
    "newScoreDict = {}\n",
    "\n",
    "for key , item in scoreDict.items():\n",
    "    if(item[0]):\n",
    "        newScoreDict[key] = item[1]\n",
    "\n",
    "ranksfeaturesDict = pd.DataFrame({\"Feature\":list(newScoreDict.keys()),\n",
    "                                  \"Score\":list(newScoreDict.values())},dtype=np.int64)\n",
    "ranksfeaturesDict = ranksfeaturesDict.sort_values(by=['Score'],ascending=False)\n",
    "ranksfeaturesDict.to_csv(\"Flipkart/RankByTotalFeature.csv\",index=False,compression=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BestModelsupportsList = bestModel.get_params()['SelectBest'].get_support()\n",
    "\n",
    "NewFeatureName = []\n",
    "index = 0\n",
    "for ele in BestModelsupportsList:\n",
    "    if(ele):\n",
    "        NewFeatureName.append(featureNames[index])\n",
    "    index = index+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classWithInfluence = {}\n",
    "\n",
    "coef = bestModel.get_params()['linearSVC'].coef_\n",
    "coef = scale(coef)\n",
    "\n",
    "coefTotalSize = coef.shape[0]*coef.shape[1]\n",
    "coef1DArr = coef.reshape(coefTotalSize,1)\n",
    "Max = ceil(max(coef1DArr[0]))\n",
    "Min = floor(min(coef1DArr[0]))\n",
    "\n",
    "for index in range(0,len(coef)):\n",
    "    normalisedCoef = [round((ele-Min)/(Max-Min),2) for ele in coef[index]]\n",
    "    name = list(NewFeatureName)\n",
    "    classWithInfluence[target[index]] = list(zip(name,normalisedCoef))\n",
    "            \n",
    "Top10InflunceFeature = {}\n",
    "for key, value in classWithInfluence.items():\n",
    "    Top10InflunceFeature[key] = sorted(value, key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "with open('Flipkart/CompanyTopFeatureByClass.json', 'w') as json_file:\n",
    "    json.dump(Top10InflunceFeature, json_file, indent=2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalConfidenceSize = yConfidence.shape[0]*yConfidence.shape[1]\n",
    "Confidence1DArr = yConfidence.reshape(totalConfidenceSize,1)\n",
    "Max = ceil(max(Confidence1DArr)[0])\n",
    "Min = floor(min(Confidence1DArr)[0])\n",
    "NormalisedConfid = [round((max(ele)-Min)/(Max-Min),2) for ele in yConfidence]\n",
    "productID = [ df[df.index==ele]['pid'].values[0] for ele in y_test_info['index'] ]\n",
    "ProductDescription =[ df[df.index==ele]['description'].values[0] for ele in y_test_info['index'] ]\n",
    "LinearSVCResult = pd.DataFrame({'id':productID,'description':ProductDescription,\n",
    "                         'trueClass': y_test,'trueClassNaem':target[y_test] ,\n",
    "                         'predictClass':yPred,'predictClassName':target[yPred],\n",
    "                         'Confidence':NormalisedConfid})\n",
    "LinearSVCResult.to_csv(\"Flipkart/SVCResults.csv\",index=False,compression=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_confidenceReport(data):\n",
    "    num = [ ele*0.01 for ele in range(20,81,2)]\n",
    "    totalitems = []\n",
    "    correct = []\n",
    "    incorrect = []\n",
    "    for ele in num:\n",
    "        Threshold = data[data.Confidence>ele]\n",
    "        correct.append(len(Threshold[Threshold['trueClass']==Threshold['predictClass']].index))\n",
    "        incorrect.append(len(Threshold[Threshold['trueClass']!=Threshold['predictClass']].index))\n",
    "        totalitems.append(len(Threshold.index))\n",
    "    \n",
    "    ClassfiedProportion = [ ele/len(data.index) for ele in totalitems]\n",
    "    \n",
    "    Acc =[]\n",
    "    for ele in zip(correct,totalitems):\n",
    "        if (ele[1]==0):\n",
    "            Acc.append(0)\n",
    "        else:\n",
    "            Acc.append(ele[0]/ele[1])\n",
    "\n",
    "    fig,ax  = plt.subplots()\n",
    "    \n",
    "    color = 'tab:blue'\n",
    "    ax.scatter(num,ClassfiedProportion,label=\"Proportion classified\",color=color)\n",
    "    ax.set_xlabel(\"Confidence Score\")\n",
    "    ax.set_ylabel(\"Proportion classified\", color=color)\n",
    "    ax.xaxis.set_ticks(np.arange(0,1.1,0.1))\n",
    "    ax.yaxis.set_ticks(np.arange(0,1.1,0.1))\n",
    "    ax.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    color = 'tab:red'\n",
    "\n",
    "    ax2 = ax.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "    ax2.scatter(num,Acc,label=\"Accuracy\", color=color)\n",
    "    ax2.set_ylabel(\"Accuracy\", color=color)\n",
    "    ax2.yaxis.set_ticks(np.arange(0,1.1,0.1))\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    ax.grid()\n",
    "    fig.savefig(\"Flipkart/ConfidenceScoreReportSVC.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, yPred,target_names=target))\n",
    "with open('Flipkart/SVCReport.txt', 'w') as file:\n",
    "    file.write(classification_report(y_test, yPred,target_names=target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, yPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "im =ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "ax.figure.colorbar(im, ax=ax)\n",
    "classes = target[unique_labels(y_test, yPred)]\n",
    "# We want to show all ticks...\n",
    "ax.set(xticks=np.arange(cm.shape[1]),yticks=np.arange(cm.shape[0]),\n",
    "       # ... and label them with the respective list entries\n",
    "        xticklabels=classes, yticklabels=classes,ylabel='True label',xlabel='Predicted label')\n",
    "# Rotate the tick labels and set their alignment.\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "fmt = 'd'\n",
    "thresh = cm.max() / 2.\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax.text(j, i, format(cm[i, j], fmt),ha=\"center\", va=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"Flipkart/LinearSVCConfusionMatrix.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_confidenceReport(LinearSVCResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax  = plt.subplots()\n",
    "ax.plot(BestSize,Scores,label=\"Linear SVC\")\n",
    "ax.set_xlabel(\"Number of best features\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "fig.savefig(\"Flipkart/linearsvcbestFeatureSize.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
