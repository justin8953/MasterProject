{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.feature_selection import SelectKBest,chi2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  \n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Conv1D, Dense, Embedding, Flatten, Input,Dropout,GlobalMaxPooling1D,MaxPooling1D\n",
    "from keras.metrics import categorical_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose folder\n",
    "folder = ['Amazon','FlipKart','Combine','Walmart']\n",
    "class OpenData:\n",
    "    def __init__(self,num):\n",
    "        self.num = num\n",
    "    def openFile(self):\n",
    "        num = self.num\n",
    "        trainData = pd.read_csv(folder[num]+'/X_train.csv')\n",
    "        trainLabel = pd.read_csv(folder[num]+'/y_train.csv')\n",
    "        testData = pd.read_csv(folder[num]+'/X_test.csv')\n",
    "        testLabel = pd.read_csv(folder[num]+'/y_test.csv')\n",
    "        if(num==0 or num==2):\n",
    "            # For Description has nan row\n",
    "            df = pd.concat([trainData,trainLabel], axis = 1)\n",
    "            df = df.dropna(subset=['X_train'])\n",
    "            trainData = pd.DataFrame({'X_train':df.X_train})\n",
    "            trainLabel = pd.DataFrame({'category':df.category,'subcategory':df.subcategory})\n",
    "            df = pd.concat([testData,testLabel], axis = 1)\n",
    "            df = df.dropna(subset=['X_test'])\n",
    "            testData = pd.DataFrame({'X_test':df.X_test})\n",
    "            testLabel = pd.DataFrame({'category':df.category,'subcategory':df.subcategory})\n",
    "        return trainData,trainLabel,testData,testLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HierarchicalModel:\n",
    "    def __init__(self,trainData, trainLabel ,testData, testLabel):\n",
    "        # X features         \n",
    "        self.X_train = trainData['X_train']\n",
    "        self.X_test =  testData['X_test']\n",
    "        # y labels \n",
    "        self.y_train = trainLabel['category']\n",
    "        self.y_test = testLabel['category']\n",
    "        self.ynd_train = trainLabel['subcategory']\n",
    "        self.ynd_test = testLabel['subcategory']\n",
    "        # y categorical labels\n",
    "        self.labels = to_categorical(trainLabel['category'])\n",
    "        self.sublabels = to_categorical(trainLabel['subcategory'])\n",
    "        # targets \n",
    "        self.target = np.unique(trainLabel['category'])\n",
    "        self.subtarget = np.unique(trainLabel['subcategory'])\n",
    "        # Output numbers\n",
    "        self.outputnum = len(np.unique(trainLabel['category']))\n",
    "        self.suboutputnum = len(np.unique(trainLabel['subcategory']))\n",
    "        # TrainList   \n",
    "        train = pd.concat([trainData,trainLabel], axis = 1)\n",
    "\n",
    "        self.trainList = train.groupby('category')\n",
    "    def wordToSequence(self):\n",
    "        parenttoChildFeature = {}\n",
    "        parenttoChildSubcategory = {}\n",
    "        uniqueCategory = self.target\n",
    "        trainList = self.trainList\n",
    "        Xtrain = self.X_train\n",
    "        Xtest = self.X_test\n",
    "        tfidfconverter = TfidfVectorizer(min_df=5, max_df=0.7)\n",
    "        X = tfidfconverter.fit_transform(Xtrain)\n",
    "        vocab_size = len(tfidfconverter.get_feature_names())\n",
    "        print(\"----- Vocabulary size : \"+ str(vocab_size)  +\" ----- \\n\")\n",
    "        tokenizer = Tokenizer(num_words=vocab_size) \n",
    "        tokenizer.fit_on_texts(Xtrain)\n",
    "        print(\"----- Convert train and test data to sequences ----- \\n\")\n",
    "        sequences = tokenizer.texts_to_sequences(Xtrain)\n",
    "        sequences_test = tokenizer.texts_to_sequences(Xtest)\n",
    "        \n",
    "        trainlengths = [len(ele) for ele in sequences]\n",
    "        testlengths = [len(ele) for ele in sequences_test]\n",
    "        max_length = max(max(trainlengths),max(testlengths))\n",
    "        \n",
    "        word_index = tokenizer.word_index\n",
    "        print(\"----- Total unique words : %d -----\\n\",len(word_index))\n",
    "        print(\"----- Convert train data to vector in second level ----- \\n\")\n",
    "        for ele in uniqueCategory:\n",
    "            subcategoryData = trainList.get_group(ele)\n",
    "            X_sub = tokenizer.texts_to_sequences(subcategoryData['X_train'])\n",
    "            parenttoChildFeature[ele] = X_sub\n",
    "            parenttoChildSubcategory[ele] = subcategoryData['subcategory']\n",
    "        self.wordIndex = word_index\n",
    "        self.vocabSize = vocab_size\n",
    "        self.max_length = max_length\n",
    "        return parenttoChildFeature,parenttoChildSubcategory, sequences, sequences_test\n",
    "    \n",
    "    def openGloveEmbeddingMatrix(self,dim):\n",
    "        embedding_dim = dim \n",
    "        self.embeddingDim = embedding_dim\n",
    "        print(\"---- Use \"+ str(dim) +\" dimension word vector ---- \\n\")\n",
    "\n",
    "        glove_dir = '../glove.6B' # This is the folder with the dataset\n",
    "        embeddings_index = {} # We create a dictionary of word -> embedding\n",
    "        with open(os.path.join(glove_dir, 'glove.6B.'+str(dim)+'d.txt')) as f:\n",
    "            for line in f:\n",
    "                values = line.split()\n",
    "                word = values[0] # The first value is the word, the rest are the values of the embedding\n",
    "                embedding = np.asarray(values[1:], dtype='float32') # Load embedding\n",
    "                embeddings_index[word] = embedding # Add embedding to our embedding dictionary\n",
    "        print('Found {:,} word vectors in GloVe.'.format(len(embeddings_index)))\n",
    "        return embeddings_index\n",
    "    \n",
    "    def creatEmeddingMatrix(self,embeddings_index):\n",
    "        word_index = self.wordIndex\n",
    "        vocab_size = self.vocabSize\n",
    "        embedding_dim = self.embeddingDim\n",
    "        nb_words = min(vocab_size, len(word_index)) # How many words are there actually\n",
    "        embedding_matrix = np.zeros((nb_words, embedding_dim))\n",
    "        # The vectors need to be in the same position as their index. \n",
    "        # Meaning a word with token 1 needs to be in the second row (rows start with zero) and so on\n",
    "        # Loop over all words in the word index\n",
    "        for word, i in word_index.items():\n",
    "            # If we are above the amount of words we want to use we do nothing\n",
    "            if i >= vocab_size: \n",
    "                continue\n",
    "            # Get the embedding vector for the word\n",
    "            embedding_vector = embeddings_index.get(word)\n",
    "            # If there is an embedding vector, put it in the embedding matrix\n",
    "            if embedding_vector is not None: \n",
    "                embedding_matrix[i] = embedding_vector\n",
    "        return embedding_matrix\n",
    "    def selectBestfeatureViaChi2(self,Xtrain, Ytrain, Xtest, num):\n",
    "        selectBest = SelectKBest(chi2, k=num).fit(Xtrain, Ytrain)\n",
    "        Xtrainbest = selectBest.transform(Xtrain)\n",
    "        Xtestbest = selectBest.transform(Xtest)\n",
    "        return Xtrainbest,Xtestbest\n",
    "    def model_settings(self,length,embeddingMatrix,outputnum):\n",
    "        vocab_size = self.vocabSize\n",
    "        embedding_dim = self.embeddingDim\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(vocab_size, embedding_dim, input_length=length, weights = [embedding_matrix], \n",
    "                                trainable = False))\n",
    "        model.add(Conv1D(200,3,padding='valid',activation='relu',strides=1))        \n",
    "        # we use max pooling:\n",
    "        model.add(GlobalMaxPooling1D())\n",
    "        # We add a vanilla hidden layer:\n",
    "        model.add(Dense(250))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(outputnum, activation='softmax'))\n",
    "        model.summary()\n",
    "        return model\n",
    "    \n",
    "    def subclassifiers(self,feature, subcategory, embeddingMatrix, num):\n",
    "        classifiers = {}\n",
    "        max_length= self.max_length\n",
    "        for key, values in feature.items():\n",
    "            numofUniqueSubcategory = len(np.unique(subcategory[key]))\n",
    "            if (numofUniqueSubcategory>1):\n",
    "                Xtrain = pad_sequences(values,maxlen= num)\n",
    "                le = LabelEncoder()\n",
    "                le.fit(subcategory[key])\n",
    "                target = le.classes_\n",
    "                labels = le.transform(subcategory[key])\n",
    "                batch_size = 100\n",
    "                epochs = 10\n",
    "                model = self.model_settings(num,embeddingMatrix,numofUniqueSubcategory)\n",
    "                model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[categorical_accuracy])\n",
    "                history = model.fit(Xtrain,to_categorical(labels), batch_size=batch_size, epochs=epochs, verbose=1, validation_split=0.2)\n",
    "                classifiers[key] = [model,target]\n",
    "            else:\n",
    "                classifiers[key] = np.unique(subcategory[key])[0]\n",
    "        return classifiers\n",
    "    def firstLevelModelTraining(self,sequences,sequences_test,embeddingMatrix,num):\n",
    "        outputnum = self.outputnum\n",
    "        trainlengths = [len(ele) for ele in sequences]\n",
    "        testlengths = [len(ele) for ele in sequences_test]\n",
    "        max_length = max(max(trainlengths),max(testlengths))\n",
    "        train = pad_sequences(sequences,maxlen= max_length)\n",
    "        test = pad_sequences(sequences_test,maxlen = max_length)\n",
    "        y_train = self.labels\n",
    "        y_test = self.y_test\n",
    "        batch_size = 100\n",
    "        epochs = 10\n",
    "        scores = []\n",
    "        X, XTest = self.selectBestfeatureViaChi2(train,y_train,test,num)\n",
    "        model = self.model_settings(num,embeddingMatrix,outputnum)\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[categorical_accuracy])\n",
    "        history = model.fit(X, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_split=0.2)\n",
    "        %time\n",
    "        y_pred = model.predict(XTest)\n",
    "        predict = []\n",
    "        for ele in y_pred:\n",
    "            predict.append(np.argmax(ele))\n",
    "        return predict\n",
    "\n",
    "    def PredictSecondLevel(self,classifiers,Ypred ,Xtest,num):\n",
    "        predict = []\n",
    "        index = 0            \n",
    "        Ytest = self.ynd_test\n",
    "        test = pad_sequences(Xtest,maxlen= num)\n",
    "        %time\n",
    "        for ele in Ypred:\n",
    "            classifier =  classifiers[ele]\n",
    "            if(type(classifier)!=np.int64):\n",
    "                model =  classifier[0]\n",
    "                target = classifier[1]\n",
    "                y_pred = model.predict(test[index:index+1])\n",
    "                predict.append(target[np.argmax(y_pred[0])])\n",
    "            else:\n",
    "                y_pred = classifier\n",
    "                predict.append(y_pred)\n",
    "            index = index + 1\n",
    "        print(classification_report(Ytest, predict,labels=np.unique(Ytest)))\n",
    "        return predict\n",
    "    def FlatApproach(self, sequences,sequences_test,embeddingMatrix,num):\n",
    "        outputnum = self.suboutputnum\n",
    "        trainlengths = [len(ele) for ele in sequences]\n",
    "        testlengths = [len(ele) for ele in sequences_test]\n",
    "        max_length = max(max(trainlengths),max(testlengths))\n",
    "        train = pad_sequences(sequences,maxlen= max_length)\n",
    "        test = pad_sequences(sequences_test,maxlen = max_length)\n",
    "        y_train = self.sublabels\n",
    "        y_test = self.ynd_test\n",
    "        batch_size = 100\n",
    "        epochs = 10\n",
    "        scores = []\n",
    "        X, XTest = self.selectBestfeatureViaChi2(train,y_train,test,num)\n",
    "        model = self.model_settings(num,embeddingMatrix,outputnum)\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[categorical_accuracy])\n",
    "        history = model.fit(X, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_split=0.2)\n",
    "        %time\n",
    "        y_pred = model.predict(XTest)\n",
    "        predict = []\n",
    "        for ele in y_pred:\n",
    "            predict.append(np.argmax(ele))\n",
    "        print(classification_report(y_test, predict,labels=np.unique(y_test)))\n",
    "\n",
    "        return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "openData = OpenData(0)\n",
    "trainData,trainLabel,testData,testLabel = openData.openFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "HCM = HierarchicalModel(trainData,trainLabel,testData,testLabel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Vocabulary size : 5927 ----- \n",
      "\n",
      "----- Convert train and test data to sequences ----- \n",
      "\n",
      "----- Total unique words : %d -----\n",
      " 24058\n",
      "----- Convert train data to vector in second level ----- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "parenttoChildFeature,parenttoChildSubcategory, sequences, sequences_test = HCM.wordToSequence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Use 300 dimension word vector ---- \n",
      "\n",
      "Found 400,000 word vectors in GloVe.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = HCM.openGloveEmbeddingMatrix(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = HCM.creatEmeddingMatrix(embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0727 13:23:17.263332 139870887159616 deprecation_wrapper.py:119] From /home/justin/classification/app/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0727 13:23:17.286681 139870887159616 deprecation_wrapper.py:119] From /home/justin/classification/app/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0727 13:23:17.290698 139870887159616 deprecation_wrapper.py:119] From /home/justin/classification/app/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0727 13:23:17.305935 139870887159616 deprecation_wrapper.py:119] From /home/justin/classification/app/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0727 13:23:17.307142 139870887159616 deprecation_wrapper.py:119] From /home/justin/classification/app/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0727 13:23:17.424219 139870887159616 deprecation.py:506] From /home/justin/classification/app/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0727 13:23:17.455979 139870887159616 deprecation_wrapper.py:119] From /home/justin/classification/app/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0727 13:23:17.483047 139870887159616 deprecation.py:323] From /home/justin/classification/app/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 650, 300)          1778100   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 648, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 1506      \n",
      "=================================================================\n",
      "Total params: 2,010,056\n",
      "Trainable params: 231,956\n",
      "Non-trainable params: 1,778,100\n",
      "_________________________________________________________________\n",
      "Train on 442 samples, validate on 111 samples\n",
      "Epoch 1/10\n",
      "442/442 [==============================] - 2s 4ms/step - loss: 0.4608 - categorical_accuracy: 0.3891 - val_loss: 0.3420 - val_categorical_accuracy: 0.6126\n",
      "Epoch 2/10\n",
      "442/442 [==============================] - 1s 3ms/step - loss: 0.3220 - categorical_accuracy: 0.5860 - val_loss: 0.2527 - val_categorical_accuracy: 0.6937\n",
      "Epoch 3/10\n",
      "442/442 [==============================] - 1s 3ms/step - loss: 0.2057 - categorical_accuracy: 0.7941 - val_loss: 0.2448 - val_categorical_accuracy: 0.6847\n",
      "Epoch 4/10\n",
      "442/442 [==============================] - 1s 3ms/step - loss: 0.1494 - categorical_accuracy: 0.8416 - val_loss: 0.2019 - val_categorical_accuracy: 0.7027\n",
      "Epoch 5/10\n",
      "442/442 [==============================] - 1s 3ms/step - loss: 0.1136 - categorical_accuracy: 0.9050 - val_loss: 0.1750 - val_categorical_accuracy: 0.7568\n",
      "Epoch 6/10\n",
      "442/442 [==============================] - 1s 3ms/step - loss: 0.0771 - categorical_accuracy: 0.9570 - val_loss: 0.1631 - val_categorical_accuracy: 0.7748\n",
      "Epoch 7/10\n",
      "442/442 [==============================] - 1s 3ms/step - loss: 0.0527 - categorical_accuracy: 0.9706 - val_loss: 0.1527 - val_categorical_accuracy: 0.7928\n",
      "Epoch 8/10\n",
      "442/442 [==============================] - 1s 3ms/step - loss: 0.0343 - categorical_accuracy: 0.9932 - val_loss: 0.1487 - val_categorical_accuracy: 0.7838\n",
      "Epoch 9/10\n",
      "442/442 [==============================] - 1s 3ms/step - loss: 0.0239 - categorical_accuracy: 0.9932 - val_loss: 0.1468 - val_categorical_accuracy: 0.7928\n",
      "Epoch 10/10\n",
      "442/442 [==============================] - 1s 3ms/step - loss: 0.0171 - categorical_accuracy: 0.9977 - val_loss: 0.1432 - val_categorical_accuracy: 0.8018\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 650, 300)          1778100   \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 648, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 7)                 1757      \n",
      "=================================================================\n",
      "Total params: 2,010,307\n",
      "Trainable params: 232,207\n",
      "Non-trainable params: 1,778,100\n",
      "_________________________________________________________________\n",
      "Train on 503 samples, validate on 126 samples\n",
      "Epoch 1/10\n",
      "503/503 [==============================] - 2s 4ms/step - loss: 0.4031 - categorical_accuracy: 0.3638 - val_loss: 0.2745 - val_categorical_accuracy: 0.6508\n",
      "Epoch 2/10\n",
      "503/503 [==============================] - 1s 3ms/step - loss: 0.2935 - categorical_accuracy: 0.5865 - val_loss: 0.2547 - val_categorical_accuracy: 0.5159\n",
      "Epoch 3/10\n",
      "503/503 [==============================] - 1s 3ms/step - loss: 0.2025 - categorical_accuracy: 0.6958 - val_loss: 0.1954 - val_categorical_accuracy: 0.7778\n",
      "Epoch 4/10\n",
      "503/503 [==============================] - 1s 3ms/step - loss: 0.1743 - categorical_accuracy: 0.7734 - val_loss: 0.1771 - val_categorical_accuracy: 0.7143\n",
      "Epoch 5/10\n",
      "503/503 [==============================] - 1s 3ms/step - loss: 0.1228 - categorical_accuracy: 0.8111 - val_loss: 0.1458 - val_categorical_accuracy: 0.8016\n",
      "Epoch 6/10\n",
      "503/503 [==============================] - 1s 3ms/step - loss: 0.0931 - categorical_accuracy: 0.9125 - val_loss: 0.1354 - val_categorical_accuracy: 0.8016\n",
      "Epoch 7/10\n",
      "503/503 [==============================] - 1s 3ms/step - loss: 0.0703 - categorical_accuracy: 0.9264 - val_loss: 0.1135 - val_categorical_accuracy: 0.8571\n",
      "Epoch 8/10\n",
      "503/503 [==============================] - 1s 3ms/step - loss: 0.0519 - categorical_accuracy: 0.9662 - val_loss: 0.1072 - val_categorical_accuracy: 0.8651\n",
      "Epoch 9/10\n",
      "503/503 [==============================] - 1s 3ms/step - loss: 0.0392 - categorical_accuracy: 0.9841 - val_loss: 0.1150 - val_categorical_accuracy: 0.8492\n",
      "Epoch 10/10\n",
      "503/503 [==============================] - 1s 3ms/step - loss: 0.0423 - categorical_accuracy: 0.9781 - val_loss: 0.1141 - val_categorical_accuracy: 0.8492\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 650, 300)          1778100   \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 648, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 502       \n",
      "=================================================================\n",
      "Total params: 2,009,052\n",
      "Trainable params: 230,952\n",
      "Non-trainable params: 1,778,100\n",
      "_________________________________________________________________\n",
      "Train on 756 samples, validate on 189 samples\n",
      "Epoch 1/10\n",
      "756/756 [==============================] - 3s 4ms/step - loss: 0.4763 - categorical_accuracy: 0.8783 - val_loss: 0.1714 - val_categorical_accuracy: 0.9365\n",
      "Epoch 2/10\n",
      "756/756 [==============================] - 2s 3ms/step - loss: 0.1594 - categorical_accuracy: 0.9378 - val_loss: 0.1067 - val_categorical_accuracy: 0.9418\n",
      "Epoch 3/10\n",
      "756/756 [==============================] - 2s 3ms/step - loss: 0.0627 - categorical_accuracy: 0.9881 - val_loss: 0.0833 - val_categorical_accuracy: 0.9630\n",
      "Epoch 4/10\n",
      "756/756 [==============================] - 2s 3ms/step - loss: 0.0303 - categorical_accuracy: 0.9907 - val_loss: 0.0758 - val_categorical_accuracy: 0.9630\n",
      "Epoch 5/10\n",
      "756/756 [==============================] - 2s 3ms/step - loss: 0.0140 - categorical_accuracy: 0.9987 - val_loss: 0.0559 - val_categorical_accuracy: 0.9683\n",
      "Epoch 6/10\n",
      "756/756 [==============================] - 2s 3ms/step - loss: 0.0101 - categorical_accuracy: 0.9987 - val_loss: 0.0610 - val_categorical_accuracy: 0.9683\n",
      "Epoch 7/10\n",
      "756/756 [==============================] - 2s 3ms/step - loss: 0.0065 - categorical_accuracy: 1.0000 - val_loss: 0.0735 - val_categorical_accuracy: 0.9683\n",
      "Epoch 8/10\n",
      "756/756 [==============================] - 2s 3ms/step - loss: 0.0053 - categorical_accuracy: 1.0000 - val_loss: 0.0750 - val_categorical_accuracy: 0.9683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "756/756 [==============================] - 2s 3ms/step - loss: 0.0044 - categorical_accuracy: 1.0000 - val_loss: 0.0661 - val_categorical_accuracy: 0.9683\n",
      "Epoch 10/10\n",
      "756/756 [==============================] - 2s 3ms/step - loss: 0.0039 - categorical_accuracy: 1.0000 - val_loss: 0.0618 - val_categorical_accuracy: 0.9683\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 650, 300)          1778100   \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 648, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_4 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 502       \n",
      "=================================================================\n",
      "Total params: 2,009,052\n",
      "Trainable params: 230,952\n",
      "Non-trainable params: 1,778,100\n",
      "_________________________________________________________________\n",
      "Train on 198 samples, validate on 50 samples\n",
      "Epoch 1/10\n",
      "198/198 [==============================] - 1s 7ms/step - loss: 1.2465 - categorical_accuracy: 0.4798 - val_loss: 0.7293 - val_categorical_accuracy: 0.4600\n",
      "Epoch 2/10\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5319 - categorical_accuracy: 0.7020 - val_loss: 0.5750 - val_categorical_accuracy: 0.7400\n",
      "Epoch 3/10\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.5120 - categorical_accuracy: 0.7626 - val_loss: 0.2306 - val_categorical_accuracy: 0.9200\n",
      "Epoch 4/10\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.1800 - categorical_accuracy: 0.9242 - val_loss: 0.2197 - val_categorical_accuracy: 0.9800\n",
      "Epoch 5/10\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.1764 - categorical_accuracy: 0.9545 - val_loss: 0.2983 - val_categorical_accuracy: 0.7800\n",
      "Epoch 6/10\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.1599 - categorical_accuracy: 0.9596 - val_loss: 0.1819 - val_categorical_accuracy: 0.9600\n",
      "Epoch 7/10\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0930 - categorical_accuracy: 0.9798 - val_loss: 0.1085 - val_categorical_accuracy: 0.9600\n",
      "Epoch 8/10\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0620 - categorical_accuracy: 0.9798 - val_loss: 0.1173 - val_categorical_accuracy: 0.9400\n",
      "Epoch 9/10\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0604 - categorical_accuracy: 0.9899 - val_loss: 0.1296 - val_categorical_accuracy: 0.9400\n",
      "Epoch 10/10\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0555 - categorical_accuracy: 0.9747 - val_loss: 0.1203 - val_categorical_accuracy: 0.9400\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 650, 300)          1778100   \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 648, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_5 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 3)                 753       \n",
      "=================================================================\n",
      "Total params: 2,009,303\n",
      "Trainable params: 231,203\n",
      "Non-trainable params: 1,778,100\n",
      "_________________________________________________________________\n",
      "Train on 348 samples, validate on 88 samples\n",
      "Epoch 1/10\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 0.6329 - categorical_accuracy: 0.4943 - val_loss: 0.4156 - val_categorical_accuracy: 0.6705\n",
      "Epoch 2/10\n",
      "348/348 [==============================] - 1s 3ms/step - loss: 0.3551 - categorical_accuracy: 0.7672 - val_loss: 0.3315 - val_categorical_accuracy: 0.7841\n",
      "Epoch 3/10\n",
      "348/348 [==============================] - 1s 3ms/step - loss: 0.2428 - categorical_accuracy: 0.8851 - val_loss: 0.3461 - val_categorical_accuracy: 0.7159\n",
      "Epoch 4/10\n",
      "348/348 [==============================] - 1s 3ms/step - loss: 0.2134 - categorical_accuracy: 0.9109 - val_loss: 0.2954 - val_categorical_accuracy: 0.7955\n",
      "Epoch 5/10\n",
      "348/348 [==============================] - 1s 3ms/step - loss: 0.1593 - categorical_accuracy: 0.9425 - val_loss: 0.3210 - val_categorical_accuracy: 0.7841\n",
      "Epoch 6/10\n",
      "348/348 [==============================] - 1s 3ms/step - loss: 0.1349 - categorical_accuracy: 0.9569 - val_loss: 0.3049 - val_categorical_accuracy: 0.7841\n",
      "Epoch 7/10\n",
      "348/348 [==============================] - 1s 3ms/step - loss: 0.1080 - categorical_accuracy: 0.9684 - val_loss: 0.3093 - val_categorical_accuracy: 0.7841\n",
      "Epoch 8/10\n",
      "348/348 [==============================] - 1s 3ms/step - loss: 0.0902 - categorical_accuracy: 0.9713 - val_loss: 0.3014 - val_categorical_accuracy: 0.7955\n",
      "Epoch 9/10\n",
      "348/348 [==============================] - 1s 3ms/step - loss: 0.0760 - categorical_accuracy: 0.9770 - val_loss: 0.2767 - val_categorical_accuracy: 0.8295\n",
      "Epoch 10/10\n",
      "348/348 [==============================] - 1s 3ms/step - loss: 0.0609 - categorical_accuracy: 0.9713 - val_loss: 0.3178 - val_categorical_accuracy: 0.7841\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 650, 300)          1778100   \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 648, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_6 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 7)                 1757      \n",
      "=================================================================\n",
      "Total params: 2,010,307\n",
      "Trainable params: 232,207\n",
      "Non-trainable params: 1,778,100\n",
      "_________________________________________________________________\n",
      "Train on 662 samples, validate on 166 samples\n",
      "Epoch 1/10\n",
      "662/662 [==============================] - 3s 4ms/step - loss: 0.4026 - categorical_accuracy: 0.3233 - val_loss: 0.3241 - val_categorical_accuracy: 0.4759\n",
      "Epoch 2/10\n",
      "662/662 [==============================] - 2s 3ms/step - loss: 0.2962 - categorical_accuracy: 0.5665 - val_loss: 0.2635 - val_categorical_accuracy: 0.5904\n",
      "Epoch 3/10\n",
      "662/662 [==============================] - 2s 3ms/step - loss: 0.2252 - categorical_accuracy: 0.6631 - val_loss: 0.2413 - val_categorical_accuracy: 0.6566\n",
      "Epoch 4/10\n",
      "662/662 [==============================] - 2s 3ms/step - loss: 0.1700 - categorical_accuracy: 0.7885 - val_loss: 0.2314 - val_categorical_accuracy: 0.6566\n",
      "Epoch 5/10\n",
      "662/662 [==============================] - 2s 3ms/step - loss: 0.1273 - categorical_accuracy: 0.8505 - val_loss: 0.2057 - val_categorical_accuracy: 0.6988\n",
      "Epoch 6/10\n",
      "662/662 [==============================] - 2s 3ms/step - loss: 0.0972 - categorical_accuracy: 0.9094 - val_loss: 0.2080 - val_categorical_accuracy: 0.6928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "662/662 [==============================] - 2s 3ms/step - loss: 0.0732 - categorical_accuracy: 0.9320 - val_loss: 0.2108 - val_categorical_accuracy: 0.6867\n",
      "Epoch 8/10\n",
      "662/662 [==============================] - 2s 3ms/step - loss: 0.0540 - categorical_accuracy: 0.9577 - val_loss: 0.2092 - val_categorical_accuracy: 0.6807\n",
      "Epoch 9/10\n",
      "662/662 [==============================] - 2s 3ms/step - loss: 0.0428 - categorical_accuracy: 0.9743 - val_loss: 0.2132 - val_categorical_accuracy: 0.6867\n",
      "Epoch 10/10\n",
      "662/662 [==============================] - 2s 3ms/step - loss: 0.0325 - categorical_accuracy: 0.9789 - val_loss: 0.2220 - val_categorical_accuracy: 0.6928\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 650, 300)          1778100   \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 648, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_7 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 6)                 1506      \n",
      "=================================================================\n",
      "Total params: 2,010,056\n",
      "Trainable params: 231,956\n",
      "Non-trainable params: 1,778,100\n",
      "_________________________________________________________________\n",
      "Train on 545 samples, validate on 137 samples\n",
      "Epoch 1/10\n",
      "545/545 [==============================] - 3s 5ms/step - loss: 0.4688 - categorical_accuracy: 0.3376 - val_loss: 0.3026 - val_categorical_accuracy: 0.6131\n",
      "Epoch 2/10\n",
      "545/545 [==============================] - 2s 3ms/step - loss: 0.2793 - categorical_accuracy: 0.6330 - val_loss: 0.2262 - val_categorical_accuracy: 0.8029\n",
      "Epoch 3/10\n",
      "545/545 [==============================] - 2s 3ms/step - loss: 0.1907 - categorical_accuracy: 0.8018 - val_loss: 0.1922 - val_categorical_accuracy: 0.7299\n",
      "Epoch 4/10\n",
      "545/545 [==============================] - 2s 3ms/step - loss: 0.1330 - categorical_accuracy: 0.8807 - val_loss: 0.1585 - val_categorical_accuracy: 0.8394\n",
      "Epoch 5/10\n",
      "545/545 [==============================] - 2s 3ms/step - loss: 0.0927 - categorical_accuracy: 0.9303 - val_loss: 0.1464 - val_categorical_accuracy: 0.8175\n",
      "Epoch 6/10\n",
      "545/545 [==============================] - 2s 3ms/step - loss: 0.0601 - categorical_accuracy: 0.9780 - val_loss: 0.1370 - val_categorical_accuracy: 0.8394\n",
      "Epoch 7/10\n",
      "545/545 [==============================] - 2s 3ms/step - loss: 0.0403 - categorical_accuracy: 0.9798 - val_loss: 0.1366 - val_categorical_accuracy: 0.8394\n",
      "Epoch 8/10\n",
      "545/545 [==============================] - 2s 3ms/step - loss: 0.0284 - categorical_accuracy: 0.9890 - val_loss: 0.1329 - val_categorical_accuracy: 0.8394\n",
      "Epoch 9/10\n",
      "545/545 [==============================] - 1s 3ms/step - loss: 0.0197 - categorical_accuracy: 0.9945 - val_loss: 0.1479 - val_categorical_accuracy: 0.8029\n",
      "Epoch 10/10\n",
      "545/545 [==============================] - 2s 3ms/step - loss: 0.0129 - categorical_accuracy: 0.9963 - val_loss: 0.1349 - val_categorical_accuracy: 0.8394\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 650, 300)          1778100   \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 648, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_8 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 6)                 1506      \n",
      "=================================================================\n",
      "Total params: 2,010,056\n",
      "Trainable params: 231,956\n",
      "Non-trainable params: 1,778,100\n",
      "_________________________________________________________________\n",
      "Train on 856 samples, validate on 214 samples\n",
      "Epoch 1/10\n",
      "856/856 [==============================] - 4s 4ms/step - loss: 0.4434 - categorical_accuracy: 0.4404 - val_loss: 0.3251 - val_categorical_accuracy: 0.5701\n",
      "Epoch 2/10\n",
      "856/856 [==============================] - 2s 3ms/step - loss: 0.2097 - categorical_accuracy: 0.7687 - val_loss: 0.1817 - val_categorical_accuracy: 0.7710\n",
      "Epoch 3/10\n",
      "856/856 [==============================] - 3s 3ms/step - loss: 0.1090 - categorical_accuracy: 0.8914 - val_loss: 0.1317 - val_categorical_accuracy: 0.8551\n",
      "Epoch 4/10\n",
      "856/856 [==============================] - 3s 3ms/step - loss: 0.0623 - categorical_accuracy: 0.9521 - val_loss: 0.1162 - val_categorical_accuracy: 0.8692\n",
      "Epoch 5/10\n",
      "856/856 [==============================] - 3s 3ms/step - loss: 0.0355 - categorical_accuracy: 0.9836 - val_loss: 0.1097 - val_categorical_accuracy: 0.8692\n",
      "Epoch 6/10\n",
      "856/856 [==============================] - 2s 3ms/step - loss: 0.0211 - categorical_accuracy: 0.9942 - val_loss: 0.1084 - val_categorical_accuracy: 0.8692\n",
      "Epoch 7/10\n",
      "856/856 [==============================] - 2s 3ms/step - loss: 0.0133 - categorical_accuracy: 0.9988 - val_loss: 0.1084 - val_categorical_accuracy: 0.8692\n",
      "Epoch 8/10\n",
      "856/856 [==============================] - 2s 3ms/step - loss: 0.0089 - categorical_accuracy: 1.0000 - val_loss: 0.1072 - val_categorical_accuracy: 0.8738\n",
      "Epoch 9/10\n",
      "856/856 [==============================] - 3s 3ms/step - loss: 0.0065 - categorical_accuracy: 1.0000 - val_loss: 0.1057 - val_categorical_accuracy: 0.8785\n",
      "Epoch 10/10\n",
      "856/856 [==============================] - 3s 3ms/step - loss: 0.0049 - categorical_accuracy: 1.0000 - val_loss: 0.1071 - val_categorical_accuracy: 0.8738\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 650, 300)          1778100   \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 648, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_9 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 3)                 753       \n",
      "=================================================================\n",
      "Total params: 2,009,303\n",
      "Trainable params: 231,203\n",
      "Non-trainable params: 1,778,100\n",
      "_________________________________________________________________\n",
      "Train on 164 samples, validate on 42 samples\n",
      "Epoch 1/10\n",
      "164/164 [==============================] - 2s 10ms/step - loss: 0.7593 - categorical_accuracy: 0.4695 - val_loss: 0.4908 - val_categorical_accuracy: 0.6429\n",
      "Epoch 2/10\n",
      "164/164 [==============================] - 0s 3ms/step - loss: 0.5635 - categorical_accuracy: 0.5732 - val_loss: 0.7984 - val_categorical_accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "164/164 [==============================] - 0s 3ms/step - loss: 0.5709 - categorical_accuracy: 0.6646 - val_loss: 0.7255 - val_categorical_accuracy: 0.5238\n",
      "Epoch 4/10\n",
      "164/164 [==============================] - 0s 3ms/step - loss: 0.4322 - categorical_accuracy: 0.7073 - val_loss: 0.4682 - val_categorical_accuracy: 0.5952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "164/164 [==============================] - 0s 3ms/step - loss: 0.2421 - categorical_accuracy: 0.9085 - val_loss: 0.3948 - val_categorical_accuracy: 0.6667\n",
      "Epoch 6/10\n",
      "164/164 [==============================] - 0s 3ms/step - loss: 0.2671 - categorical_accuracy: 0.8171 - val_loss: 0.3494 - val_categorical_accuracy: 0.7619\n",
      "Epoch 7/10\n",
      "164/164 [==============================] - 0s 3ms/step - loss: 0.1556 - categorical_accuracy: 0.9573 - val_loss: 0.4347 - val_categorical_accuracy: 0.6667\n",
      "Epoch 8/10\n",
      "164/164 [==============================] - 0s 3ms/step - loss: 0.1389 - categorical_accuracy: 0.9451 - val_loss: 0.5043 - val_categorical_accuracy: 0.5952\n",
      "Epoch 9/10\n",
      "164/164 [==============================] - 0s 3ms/step - loss: 0.1253 - categorical_accuracy: 0.9390 - val_loss: 0.4549 - val_categorical_accuracy: 0.5952\n",
      "Epoch 10/10\n",
      "164/164 [==============================] - 0s 3ms/step - loss: 0.0799 - categorical_accuracy: 0.9878 - val_loss: 0.3550 - val_categorical_accuracy: 0.8095\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 650, 300)          1778100   \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 648, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_10 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 2)                 502       \n",
      "=================================================================\n",
      "Total params: 2,009,052\n",
      "Trainable params: 230,952\n",
      "Non-trainable params: 1,778,100\n",
      "_________________________________________________________________\n",
      "Train on 352 samples, validate on 88 samples\n",
      "Epoch 1/10\n",
      "352/352 [==============================] - 2s 7ms/step - loss: 0.6401 - categorical_accuracy: 0.5909 - val_loss: 0.3499 - val_categorical_accuracy: 0.7841\n",
      "Epoch 2/10\n",
      "352/352 [==============================] - 1s 3ms/step - loss: 0.3377 - categorical_accuracy: 0.8807 - val_loss: 0.2929 - val_categorical_accuracy: 0.8750\n",
      "Epoch 3/10\n",
      "352/352 [==============================] - 1s 3ms/step - loss: 0.2448 - categorical_accuracy: 0.9034 - val_loss: 0.1722 - val_categorical_accuracy: 0.9205\n",
      "Epoch 4/10\n",
      "352/352 [==============================] - 1s 3ms/step - loss: 0.1570 - categorical_accuracy: 0.9574 - val_loss: 0.1584 - val_categorical_accuracy: 0.9318\n",
      "Epoch 5/10\n",
      "352/352 [==============================] - 1s 3ms/step - loss: 0.1090 - categorical_accuracy: 0.9744 - val_loss: 0.1481 - val_categorical_accuracy: 0.9205\n",
      "Epoch 6/10\n",
      "352/352 [==============================] - 1s 3ms/step - loss: 0.0894 - categorical_accuracy: 0.9744 - val_loss: 0.1321 - val_categorical_accuracy: 0.9318\n",
      "Epoch 7/10\n",
      "352/352 [==============================] - 1s 3ms/step - loss: 0.0752 - categorical_accuracy: 0.9659 - val_loss: 0.1400 - val_categorical_accuracy: 0.9318\n",
      "Epoch 8/10\n",
      "352/352 [==============================] - 1s 3ms/step - loss: 0.0635 - categorical_accuracy: 0.9716 - val_loss: 0.1284 - val_categorical_accuracy: 0.9318\n",
      "Epoch 9/10\n",
      "352/352 [==============================] - 1s 3ms/step - loss: 0.0571 - categorical_accuracy: 0.9801 - val_loss: 0.1352 - val_categorical_accuracy: 0.9205\n",
      "Epoch 10/10\n",
      "352/352 [==============================] - 1s 3ms/step - loss: 0.0498 - categorical_accuracy: 0.9830 - val_loss: 0.1446 - val_categorical_accuracy: 0.9432\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 650, 300)          1778100   \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 648, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_11 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 2)                 502       \n",
      "=================================================================\n",
      "Total params: 2,009,052\n",
      "Trainable params: 230,952\n",
      "Non-trainable params: 1,778,100\n",
      "_________________________________________________________________\n",
      "Train on 153 samples, validate on 39 samples\n",
      "Epoch 1/10\n",
      "153/153 [==============================] - 2s 13ms/step - loss: 0.0693 - categorical_accuracy: 0.9869 - val_loss: 2.5880e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "153/153 [==============================] - 0s 3ms/step - loss: 0.0456 - categorical_accuracy: 0.9935 - val_loss: 3.0067e-07 - val_categorical_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "153/153 [==============================] - 0s 3ms/step - loss: 0.0450 - categorical_accuracy: 0.9935 - val_loss: 1.1908e-07 - val_categorical_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "153/153 [==============================] - 0s 3ms/step - loss: 0.0261 - categorical_accuracy: 0.9935 - val_loss: 1.0960e-07 - val_categorical_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "153/153 [==============================] - 0s 3ms/step - loss: 0.0212 - categorical_accuracy: 0.9935 - val_loss: 1.0960e-07 - val_categorical_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "153/153 [==============================] - 0s 3ms/step - loss: 0.0086 - categorical_accuracy: 0.9935 - val_loss: 1.0960e-07 - val_categorical_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "153/153 [==============================] - 0s 3ms/step - loss: 0.0046 - categorical_accuracy: 1.0000 - val_loss: 1.0960e-07 - val_categorical_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "153/153 [==============================] - 0s 3ms/step - loss: 0.0041 - categorical_accuracy: 1.0000 - val_loss: 1.0960e-07 - val_categorical_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "153/153 [==============================] - 0s 3ms/step - loss: 0.0040 - categorical_accuracy: 1.0000 - val_loss: 1.0960e-07 - val_categorical_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "153/153 [==============================] - 0s 3ms/step - loss: 0.0039 - categorical_accuracy: 1.0000 - val_loss: 1.0960e-07 - val_categorical_accuracy: 1.0000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, 650, 300)          1778100   \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 648, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_12 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 2)                 502       \n",
      "=================================================================\n",
      "Total params: 2,009,052\n",
      "Trainable params: 230,952\n",
      "Non-trainable params: 1,778,100\n",
      "_________________________________________________________________\n",
      "Train on 184 samples, validate on 46 samples\n",
      "Epoch 1/10\n",
      "184/184 [==============================] - 2s 11ms/step - loss: 1.3361 - categorical_accuracy: 0.4620 - val_loss: 0.4493 - val_categorical_accuracy: 0.7826\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 1s 3ms/step - loss: 0.7838 - categorical_accuracy: 0.6141 - val_loss: 1.3822 - val_categorical_accuracy: 0.2609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "184/184 [==============================] - 1s 3ms/step - loss: 0.6938 - categorical_accuracy: 0.6250 - val_loss: 0.2640 - val_categorical_accuracy: 0.9348\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 1s 3ms/step - loss: 0.3319 - categorical_accuracy: 0.8478 - val_loss: 0.3394 - val_categorical_accuracy: 0.8043\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 1s 3ms/step - loss: 0.3852 - categorical_accuracy: 0.7609 - val_loss: 0.1942 - val_categorical_accuracy: 0.9130\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 1s 3ms/step - loss: 0.1504 - categorical_accuracy: 0.9620 - val_loss: 0.2250 - val_categorical_accuracy: 0.9130\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 1s 3ms/step - loss: 0.1180 - categorical_accuracy: 0.9837 - val_loss: 0.3563 - val_categorical_accuracy: 0.7174\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 1s 3ms/step - loss: 0.1503 - categorical_accuracy: 0.9457 - val_loss: 0.2828 - val_categorical_accuracy: 0.8913\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 1s 3ms/step - loss: 0.1024 - categorical_accuracy: 0.9728 - val_loss: 0.1573 - val_categorical_accuracy: 0.9348\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 1s 3ms/step - loss: 0.0376 - categorical_accuracy: 1.0000 - val_loss: 0.1116 - val_categorical_accuracy: 0.9348\n"
     ]
    }
   ],
   "source": [
    "classifiers= HCM.subclassifiers(parenttoChildFeature,parenttoChildSubcategory,embedding_matrix,650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, 650, 300)          1778100   \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 648, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_13 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 14)                3514      \n",
      "=================================================================\n",
      "Total params: 2,012,064\n",
      "Trainable params: 233,964\n",
      "Non-trainable params: 1,778,100\n",
      "_________________________________________________________________\n",
      "Train on 5219 samples, validate on 1305 samples\n",
      "Epoch 1/10\n",
      "5219/5219 [==============================] - 16s 3ms/step - loss: 0.1676 - categorical_accuracy: 0.5112 - val_loss: 0.0989 - val_categorical_accuracy: 0.7387\n",
      "Epoch 2/10\n",
      "5219/5219 [==============================] - 15s 3ms/step - loss: 0.0803 - categorical_accuracy: 0.7948 - val_loss: 0.0755 - val_categorical_accuracy: 0.8038\n",
      "Epoch 3/10\n",
      "5219/5219 [==============================] - 15s 3ms/step - loss: 0.0499 - categorical_accuracy: 0.8789 - val_loss: 0.0708 - val_categorical_accuracy: 0.8130\n",
      "Epoch 4/10\n",
      "5219/5219 [==============================] - 15s 3ms/step - loss: 0.0317 - categorical_accuracy: 0.9306 - val_loss: 0.0710 - val_categorical_accuracy: 0.8299\n",
      "Epoch 5/10\n",
      "5219/5219 [==============================] - 15s 3ms/step - loss: 0.0200 - categorical_accuracy: 0.9628 - val_loss: 0.0716 - val_categorical_accuracy: 0.8245\n",
      "Epoch 6/10\n",
      "5219/5219 [==============================] - 15s 3ms/step - loss: 0.0134 - categorical_accuracy: 0.9793 - val_loss: 0.0776 - val_categorical_accuracy: 0.8291\n",
      "Epoch 7/10\n",
      "5219/5219 [==============================] - 15s 3ms/step - loss: 0.0113 - categorical_accuracy: 0.9835 - val_loss: 0.0770 - val_categorical_accuracy: 0.8245\n",
      "Epoch 8/10\n",
      "5219/5219 [==============================] - 15s 3ms/step - loss: 0.0103 - categorical_accuracy: 0.9833 - val_loss: 0.0787 - val_categorical_accuracy: 0.8360\n",
      "Epoch 9/10\n",
      "5219/5219 [==============================] - 15s 3ms/step - loss: 0.0102 - categorical_accuracy: 0.9837 - val_loss: 0.0803 - val_categorical_accuracy: 0.8314\n",
      "Epoch 10/10\n",
      "5219/5219 [==============================] - 15s 3ms/step - loss: 0.0099 - categorical_accuracy: 0.9849 - val_loss: 0.0806 - val_categorical_accuracy: 0.8322\n",
      "CPU times: user 5 s, sys: 0 ns, total: 5 s\n",
      "Wall time: 9.06 s\n"
     ]
    }
   ],
   "source": [
    "y_pred = HCM.firstLevelModelTraining(sequences,sequences_test,embedding_matrix,650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 s, sys: 1e+03 ns, total: 6 s\n",
      "Wall time: 8.82 s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.71      0.77         7\n",
      "           1       0.47      0.22      0.30        37\n",
      "           2       0.63      0.79      0.70        72\n",
      "           3       1.00      0.70      0.82        10\n",
      "           4       0.75      0.85      0.80        61\n",
      "           5       0.76      0.67      0.71        39\n",
      "           6       0.71      0.77      0.74        13\n",
      "           7       0.32      0.57      0.41        35\n",
      "           8       1.00      0.95      0.97        19\n",
      "           9       0.50      0.43      0.46         7\n",
      "          10       0.94      0.94      0.94        78\n",
      "          11       0.47      0.23      0.31        30\n",
      "          12       0.00      0.00      0.00         6\n",
      "          13       0.50      0.69      0.58        13\n",
      "          14       0.60      0.39      0.48        38\n",
      "          15       0.33      0.17      0.22         6\n",
      "          16       1.00      0.25      0.40         8\n",
      "          17       0.66      0.81      0.73        48\n",
      "          18       0.87      0.95      0.91        56\n",
      "          19       0.73      0.85      0.79        13\n",
      "          20       0.54      0.51      0.52        71\n",
      "          21       0.96      0.85      0.90        26\n",
      "          22       0.93      0.74      0.82        19\n",
      "          23       0.27      0.30      0.29        20\n",
      "          24       0.00      0.00      0.00         9\n",
      "          25       0.95      0.95      0.95        44\n",
      "          26       0.75      0.50      0.60         6\n",
      "          27       0.53      0.30      0.38        30\n",
      "          28       0.64      0.83      0.72        30\n",
      "          29       0.86      0.68      0.76        28\n",
      "          30       0.81      0.65      0.72        40\n",
      "          31       0.40      0.74      0.52        23\n",
      "          32       0.79      0.78      0.79        79\n",
      "          33       0.68      0.45      0.54        29\n",
      "          34       0.67      0.71      0.69        14\n",
      "          35       0.00      0.00      0.00         8\n",
      "          36       0.53      0.60      0.56        30\n",
      "          37       0.44      0.64      0.52        92\n",
      "          38       0.75      0.30      0.43        10\n",
      "          39       0.43      0.56      0.48        36\n",
      "          40       0.75      0.75      0.75        20\n",
      "          41       0.50      0.50      0.50         4\n",
      "          42       0.76      0.86      0.81        44\n",
      "          43       0.64      0.64      0.64        14\n",
      "          44       0.79      0.73      0.76        15\n",
      "          45       0.86      0.79      0.82       218\n",
      "          46       0.64      0.66      0.65        62\n",
      "          47       0.67      0.25      0.36        16\n",
      "\n",
      "   micro avg       0.68      0.68      0.68      1633\n",
      "   macro avg       0.64      0.59      0.59      1633\n",
      "weighted avg       0.69      0.68      0.67      1633\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/justin/classification/app/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_nd = HCM.PredictSecondLevel(classifiers,y_pred ,sequences_test,650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_14 (Embedding)     (None, 650, 300)          1778100   \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 648, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_14 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 48)                12048     \n",
      "=================================================================\n",
      "Total params: 2,020,598\n",
      "Trainable params: 242,498\n",
      "Non-trainable params: 1,778,100\n",
      "_________________________________________________________________\n",
      "Train on 5219 samples, validate on 1305 samples\n",
      "Epoch 1/10\n",
      "5219/5219 [==============================] - 17s 3ms/step - loss: 0.0767 - categorical_accuracy: 0.3347 - val_loss: 0.0527 - val_categorical_accuracy: 0.5686\n",
      "Epoch 2/10\n",
      "5219/5219 [==============================] - 15s 3ms/step - loss: 0.0436 - categorical_accuracy: 0.6346 - val_loss: 0.0394 - val_categorical_accuracy: 0.6743\n",
      "Epoch 3/10\n",
      "5219/5219 [==============================] - 15s 3ms/step - loss: 0.0305 - categorical_accuracy: 0.7528 - val_loss: 0.0348 - val_categorical_accuracy: 0.6920\n",
      "Epoch 4/10\n",
      "5219/5219 [==============================] - 15s 3ms/step - loss: 0.0217 - categorical_accuracy: 0.8335 - val_loss: 0.0333 - val_categorical_accuracy: 0.7157\n",
      "Epoch 5/10\n",
      "5219/5219 [==============================] - 15s 3ms/step - loss: 0.0156 - categorical_accuracy: 0.8854 - val_loss: 0.0330 - val_categorical_accuracy: 0.7088\n",
      "Epoch 6/10\n",
      "5219/5219 [==============================] - 15s 3ms/step - loss: 0.0115 - categorical_accuracy: 0.9218 - val_loss: 0.0331 - val_categorical_accuracy: 0.7195\n",
      "Epoch 7/10\n",
      "5219/5219 [==============================] - 15s 3ms/step - loss: 0.0081 - categorical_accuracy: 0.9534 - val_loss: 0.0340 - val_categorical_accuracy: 0.7241\n",
      "Epoch 8/10\n",
      "5219/5219 [==============================] - 15s 3ms/step - loss: 0.0067 - categorical_accuracy: 0.9626 - val_loss: 0.0352 - val_categorical_accuracy: 0.7218\n",
      "Epoch 9/10\n",
      "5219/5219 [==============================] - 15s 3ms/step - loss: 0.0047 - categorical_accuracy: 0.9749 - val_loss: 0.0351 - val_categorical_accuracy: 0.7142\n",
      "Epoch 10/10\n",
      "5219/5219 [==============================] - 15s 3ms/step - loss: 0.0047 - categorical_accuracy: 0.9757 - val_loss: 0.0373 - val_categorical_accuracy: 0.7257\n",
      "CPU times: user 5 s, sys: 0 ns, total: 5 s\n",
      "Wall time: 9.3 s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.71      0.77         7\n",
      "           1       0.62      0.14      0.22        37\n",
      "           2       0.64      0.69      0.67        72\n",
      "           3       0.78      0.70      0.74        10\n",
      "           4       0.84      0.85      0.85        61\n",
      "           5       0.70      0.67      0.68        39\n",
      "           6       0.83      0.77      0.80        13\n",
      "           7       0.32      0.71      0.44        35\n",
      "           8       1.00      0.95      0.97        19\n",
      "           9       0.17      0.43      0.24         7\n",
      "          10       0.95      0.94      0.94        78\n",
      "          11       0.43      0.40      0.41        30\n",
      "          12       0.00      0.00      0.00         6\n",
      "          13       0.50      0.38      0.43        13\n",
      "          14       0.54      0.37      0.44        38\n",
      "          15       0.50      0.17      0.25         6\n",
      "          16       0.57      0.50      0.53         8\n",
      "          17       0.72      0.69      0.70        48\n",
      "          18       0.78      0.96      0.86        56\n",
      "          19       0.69      0.85      0.76        13\n",
      "          20       0.45      0.49      0.47        71\n",
      "          21       0.92      0.85      0.88        26\n",
      "          22       1.00      0.84      0.91        19\n",
      "          23       0.17      0.05      0.08        20\n",
      "          24       0.00      0.00      0.00         9\n",
      "          25       0.93      0.91      0.92        44\n",
      "          26       0.75      0.50      0.60         6\n",
      "          27       0.82      0.30      0.44        30\n",
      "          28       0.90      0.60      0.72        30\n",
      "          29       0.90      0.64      0.75        28\n",
      "          30       0.73      0.68      0.70        40\n",
      "          31       0.40      0.35      0.37        23\n",
      "          32       0.91      0.76      0.83        79\n",
      "          33       0.52      0.41      0.46        29\n",
      "          34       0.52      0.79      0.63        14\n",
      "          35       0.50      0.88      0.64         8\n",
      "          36       0.74      0.47      0.57        30\n",
      "          37       0.42      0.58      0.49        92\n",
      "          38       0.62      0.50      0.56        10\n",
      "          39       0.72      0.50      0.59        36\n",
      "          40       0.63      0.85      0.72        20\n",
      "          41       0.33      0.50      0.40         4\n",
      "          42       0.71      0.82      0.76        44\n",
      "          43       0.88      0.50      0.64        14\n",
      "          44       0.64      0.60      0.62        15\n",
      "          45       0.67      0.88      0.76       218\n",
      "          46       0.81      0.61      0.70        62\n",
      "          47       0.60      0.19      0.29        16\n",
      "\n",
      "   micro avg       0.67      0.67      0.67      1633\n",
      "   macro avg       0.64      0.58      0.59      1633\n",
      "weighted avg       0.68      0.67      0.66      1633\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/justin/classification/app/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_flat_nd = HCM.FlatApproach(sequences,sequences_test,embedding_matrix,650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "openData = OpenData(1)\n",
    "trainData,trainLabel,testData,testLabel = openData.openFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "HCM = HierarchicalModel(trainData,trainLabel,testData,testLabel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Vocabulary size : 4742 ----- \n",
      "\n",
      "----- Convert train and test data to sequences ----- \n",
      "\n",
      "----- Total unique words : %d -----\n",
      " 16399\n",
      "----- Convert train data to vector in second level ----- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "parenttoChildFeature,parenttoChildSubcategory, sequences, sequences_test = HCM.wordToSequence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Use 300 dimension word vector ---- \n",
      "\n",
      "Found 400,000 word vectors in GloVe.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = HCM.openGloveEmbeddingMatrix(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = HCM.creatEmeddingMatrix(embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (None, 500, 300)          1422600   \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 498, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_15 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 2)                 502       \n",
      "=================================================================\n",
      "Total params: 1,653,552\n",
      "Trainable params: 230,952\n",
      "Non-trainable params: 1,422,600\n",
      "_________________________________________________________________\n",
      "Train on 605 samples, validate on 152 samples\n",
      "Epoch 1/10\n",
      "605/605 [==============================] - 4s 7ms/step - loss: 0.2492 - categorical_accuracy: 0.9455 - val_loss: 0.1357 - val_categorical_accuracy: 0.9605\n",
      "Epoch 2/10\n",
      "605/605 [==============================] - 1s 2ms/step - loss: 0.0735 - categorical_accuracy: 0.9736 - val_loss: 0.1248 - val_categorical_accuracy: 0.9539\n",
      "Epoch 3/10\n",
      "605/605 [==============================] - 1s 2ms/step - loss: 0.0461 - categorical_accuracy: 0.9818 - val_loss: 0.1225 - val_categorical_accuracy: 0.9671\n",
      "Epoch 4/10\n",
      "605/605 [==============================] - 1s 2ms/step - loss: 0.0303 - categorical_accuracy: 0.9868 - val_loss: 0.0753 - val_categorical_accuracy: 0.9605\n",
      "Epoch 5/10\n",
      "605/605 [==============================] - 1s 2ms/step - loss: 0.0076 - categorical_accuracy: 1.0000 - val_loss: 0.1058 - val_categorical_accuracy: 0.9737\n",
      "Epoch 6/10\n",
      "605/605 [==============================] - 1s 2ms/step - loss: 0.0184 - categorical_accuracy: 0.9917 - val_loss: 0.0810 - val_categorical_accuracy: 0.9539\n",
      "Epoch 7/10\n",
      "605/605 [==============================] - 1s 2ms/step - loss: 0.0102 - categorical_accuracy: 0.9967 - val_loss: 0.0894 - val_categorical_accuracy: 0.9737\n",
      "Epoch 8/10\n",
      "605/605 [==============================] - 1s 2ms/step - loss: 0.0041 - categorical_accuracy: 0.9983 - val_loss: 0.1010 - val_categorical_accuracy: 0.9737\n",
      "Epoch 9/10\n",
      "605/605 [==============================] - 1s 2ms/step - loss: 0.0035 - categorical_accuracy: 0.9983 - val_loss: 0.0847 - val_categorical_accuracy: 0.9605\n",
      "Epoch 10/10\n",
      "605/605 [==============================] - 1s 2ms/step - loss: 0.0029 - categorical_accuracy: 1.0000 - val_loss: 0.0878 - val_categorical_accuracy: 0.9605\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_16 (Embedding)     (None, 500, 300)          1422600   \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 498, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_16 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 2)                 502       \n",
      "=================================================================\n",
      "Total params: 1,653,552\n",
      "Trainable params: 230,952\n",
      "Non-trainable params: 1,422,600\n",
      "_________________________________________________________________\n",
      "Train on 239 samples, validate on 60 samples\n",
      "Epoch 1/10\n",
      "239/239 [==============================] - 3s 14ms/step - loss: 1.1305 - categorical_accuracy: 0.5397 - val_loss: 0.1140 - val_categorical_accuracy: 0.9333\n",
      "Epoch 2/10\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.0580 - categorical_accuracy: 0.9749 - val_loss: 0.0522 - val_categorical_accuracy: 0.9833\n",
      "Epoch 3/10\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.0818 - categorical_accuracy: 0.9665 - val_loss: 0.0340 - val_categorical_accuracy: 0.9833\n",
      "Epoch 4/10\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.0445 - categorical_accuracy: 0.9833 - val_loss: 0.0075 - val_categorical_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.0089 - categorical_accuracy: 1.0000 - val_loss: 0.0057 - val_categorical_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.0071 - categorical_accuracy: 1.0000 - val_loss: 0.0053 - val_categorical_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.0058 - categorical_accuracy: 1.0000 - val_loss: 0.0032 - val_categorical_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.0057 - categorical_accuracy: 1.0000 - val_loss: 0.0016 - val_categorical_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.0017 - categorical_accuracy: 1.0000 - val_loss: 9.0120e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.0012 - categorical_accuracy: 1.0000 - val_loss: 5.4880e-04 - val_categorical_accuracy: 1.0000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_17 (Embedding)     (None, 500, 300)          1422600   \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 498, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_17 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 4)                 1004      \n",
      "=================================================================\n",
      "Total params: 1,654,054\n",
      "Trainable params: 231,454\n",
      "Non-trainable params: 1,422,600\n",
      "_________________________________________________________________\n",
      "Train on 359 samples, validate on 90 samples\n",
      "Epoch 1/10\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.4493 - categorical_accuracy: 0.5877 - val_loss: 0.2809 - val_categorical_accuracy: 0.8222\n",
      "Epoch 2/10\n",
      "359/359 [==============================] - 1s 2ms/step - loss: 0.1748 - categorical_accuracy: 0.8663 - val_loss: 0.1326 - val_categorical_accuracy: 0.8444\n",
      "Epoch 3/10\n",
      "359/359 [==============================] - 1s 2ms/step - loss: 0.0623 - categorical_accuracy: 0.9582 - val_loss: 0.0641 - val_categorical_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "359/359 [==============================] - 1s 2ms/step - loss: 0.0524 - categorical_accuracy: 0.9749 - val_loss: 0.0250 - val_categorical_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "359/359 [==============================] - 1s 2ms/step - loss: 0.0119 - categorical_accuracy: 1.0000 - val_loss: 0.0212 - val_categorical_accuracy: 0.9778\n",
      "Epoch 6/10\n",
      "359/359 [==============================] - 1s 2ms/step - loss: 0.0100 - categorical_accuracy: 0.9944 - val_loss: 0.0167 - val_categorical_accuracy: 0.9889\n",
      "Epoch 7/10\n",
      "359/359 [==============================] - 1s 2ms/step - loss: 0.0053 - categorical_accuracy: 0.9972 - val_loss: 0.0125 - val_categorical_accuracy: 0.9889\n",
      "Epoch 8/10\n",
      "359/359 [==============================] - 1s 2ms/step - loss: 0.0026 - categorical_accuracy: 1.0000 - val_loss: 0.0079 - val_categorical_accuracy: 0.9889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "359/359 [==============================] - 1s 2ms/step - loss: 0.0015 - categorical_accuracy: 1.0000 - val_loss: 0.0049 - val_categorical_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "359/359 [==============================] - 1s 2ms/step - loss: 0.0019 - categorical_accuracy: 1.0000 - val_loss: 0.0035 - val_categorical_accuracy: 1.0000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_18 (Embedding)     (None, 500, 300)          1422600   \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 498, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_18 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 3)                 753       \n",
      "=================================================================\n",
      "Total params: 1,653,803\n",
      "Trainable params: 231,203\n",
      "Non-trainable params: 1,422,600\n",
      "_________________________________________________________________\n",
      "Train on 3868 samples, validate on 968 samples\n",
      "Epoch 1/10\n",
      "3868/3868 [==============================] - 12s 3ms/step - loss: 0.4087 - categorical_accuracy: 0.7528 - val_loss: 0.2383 - val_categorical_accuracy: 0.8492\n",
      "Epoch 2/10\n",
      "3868/3868 [==============================] - 9s 2ms/step - loss: 0.1860 - categorical_accuracy: 0.8886 - val_loss: 0.1792 - val_categorical_accuracy: 0.9029\n",
      "Epoch 3/10\n",
      "3868/3868 [==============================] - 9s 2ms/step - loss: 0.1205 - categorical_accuracy: 0.9364 - val_loss: 0.1577 - val_categorical_accuracy: 0.9050\n",
      "Epoch 4/10\n",
      "3868/3868 [==============================] - 8s 2ms/step - loss: 0.0780 - categorical_accuracy: 0.9638 - val_loss: 0.1275 - val_categorical_accuracy: 0.9246\n",
      "Epoch 5/10\n",
      "3868/3868 [==============================] - 9s 2ms/step - loss: 0.0512 - categorical_accuracy: 0.9793 - val_loss: 0.1212 - val_categorical_accuracy: 0.9298\n",
      "Epoch 6/10\n",
      "3868/3868 [==============================] - 8s 2ms/step - loss: 0.0380 - categorical_accuracy: 0.9845 - val_loss: 0.1347 - val_categorical_accuracy: 0.9246\n",
      "Epoch 7/10\n",
      "3868/3868 [==============================] - 8s 2ms/step - loss: 0.0295 - categorical_accuracy: 0.9889 - val_loss: 0.1181 - val_categorical_accuracy: 0.9360\n",
      "Epoch 8/10\n",
      "3868/3868 [==============================] - 8s 2ms/step - loss: 0.0206 - categorical_accuracy: 0.9910 - val_loss: 0.1303 - val_categorical_accuracy: 0.9339\n",
      "Epoch 9/10\n",
      "3868/3868 [==============================] - 9s 2ms/step - loss: 0.0138 - categorical_accuracy: 0.9948 - val_loss: 0.1559 - val_categorical_accuracy: 0.9298\n",
      "Epoch 10/10\n",
      "3868/3868 [==============================] - 8s 2ms/step - loss: 0.0119 - categorical_accuracy: 0.9951 - val_loss: 0.1426 - val_categorical_accuracy: 0.9349\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_19 (Embedding)     (None, 500, 300)          1422600   \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 498, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_19 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 3)                 753       \n",
      "=================================================================\n",
      "Total params: 1,653,803\n",
      "Trainable params: 231,203\n",
      "Non-trainable params: 1,422,600\n",
      "_________________________________________________________________\n",
      "Train on 333 samples, validate on 84 samples\n",
      "Epoch 1/10\n",
      "333/333 [==============================] - 4s 11ms/step - loss: 0.5163 - categorical_accuracy: 0.5616 - val_loss: 0.0879 - val_categorical_accuracy: 0.9762\n",
      "Epoch 2/10\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.1402 - categorical_accuracy: 0.9339 - val_loss: 0.0316 - val_categorical_accuracy: 0.9881\n",
      "Epoch 3/10\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.0868 - categorical_accuracy: 0.9700 - val_loss: 0.0121 - val_categorical_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.0665 - categorical_accuracy: 0.9820 - val_loss: 0.0074 - val_categorical_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.0457 - categorical_accuracy: 0.9880 - val_loss: 0.0062 - val_categorical_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.0458 - categorical_accuracy: 0.9910 - val_loss: 0.0039 - val_categorical_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.0393 - categorical_accuracy: 0.9940 - val_loss: 0.0015 - val_categorical_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.0372 - categorical_accuracy: 0.9940 - val_loss: 0.0014 - val_categorical_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.0363 - categorical_accuracy: 0.9940 - val_loss: 9.9875e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "333/333 [==============================] - 1s 2ms/step - loss: 0.0372 - categorical_accuracy: 0.9940 - val_loss: 5.2718e-04 - val_categorical_accuracy: 1.0000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_20 (Embedding)     (None, 500, 300)          1422600   \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 498, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_20 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 3)                 753       \n",
      "=================================================================\n",
      "Total params: 1,653,803\n",
      "Trainable params: 231,203\n",
      "Non-trainable params: 1,422,600\n",
      "_________________________________________________________________\n",
      "Train on 726 samples, validate on 182 samples\n",
      "Epoch 1/10\n",
      "726/726 [==============================] - 5s 7ms/step - loss: 0.6528 - categorical_accuracy: 0.5702 - val_loss: 0.5060 - val_categorical_accuracy: 0.7143\n",
      "Epoch 2/10\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.3498 - categorical_accuracy: 0.7837 - val_loss: 0.4355 - val_categorical_accuracy: 0.7308\n",
      "Epoch 3/10\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.2695 - categorical_accuracy: 0.8251 - val_loss: 0.3138 - val_categorical_accuracy: 0.7802\n",
      "Epoch 4/10\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.2006 - categorical_accuracy: 0.8705 - val_loss: 0.2411 - val_categorical_accuracy: 0.8571\n",
      "Epoch 5/10\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.1317 - categorical_accuracy: 0.9174 - val_loss: 0.1807 - val_categorical_accuracy: 0.8736\n",
      "Epoch 6/10\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.0931 - categorical_accuracy: 0.9435 - val_loss: 0.1635 - val_categorical_accuracy: 0.8956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.0783 - categorical_accuracy: 0.9601 - val_loss: 0.1364 - val_categorical_accuracy: 0.9121\n",
      "Epoch 8/10\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.0607 - categorical_accuracy: 0.9725 - val_loss: 0.1512 - val_categorical_accuracy: 0.9231\n",
      "Epoch 9/10\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.0529 - categorical_accuracy: 0.9711 - val_loss: 0.1120 - val_categorical_accuracy: 0.9451\n",
      "Epoch 10/10\n",
      "726/726 [==============================] - 2s 2ms/step - loss: 0.0400 - categorical_accuracy: 0.9835 - val_loss: 0.1199 - val_categorical_accuracy: 0.9286\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_21 (Embedding)     (None, 500, 300)          1422600   \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 498, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_21 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 4)                 1004      \n",
      "=================================================================\n",
      "Total params: 1,654,054\n",
      "Trainable params: 231,454\n",
      "Non-trainable params: 1,422,600\n",
      "_________________________________________________________________\n",
      "Train on 375 samples, validate on 94 samples\n",
      "Epoch 1/10\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.5431 - categorical_accuracy: 0.4507 - val_loss: 0.4948 - val_categorical_accuracy: 0.6702\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3524 - categorical_accuracy: 0.6907 - val_loss: 0.2980 - val_categorical_accuracy: 0.7128\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2133 - categorical_accuracy: 0.7973 - val_loss: 0.2039 - val_categorical_accuracy: 0.8298\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1556 - categorical_accuracy: 0.8933 - val_loss: 0.1381 - val_categorical_accuracy: 0.8830\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1059 - categorical_accuracy: 0.9093 - val_loss: 0.1444 - val_categorical_accuracy: 0.8723\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0847 - categorical_accuracy: 0.9333 - val_loss: 0.1085 - val_categorical_accuracy: 0.8936\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0518 - categorical_accuracy: 0.9760 - val_loss: 0.1010 - val_categorical_accuracy: 0.8936\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0466 - categorical_accuracy: 0.9733 - val_loss: 0.0892 - val_categorical_accuracy: 0.9043\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0334 - categorical_accuracy: 0.9867 - val_loss: 0.0861 - val_categorical_accuracy: 0.9149\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0207 - categorical_accuracy: 0.9920 - val_loss: 0.0863 - val_categorical_accuracy: 0.9149\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_22 (Embedding)     (None, 500, 300)          1422600   \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 498, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_22 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 4)                 1004      \n",
      "=================================================================\n",
      "Total params: 1,654,054\n",
      "Trainable params: 231,454\n",
      "Non-trainable params: 1,422,600\n",
      "_________________________________________________________________\n",
      "Train on 316 samples, validate on 80 samples\n",
      "Epoch 1/10\n",
      "316/316 [==============================] - 4s 13ms/step - loss: 0.7598 - categorical_accuracy: 0.3956 - val_loss: 0.4180 - val_categorical_accuracy: 0.7375\n",
      "Epoch 2/10\n",
      "316/316 [==============================] - 1s 2ms/step - loss: 0.4809 - categorical_accuracy: 0.7373 - val_loss: 0.2055 - val_categorical_accuracy: 0.9000\n",
      "Epoch 3/10\n",
      "316/316 [==============================] - 1s 2ms/step - loss: 0.2715 - categorical_accuracy: 0.8259 - val_loss: 0.0600 - val_categorical_accuracy: 0.9500\n",
      "Epoch 4/10\n",
      "316/316 [==============================] - 1s 2ms/step - loss: 0.0691 - categorical_accuracy: 0.9684 - val_loss: 0.0602 - val_categorical_accuracy: 0.9500\n",
      "Epoch 5/10\n",
      "316/316 [==============================] - 1s 2ms/step - loss: 0.0519 - categorical_accuracy: 0.9810 - val_loss: 0.0199 - val_categorical_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "316/316 [==============================] - 1s 2ms/step - loss: 0.0149 - categorical_accuracy: 0.9937 - val_loss: 0.0032 - val_categorical_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "316/316 [==============================] - 1s 2ms/step - loss: 0.0051 - categorical_accuracy: 1.0000 - val_loss: 0.0013 - val_categorical_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "316/316 [==============================] - 1s 2ms/step - loss: 0.0032 - categorical_accuracy: 1.0000 - val_loss: 8.0277e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "316/316 [==============================] - 1s 2ms/step - loss: 0.0021 - categorical_accuracy: 1.0000 - val_loss: 5.5843e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "316/316 [==============================] - 1s 2ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 4.0102e-04 - val_categorical_accuracy: 1.0000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_23 (Embedding)     (None, 500, 300)          1422600   \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 498, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_23 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 3)                 753       \n",
      "=================================================================\n",
      "Total params: 1,653,803\n",
      "Trainable params: 231,203\n",
      "Non-trainable params: 1,422,600\n",
      "_________________________________________________________________\n",
      "Train on 1499 samples, validate on 375 samples\n",
      "Epoch 1/10\n",
      "1499/1499 [==============================] - 7s 4ms/step - loss: 0.3286 - categorical_accuracy: 0.8225 - val_loss: 0.0501 - val_categorical_accuracy: 0.9707\n",
      "Epoch 2/10\n",
      "1499/1499 [==============================] - 3s 2ms/step - loss: 0.0226 - categorical_accuracy: 0.9900 - val_loss: 0.0053 - val_categorical_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "1499/1499 [==============================] - 3s 2ms/step - loss: 0.0025 - categorical_accuracy: 0.9993 - val_loss: 0.0014 - val_categorical_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "1499/1499 [==============================] - 3s 2ms/step - loss: 0.0011 - categorical_accuracy: 0.9993 - val_loss: 7.7616e-04 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "1499/1499 [==============================] - 3s 2ms/step - loss: 4.1891e-04 - categorical_accuracy: 1.0000 - val_loss: 5.9461e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1499/1499 [==============================] - 3s 2ms/step - loss: 3.0026e-04 - categorical_accuracy: 1.0000 - val_loss: 5.9537e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1499/1499 [==============================] - 3s 2ms/step - loss: 3.0456e-04 - categorical_accuracy: 1.0000 - val_loss: 5.2667e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1499/1499 [==============================] - 3s 2ms/step - loss: 2.0801e-04 - categorical_accuracy: 1.0000 - val_loss: 4.5642e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1499/1499 [==============================] - 3s 2ms/step - loss: 1.7581e-04 - categorical_accuracy: 1.0000 - val_loss: 4.2950e-04 - val_categorical_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1499/1499 [==============================] - 3s 2ms/step - loss: 2.5475e-04 - categorical_accuracy: 1.0000 - val_loss: 3.7729e-04 - val_categorical_accuracy: 1.0000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_24 (Embedding)     (None, 500, 300)          1422600   \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 498, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_24 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 4)                 1004      \n",
      "=================================================================\n",
      "Total params: 1,654,054\n",
      "Trainable params: 231,454\n",
      "Non-trainable params: 1,422,600\n",
      "_________________________________________________________________\n",
      "Train on 280 samples, validate on 71 samples\n",
      "Epoch 1/10\n",
      "280/280 [==============================] - 4s 15ms/step - loss: 0.8681 - categorical_accuracy: 0.3679 - val_loss: 0.7906 - val_categorical_accuracy: 0.4789\n",
      "Epoch 2/10\n",
      "280/280 [==============================] - 1s 2ms/step - loss: 0.5686 - categorical_accuracy: 0.6536 - val_loss: 0.4822 - val_categorical_accuracy: 0.7042\n",
      "Epoch 3/10\n",
      "280/280 [==============================] - 1s 2ms/step - loss: 0.3958 - categorical_accuracy: 0.7179 - val_loss: 0.2799 - val_categorical_accuracy: 0.7324\n",
      "Epoch 4/10\n",
      "280/280 [==============================] - 1s 2ms/step - loss: 0.1707 - categorical_accuracy: 0.8643 - val_loss: 0.1224 - val_categorical_accuracy: 0.9155\n",
      "Epoch 5/10\n",
      "280/280 [==============================] - 1s 2ms/step - loss: 0.0888 - categorical_accuracy: 0.9286 - val_loss: 0.1248 - val_categorical_accuracy: 0.9014\n",
      "Epoch 6/10\n",
      "280/280 [==============================] - 1s 2ms/step - loss: 0.0682 - categorical_accuracy: 0.9393 - val_loss: 0.0469 - val_categorical_accuracy: 0.9718\n",
      "Epoch 7/10\n",
      "280/280 [==============================] - 1s 2ms/step - loss: 0.0245 - categorical_accuracy: 0.9964 - val_loss: 0.0240 - val_categorical_accuracy: 0.9859\n",
      "Epoch 8/10\n",
      "280/280 [==============================] - 1s 2ms/step - loss: 0.0109 - categorical_accuracy: 0.9964 - val_loss: 0.0227 - val_categorical_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "280/280 [==============================] - 1s 2ms/step - loss: 0.0098 - categorical_accuracy: 1.0000 - val_loss: 0.0202 - val_categorical_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "280/280 [==============================] - 1s 2ms/step - loss: 0.0083 - categorical_accuracy: 1.0000 - val_loss: 0.0165 - val_categorical_accuracy: 1.0000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_25 (Embedding)     (None, 500, 300)          1422600   \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 498, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_25 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 2)                 502       \n",
      "=================================================================\n",
      "Total params: 1,653,552\n",
      "Trainable params: 230,952\n",
      "Non-trainable params: 1,422,600\n",
      "_________________________________________________________________\n",
      "Train on 621 samples, validate on 156 samples\n",
      "Epoch 1/10\n",
      "621/621 [==============================] - 5s 8ms/step - loss: 0.8712 - categorical_accuracy: 0.7359 - val_loss: 0.2314 - val_categorical_accuracy: 0.9615\n",
      "Epoch 2/10\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.2762 - categorical_accuracy: 0.8728 - val_loss: 0.1059 - val_categorical_accuracy: 0.9295\n",
      "Epoch 3/10\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.0988 - categorical_accuracy: 0.9517 - val_loss: 0.0242 - val_categorical_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.0413 - categorical_accuracy: 0.9871 - val_loss: 0.0202 - val_categorical_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.0169 - categorical_accuracy: 0.9968 - val_loss: 0.0103 - val_categorical_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.0141 - categorical_accuracy: 0.9968 - val_loss: 0.0110 - val_categorical_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.0065 - categorical_accuracy: 1.0000 - val_loss: 0.0058 - val_categorical_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.0067 - categorical_accuracy: 0.9984 - val_loss: 0.0048 - val_categorical_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.0059 - categorical_accuracy: 0.9984 - val_loss: 0.0046 - val_categorical_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "621/621 [==============================] - 1s 2ms/step - loss: 0.0030 - categorical_accuracy: 1.0000 - val_loss: 0.0048 - val_categorical_accuracy: 1.0000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_26 (Embedding)     (None, 500, 300)          1422600   \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 498, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_26 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 3)                 753       \n",
      "=================================================================\n",
      "Total params: 1,653,803\n",
      "Trainable params: 231,203\n",
      "Non-trainable params: 1,422,600\n",
      "_________________________________________________________________\n",
      "Train on 76 samples, validate on 20 samples\n",
      "Epoch 1/10\n",
      "76/76 [==============================] - 4s 51ms/step - loss: 1.2259 - categorical_accuracy: 0.1711 - val_loss: 0.6715 - val_categorical_accuracy: 0.6500\n",
      "Epoch 2/10\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.6118 - categorical_accuracy: 0.6053 - val_loss: 0.9378 - val_categorical_accuracy: 0.6500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.7682 - categorical_accuracy: 0.7237 - val_loss: 0.8282 - val_categorical_accuracy: 0.8000\n",
      "Epoch 4/10\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.7087 - categorical_accuracy: 0.8158 - val_loss: 0.8329 - val_categorical_accuracy: 0.8000\n",
      "Epoch 5/10\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.6999 - categorical_accuracy: 0.8158 - val_loss: 0.8377 - val_categorical_accuracy: 0.8000\n",
      "Epoch 6/10\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.6480 - categorical_accuracy: 0.8289 - val_loss: 0.8338 - val_categorical_accuracy: 0.8000\n",
      "Epoch 7/10\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.6364 - categorical_accuracy: 0.8289 - val_loss: 0.7239 - val_categorical_accuracy: 0.8000\n",
      "Epoch 8/10\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5416 - categorical_accuracy: 0.8421 - val_loss: 0.5810 - val_categorical_accuracy: 0.8000\n",
      "Epoch 9/10\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4310 - categorical_accuracy: 0.8421 - val_loss: 0.4619 - val_categorical_accuracy: 0.8000\n",
      "Epoch 10/10\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.3628 - categorical_accuracy: 0.8421 - val_loss: 0.3477 - val_categorical_accuracy: 0.8000\n"
     ]
    }
   ],
   "source": [
    "classifiers= HCM.subclassifiers(parenttoChildFeature,parenttoChildSubcategory,embedding_matrix,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_27 (Embedding)     (None, 500, 300)          1422600   \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 498, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_27 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 18)                4518      \n",
      "=================================================================\n",
      "Total params: 1,657,568\n",
      "Trainable params: 234,968\n",
      "Non-trainable params: 1,422,600\n",
      "_________________________________________________________________\n",
      "Train on 9911 samples, validate on 2478 samples\n",
      "Epoch 1/10\n",
      "9911/9911 [==============================] - 26s 3ms/step - loss: 0.0394 - categorical_accuracy: 0.8759 - val_loss: 0.0076 - val_categorical_accuracy: 0.9790\n",
      "Epoch 2/10\n",
      "9911/9911 [==============================] - 22s 2ms/step - loss: 0.0051 - categorical_accuracy: 0.9879 - val_loss: 0.0051 - val_categorical_accuracy: 0.9826\n",
      "Epoch 3/10\n",
      "9911/9911 [==============================] - 22s 2ms/step - loss: 0.0029 - categorical_accuracy: 0.9923 - val_loss: 0.0032 - val_categorical_accuracy: 0.9875\n",
      "Epoch 4/10\n",
      "9911/9911 [==============================] - 22s 2ms/step - loss: 0.0016 - categorical_accuracy: 0.9958 - val_loss: 0.0034 - val_categorical_accuracy: 0.9879\n",
      "Epoch 5/10\n",
      "9911/9911 [==============================] - 22s 2ms/step - loss: 0.0019 - categorical_accuracy: 0.9947 - val_loss: 0.0037 - val_categorical_accuracy: 0.9875\n",
      "Epoch 6/10\n",
      "9911/9911 [==============================] - 22s 2ms/step - loss: 0.0011 - categorical_accuracy: 0.9969 - val_loss: 0.0028 - val_categorical_accuracy: 0.9907\n",
      "Epoch 7/10\n",
      "9911/9911 [==============================] - 22s 2ms/step - loss: 9.2252e-04 - categorical_accuracy: 0.9973 - val_loss: 0.0052 - val_categorical_accuracy: 0.9843\n",
      "Epoch 8/10\n",
      "9911/9911 [==============================] - 22s 2ms/step - loss: 9.6387e-04 - categorical_accuracy: 0.9975 - val_loss: 0.0033 - val_categorical_accuracy: 0.9895\n",
      "Epoch 9/10\n",
      "9911/9911 [==============================] - 23s 2ms/step - loss: 9.5279e-04 - categorical_accuracy: 0.9975 - val_loss: 0.0039 - val_categorical_accuracy: 0.9879\n",
      "Epoch 10/10\n",
      "9911/9911 [==============================] - 22s 2ms/step - loss: 0.0012 - categorical_accuracy: 0.9969 - val_loss: 0.0051 - val_categorical_accuracy: 0.9891\n",
      "CPU times: user 6 s, sys: 0 ns, total: 6 s\n",
      "Wall time: 10.3 s\n"
     ]
    }
   ],
   "source": [
    "y_pred = HCM.firstLevelModelTraining(sequences,sequences_test,embedding_matrix,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 s, sys: 1e+03 ns, total: 7 s\n",
      "Wall time: 12.2 s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        30\n",
      "           1       0.97      0.99      0.98       152\n",
      "           2       1.00      1.00      1.00        42\n",
      "           3       1.00      1.00      1.00        35\n",
      "           4       1.00      0.98      0.99       125\n",
      "           5       1.00      1.00      1.00        14\n",
      "           6       1.00      1.00      1.00        34\n",
      "           7       1.00      1.00      1.00        12\n",
      "           8       1.00      1.00      1.00        13\n",
      "           9       0.89      0.73      0.80        11\n",
      "          10       1.00      1.00      1.00        53\n",
      "          11       0.00      0.00      0.00         5\n",
      "          12       1.00      1.00      1.00        13\n",
      "          13       1.00      1.00      1.00        29\n",
      "          14       1.00      1.00      1.00        21\n",
      "          15       1.00      1.00      1.00        15\n",
      "          16       1.00      0.91      0.95        11\n",
      "          17       0.98      1.00      0.99        61\n",
      "          18       0.84      0.93      0.88        40\n",
      "          19       0.93      0.87      0.90        15\n",
      "          20       0.80      0.68      0.73        99\n",
      "          21       1.00      1.00      1.00        16\n",
      "          22       0.93      1.00      0.97        57\n",
      "          23       1.00      1.00      1.00         9\n",
      "          24       1.00      1.00      1.00        11\n",
      "          25       0.82      1.00      0.90         9\n",
      "          26       0.91      0.95      0.93       349\n",
      "          27       0.89      0.85      0.87        59\n",
      "          28       0.98      0.91      0.94        44\n",
      "          29       1.00      1.00      1.00       332\n",
      "          30       1.00      1.00      1.00        46\n",
      "          31       0.82      1.00      0.90         9\n",
      "          32       0.95      0.98      0.96        55\n",
      "          33       0.86      0.80      0.83        40\n",
      "          34       0.65      0.75      0.70        20\n",
      "          35       0.99      0.99      0.99       155\n",
      "          36       1.00      1.00      1.00        67\n",
      "          37       0.98      1.00      0.99        46\n",
      "          38       0.96      0.96      0.96       783\n",
      "          39       0.93      0.96      0.95       134\n",
      "          40       1.00      1.00      1.00        27\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      3098\n",
      "   macro avg       0.93      0.93      0.93      3098\n",
      "weighted avg       0.95      0.96      0.95      3098\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/justin/classification/app/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_nd = HCM.PredictSecondLevel(classifiers,y_pred ,sequences_test,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_28 (Embedding)     (None, 500, 300)          1422600   \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 498, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_28 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 41)                10291     \n",
      "=================================================================\n",
      "Total params: 1,663,341\n",
      "Trainable params: 240,741\n",
      "Non-trainable params: 1,422,600\n",
      "_________________________________________________________________\n",
      "Train on 9911 samples, validate on 2478 samples\n",
      "Epoch 1/10\n",
      "9911/9911 [==============================] - 26s 3ms/step - loss: 0.0344 - categorical_accuracy: 0.7481 - val_loss: 0.0132 - val_categorical_accuracy: 0.9023\n",
      "Epoch 2/10\n",
      "9911/9911 [==============================] - 22s 2ms/step - loss: 0.0094 - categorical_accuracy: 0.9286 - val_loss: 0.0084 - val_categorical_accuracy: 0.9399\n",
      "Epoch 3/10\n",
      "9911/9911 [==============================] - 22s 2ms/step - loss: 0.0055 - categorical_accuracy: 0.9609 - val_loss: 0.0081 - val_categorical_accuracy: 0.9391\n",
      "Epoch 4/10\n",
      "9911/9911 [==============================] - 22s 2ms/step - loss: 0.0036 - categorical_accuracy: 0.9767 - val_loss: 0.0076 - val_categorical_accuracy: 0.9447\n",
      "Epoch 5/10\n",
      "9911/9911 [==============================] - 22s 2ms/step - loss: 0.0027 - categorical_accuracy: 0.9813 - val_loss: 0.0068 - val_categorical_accuracy: 0.9508\n",
      "Epoch 6/10\n",
      "9911/9911 [==============================] - 22s 2ms/step - loss: 0.0021 - categorical_accuracy: 0.9855 - val_loss: 0.0088 - val_categorical_accuracy: 0.9419\n",
      "Epoch 7/10\n",
      "9911/9911 [==============================] - 22s 2ms/step - loss: 0.0018 - categorical_accuracy: 0.9886 - val_loss: 0.0080 - val_categorical_accuracy: 0.9552\n",
      "Epoch 8/10\n",
      "9911/9911 [==============================] - 22s 2ms/step - loss: 0.0013 - categorical_accuracy: 0.9921 - val_loss: 0.0077 - val_categorical_accuracy: 0.9564\n",
      "Epoch 9/10\n",
      "9911/9911 [==============================] - 22s 2ms/step - loss: 0.0012 - categorical_accuracy: 0.9924 - val_loss: 0.0086 - val_categorical_accuracy: 0.9528\n",
      "Epoch 10/10\n",
      "9911/9911 [==============================] - 22s 2ms/step - loss: 0.0014 - categorical_accuracy: 0.9899 - val_loss: 0.0100 - val_categorical_accuracy: 0.9443\n",
      "CPU times: user 5 s, sys: 1e+03 ns, total: 6 s\n",
      "Wall time: 9.06 s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        30\n",
      "           1       0.97      0.99      0.98       152\n",
      "           2       1.00      1.00      1.00        42\n",
      "           3       1.00      0.91      0.96        35\n",
      "           4       0.99      0.98      0.98       125\n",
      "           5       1.00      1.00      1.00        14\n",
      "           6       1.00      1.00      1.00        34\n",
      "           7       1.00      0.92      0.96        12\n",
      "           8       1.00      1.00      1.00        13\n",
      "           9       0.73      0.73      0.73        11\n",
      "          10       1.00      1.00      1.00        53\n",
      "          11       1.00      1.00      1.00         5\n",
      "          12       1.00      1.00      1.00        13\n",
      "          13       1.00      1.00      1.00        29\n",
      "          14       1.00      1.00      1.00        21\n",
      "          15       1.00      1.00      1.00        15\n",
      "          16       1.00      1.00      1.00        11\n",
      "          17       1.00      1.00      1.00        61\n",
      "          18       0.88      0.90      0.89        40\n",
      "          19       1.00      0.80      0.89        15\n",
      "          20       0.82      0.65      0.72        99\n",
      "          21       1.00      0.94      0.97        16\n",
      "          22       0.98      0.96      0.97        57\n",
      "          23       1.00      1.00      1.00         9\n",
      "          24       1.00      1.00      1.00        11\n",
      "          25       1.00      1.00      1.00         9\n",
      "          26       0.79      0.98      0.88       349\n",
      "          27       0.95      0.71      0.82        59\n",
      "          28       0.95      0.91      0.93        44\n",
      "          29       1.00      1.00      1.00       332\n",
      "          30       1.00      1.00      1.00        46\n",
      "          31       1.00      1.00      1.00         9\n",
      "          32       1.00      1.00      1.00        55\n",
      "          33       0.96      0.68      0.79        40\n",
      "          34       0.59      0.95      0.73        20\n",
      "          35       0.99      1.00      0.99       155\n",
      "          36       1.00      1.00      1.00        67\n",
      "          37       1.00      1.00      1.00        46\n",
      "          38       0.98      0.91      0.94       783\n",
      "          39       0.88      0.99      0.93       134\n",
      "          40       1.00      1.00      1.00        27\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      3098\n",
      "   macro avg       0.96      0.95      0.95      3098\n",
      "weighted avg       0.95      0.94      0.94      3098\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_flat_nd = HCM.FlatApproach(sequences,sequences_test,embedding_matrix,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "openData = OpenData(2)\n",
    "trainData,trainLabel,testData,testLabel = openData.openFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "HCM = HierarchicalModel(trainData,trainLabel,testData,testLabel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Vocabulary size : 9848 ----- \n",
      "\n",
      "----- Convert train and test data to sequences ----- \n",
      "\n",
      "----- Total unique words : %d -----\n",
      " 37793\n",
      "----- Convert train data to vector in second level ----- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "parenttoChildFeature,parenttoChildSubcategory, sequences, sequences_test = HCM.wordToSequence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Use 300 dimension word vector ---- \n",
      "\n",
      "Found 400,000 word vectors in GloVe.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = HCM.openGloveEmbeddingMatrix(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = HCM.creatEmeddingMatrix(embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_29 (Embedding)     (None, 1100, 300)         2954400   \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 1098, 200)         180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_29 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 2)                 502       \n",
      "=================================================================\n",
      "Total params: 3,185,352\n",
      "Trainable params: 230,952\n",
      "Non-trainable params: 2,954,400\n",
      "_________________________________________________________________\n",
      "Train on 655 samples, validate on 164 samples\n",
      "Epoch 1/10\n",
      "655/655 [==============================] - 8s 12ms/step - loss: 0.3864 - categorical_accuracy: 0.9099 - val_loss: 0.3340 - val_categorical_accuracy: 0.7561\n",
      "Epoch 2/10\n",
      "655/655 [==============================] - 3s 5ms/step - loss: 0.2253 - categorical_accuracy: 0.9191 - val_loss: 0.1223 - val_categorical_accuracy: 0.9390\n",
      "Epoch 3/10\n",
      "655/655 [==============================] - 3s 5ms/step - loss: 0.1195 - categorical_accuracy: 0.9557 - val_loss: 0.0637 - val_categorical_accuracy: 0.9817\n",
      "Epoch 4/10\n",
      "655/655 [==============================] - 3s 5ms/step - loss: 0.0779 - categorical_accuracy: 0.9679 - val_loss: 0.0494 - val_categorical_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "655/655 [==============================] - 3s 5ms/step - loss: 0.0562 - categorical_accuracy: 0.9863 - val_loss: 0.0417 - val_categorical_accuracy: 0.9939\n",
      "Epoch 6/10\n",
      "655/655 [==============================] - 3s 5ms/step - loss: 0.0346 - categorical_accuracy: 0.9924 - val_loss: 0.0376 - val_categorical_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "655/655 [==============================] - 3s 5ms/step - loss: 0.0245 - categorical_accuracy: 0.9954 - val_loss: 0.0342 - val_categorical_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "655/655 [==============================] - 3s 5ms/step - loss: 0.0194 - categorical_accuracy: 0.9954 - val_loss: 0.0297 - val_categorical_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "655/655 [==============================] - 3s 5ms/step - loss: 0.0128 - categorical_accuracy: 0.9969 - val_loss: 0.0266 - val_categorical_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "655/655 [==============================] - 3s 5ms/step - loss: 0.0115 - categorical_accuracy: 0.9969 - val_loss: 0.0286 - val_categorical_accuracy: 0.9939\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_30 (Embedding)     (None, 1100, 300)         2954400   \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 1098, 200)         180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_30 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 2)                 502       \n",
      "=================================================================\n",
      "Total params: 3,185,352\n",
      "Trainable params: 230,952\n",
      "Non-trainable params: 2,954,400\n",
      "_________________________________________________________________\n",
      "Train on 312 samples, validate on 79 samples\n",
      "Epoch 1/10\n",
      "312/312 [==============================] - 7s 22ms/step - loss: 0.4876 - categorical_accuracy: 0.8269 - val_loss: 0.2983 - val_categorical_accuracy: 0.8481\n",
      "Epoch 2/10\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.2330 - categorical_accuracy: 0.9103 - val_loss: 0.2189 - val_categorical_accuracy: 0.9241\n",
      "Epoch 3/10\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.2306 - categorical_accuracy: 0.9359 - val_loss: 0.1524 - val_categorical_accuracy: 0.9367\n",
      "Epoch 4/10\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.0781 - categorical_accuracy: 0.9583 - val_loss: 0.4811 - val_categorical_accuracy: 0.8734\n",
      "Epoch 5/10\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.1601 - categorical_accuracy: 0.9263 - val_loss: 0.1496 - val_categorical_accuracy: 0.9114\n",
      "Epoch 6/10\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.0221 - categorical_accuracy: 0.9968 - val_loss: 0.1190 - val_categorical_accuracy: 0.9367\n",
      "Epoch 7/10\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.0512 - categorical_accuracy: 0.9808 - val_loss: 0.1009 - val_categorical_accuracy: 0.9620\n",
      "Epoch 8/10\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.0193 - categorical_accuracy: 0.9968 - val_loss: 0.0515 - val_categorical_accuracy: 0.9873\n",
      "Epoch 9/10\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.0049 - categorical_accuracy: 1.0000 - val_loss: 0.0736 - val_categorical_accuracy: 0.9620\n",
      "Epoch 10/10\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.0062 - categorical_accuracy: 1.0000 - val_loss: 0.0881 - val_categorical_accuracy: 0.9494\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_31 (Embedding)     (None, 1100, 300)         2954400   \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 1098, 200)         180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_31 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 4)                 1004      \n",
      "=================================================================\n",
      "Total params: 3,185,854\n",
      "Trainable params: 231,454\n",
      "Non-trainable params: 2,954,400\n",
      "_________________________________________________________________\n",
      "Train on 319 samples, validate on 80 samples\n",
      "Epoch 1/10\n",
      "319/319 [==============================] - 7s 21ms/step - loss: 0.5655 - categorical_accuracy: 0.5110 - val_loss: 0.3930 - val_categorical_accuracy: 0.7875\n",
      "Epoch 2/10\n",
      "319/319 [==============================] - 2s 5ms/step - loss: 0.3152 - categorical_accuracy: 0.8339 - val_loss: 0.3883 - val_categorical_accuracy: 0.8250\n",
      "Epoch 3/10\n",
      "319/319 [==============================] - 2s 5ms/step - loss: 0.2566 - categorical_accuracy: 0.8495 - val_loss: 0.2345 - val_categorical_accuracy: 0.8500\n",
      "Epoch 4/10\n",
      "319/319 [==============================] - 2s 5ms/step - loss: 0.1386 - categorical_accuracy: 0.8871 - val_loss: 0.1031 - val_categorical_accuracy: 0.9250\n",
      "Epoch 5/10\n",
      "319/319 [==============================] - 2s 5ms/step - loss: 0.0810 - categorical_accuracy: 0.9436 - val_loss: 0.0914 - val_categorical_accuracy: 0.9500\n",
      "Epoch 6/10\n",
      "319/319 [==============================] - 2s 5ms/step - loss: 0.0609 - categorical_accuracy: 0.9624 - val_loss: 0.0699 - val_categorical_accuracy: 0.9500\n",
      "Epoch 7/10\n",
      "319/319 [==============================] - 2s 5ms/step - loss: 0.0291 - categorical_accuracy: 0.9875 - val_loss: 0.0897 - val_categorical_accuracy: 0.9250\n",
      "Epoch 8/10\n",
      "319/319 [==============================] - 2s 5ms/step - loss: 0.0383 - categorical_accuracy: 0.9749 - val_loss: 0.0841 - val_categorical_accuracy: 0.9250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "319/319 [==============================] - 2s 5ms/step - loss: 0.0198 - categorical_accuracy: 0.9937 - val_loss: 0.0566 - val_categorical_accuracy: 0.9625\n",
      "Epoch 10/10\n",
      "319/319 [==============================] - 2s 5ms/step - loss: 0.0104 - categorical_accuracy: 0.9969 - val_loss: 0.0479 - val_categorical_accuracy: 0.9500\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_32 (Embedding)     (None, 1100, 300)         2954400   \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 1098, 200)         180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_32 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 5)                 1255      \n",
      "=================================================================\n",
      "Total params: 3,186,105\n",
      "Trainable params: 231,705\n",
      "Non-trainable params: 2,954,400\n",
      "_________________________________________________________________\n",
      "Train on 504 samples, validate on 127 samples\n",
      "Epoch 1/10\n",
      "504/504 [==============================] - 8s 15ms/step - loss: 0.4741 - categorical_accuracy: 0.4901 - val_loss: 0.3013 - val_categorical_accuracy: 0.7087\n",
      "Epoch 2/10\n",
      "504/504 [==============================] - 2s 5ms/step - loss: 0.2272 - categorical_accuracy: 0.7401 - val_loss: 0.1506 - val_categorical_accuracy: 0.8425\n",
      "Epoch 3/10\n",
      "504/504 [==============================] - 2s 5ms/step - loss: 0.1314 - categorical_accuracy: 0.8651 - val_loss: 0.1442 - val_categorical_accuracy: 0.8346\n",
      "Epoch 4/10\n",
      "504/504 [==============================] - 2s 5ms/step - loss: 0.0923 - categorical_accuracy: 0.8988 - val_loss: 0.1129 - val_categorical_accuracy: 0.8819\n",
      "Epoch 5/10\n",
      "504/504 [==============================] - 2s 5ms/step - loss: 0.0610 - categorical_accuracy: 0.9643 - val_loss: 0.0883 - val_categorical_accuracy: 0.9291\n",
      "Epoch 6/10\n",
      "504/504 [==============================] - 2s 5ms/step - loss: 0.0413 - categorical_accuracy: 0.9762 - val_loss: 0.0872 - val_categorical_accuracy: 0.9213\n",
      "Epoch 7/10\n",
      "504/504 [==============================] - 2s 5ms/step - loss: 0.0374 - categorical_accuracy: 0.9742 - val_loss: 0.0714 - val_categorical_accuracy: 0.9528\n",
      "Epoch 8/10\n",
      "504/504 [==============================] - 2s 5ms/step - loss: 0.0352 - categorical_accuracy: 0.9802 - val_loss: 0.0739 - val_categorical_accuracy: 0.9449\n",
      "Epoch 9/10\n",
      "504/504 [==============================] - 2s 5ms/step - loss: 0.0211 - categorical_accuracy: 0.9861 - val_loss: 0.1061 - val_categorical_accuracy: 0.8898\n",
      "Epoch 10/10\n",
      "504/504 [==============================] - 2s 5ms/step - loss: 0.0142 - categorical_accuracy: 0.9940 - val_loss: 0.0775 - val_categorical_accuracy: 0.9291\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_33 (Embedding)     (None, 1100, 300)         2954400   \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 1098, 200)         180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_33 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 4)                 1004      \n",
      "=================================================================\n",
      "Total params: 3,185,854\n",
      "Trainable params: 231,454\n",
      "Non-trainable params: 2,954,400\n",
      "_________________________________________________________________\n",
      "Train on 1166 samples, validate on 292 samples\n",
      "Epoch 1/10\n",
      "1166/1166 [==============================] - 11s 9ms/step - loss: 0.3529 - categorical_accuracy: 0.7290 - val_loss: 0.1465 - val_categorical_accuracy: 0.8733\n",
      "Epoch 2/10\n",
      "1166/1166 [==============================] - 6s 5ms/step - loss: 0.1094 - categorical_accuracy: 0.9099 - val_loss: 0.0865 - val_categorical_accuracy: 0.9384\n",
      "Epoch 3/10\n",
      "1166/1166 [==============================] - 6s 5ms/step - loss: 0.0513 - categorical_accuracy: 0.9648 - val_loss: 0.0737 - val_categorical_accuracy: 0.9315\n",
      "Epoch 4/10\n",
      "1166/1166 [==============================] - 6s 5ms/step - loss: 0.0246 - categorical_accuracy: 0.9863 - val_loss: 0.0447 - val_categorical_accuracy: 0.9726\n",
      "Epoch 5/10\n",
      "1166/1166 [==============================] - 6s 5ms/step - loss: 0.0152 - categorical_accuracy: 0.9940 - val_loss: 0.0356 - val_categorical_accuracy: 0.9760\n",
      "Epoch 6/10\n",
      "1166/1166 [==============================] - 6s 5ms/step - loss: 0.0103 - categorical_accuracy: 0.9983 - val_loss: 0.0407 - val_categorical_accuracy: 0.9726\n",
      "Epoch 7/10\n",
      "1166/1166 [==============================] - 6s 5ms/step - loss: 0.0066 - categorical_accuracy: 0.9991 - val_loss: 0.0297 - val_categorical_accuracy: 0.9760\n",
      "Epoch 8/10\n",
      "1166/1166 [==============================] - 6s 5ms/step - loss: 0.0044 - categorical_accuracy: 0.9991 - val_loss: 0.0327 - val_categorical_accuracy: 0.9795\n",
      "Epoch 9/10\n",
      "1166/1166 [==============================] - 6s 5ms/step - loss: 0.0031 - categorical_accuracy: 1.0000 - val_loss: 0.0322 - val_categorical_accuracy: 0.9795\n",
      "Epoch 10/10\n",
      "1166/1166 [==============================] - 6s 5ms/step - loss: 0.0024 - categorical_accuracy: 1.0000 - val_loss: 0.0304 - val_categorical_accuracy: 0.9795\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_34 (Embedding)     (None, 1100, 300)         2954400   \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 1098, 200)         180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_34 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 4)                 1004      \n",
      "=================================================================\n",
      "Total params: 3,185,854\n",
      "Trainable params: 231,454\n",
      "Non-trainable params: 2,954,400\n",
      "_________________________________________________________________\n",
      "Train on 8018 samples, validate on 2005 samples\n",
      "Epoch 1/10\n",
      "8018/8018 [==============================] - 44s 5ms/step - loss: 0.1003 - categorical_accuracy: 0.9293 - val_loss: 0.0228 - val_categorical_accuracy: 0.9830\n",
      "Epoch 2/10\n",
      "8018/8018 [==============================] - 39s 5ms/step - loss: 0.0144 - categorical_accuracy: 0.9908 - val_loss: 0.0204 - val_categorical_accuracy: 0.9845\n",
      "Epoch 3/10\n",
      "8018/8018 [==============================] - 38s 5ms/step - loss: 0.0055 - categorical_accuracy: 0.9974 - val_loss: 0.0185 - val_categorical_accuracy: 0.9855\n",
      "Epoch 4/10\n",
      "8018/8018 [==============================] - 38s 5ms/step - loss: 0.0027 - categorical_accuracy: 0.9990 - val_loss: 0.0197 - val_categorical_accuracy: 0.9860\n",
      "Epoch 5/10\n",
      "8018/8018 [==============================] - 38s 5ms/step - loss: 0.0027 - categorical_accuracy: 0.9990 - val_loss: 0.0198 - val_categorical_accuracy: 0.9870\n",
      "Epoch 6/10\n",
      "8018/8018 [==============================] - 38s 5ms/step - loss: 0.0013 - categorical_accuracy: 0.9994 - val_loss: 0.0204 - val_categorical_accuracy: 0.9870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "8018/8018 [==============================] - 38s 5ms/step - loss: 0.0016 - categorical_accuracy: 0.9998 - val_loss: 0.0250 - val_categorical_accuracy: 0.9840\n",
      "Epoch 8/10\n",
      "8018/8018 [==============================] - 38s 5ms/step - loss: 0.0028 - categorical_accuracy: 0.9993 - val_loss: 0.0242 - val_categorical_accuracy: 0.9855\n",
      "Epoch 9/10\n",
      "8018/8018 [==============================] - 38s 5ms/step - loss: 0.0012 - categorical_accuracy: 0.9995 - val_loss: 0.0219 - val_categorical_accuracy: 0.9875\n",
      "Epoch 10/10\n",
      "8018/8018 [==============================] - 38s 5ms/step - loss: 0.0018 - categorical_accuracy: 0.9996 - val_loss: 0.0242 - val_categorical_accuracy: 0.9855\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_35 (Embedding)     (None, 1100, 300)         2954400   \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 1098, 200)         180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_35 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 7)                 1757      \n",
      "=================================================================\n",
      "Total params: 3,186,607\n",
      "Trainable params: 232,207\n",
      "Non-trainable params: 2,954,400\n",
      "_________________________________________________________________\n",
      "Train on 1868 samples, validate on 467 samples\n",
      "Epoch 1/10\n",
      "1868/1868 [==============================] - 14s 8ms/step - loss: 0.2590 - categorical_accuracy: 0.6140 - val_loss: 0.1184 - val_categorical_accuracy: 0.8480\n",
      "Epoch 2/10\n",
      "1868/1868 [==============================] - 9s 5ms/step - loss: 0.0808 - categorical_accuracy: 0.9058 - val_loss: 0.0561 - val_categorical_accuracy: 0.9379\n",
      "Epoch 3/10\n",
      "1868/1868 [==============================] - 9s 5ms/step - loss: 0.0350 - categorical_accuracy: 0.9695 - val_loss: 0.0374 - val_categorical_accuracy: 0.9615\n",
      "Epoch 4/10\n",
      "1868/1868 [==============================] - 9s 5ms/step - loss: 0.0188 - categorical_accuracy: 0.9845 - val_loss: 0.0278 - val_categorical_accuracy: 0.9679\n",
      "Epoch 5/10\n",
      "1868/1868 [==============================] - 9s 5ms/step - loss: 0.0113 - categorical_accuracy: 0.9893 - val_loss: 0.0251 - val_categorical_accuracy: 0.9722\n",
      "Epoch 6/10\n",
      "1868/1868 [==============================] - 9s 5ms/step - loss: 0.0072 - categorical_accuracy: 0.9946 - val_loss: 0.0247 - val_categorical_accuracy: 0.9679\n",
      "Epoch 7/10\n",
      "1868/1868 [==============================] - 9s 5ms/step - loss: 0.0046 - categorical_accuracy: 0.9979 - val_loss: 0.0214 - val_categorical_accuracy: 0.9764\n",
      "Epoch 8/10\n",
      "1868/1868 [==============================] - 9s 5ms/step - loss: 0.0032 - categorical_accuracy: 0.9984 - val_loss: 0.0208 - val_categorical_accuracy: 0.9764\n",
      "Epoch 9/10\n",
      "1868/1868 [==============================] - 9s 5ms/step - loss: 0.0022 - categorical_accuracy: 1.0000 - val_loss: 0.0215 - val_categorical_accuracy: 0.9679\n",
      "Epoch 10/10\n",
      "1868/1868 [==============================] - 9s 5ms/step - loss: 0.0021 - categorical_accuracy: 0.9989 - val_loss: 0.0206 - val_categorical_accuracy: 0.9786\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_36 (Embedding)     (None, 1100, 300)         2954400   \n",
      "_________________________________________________________________\n",
      "conv1d_36 (Conv1D)           (None, 1098, 200)         180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_36 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 4)                 1004      \n",
      "=================================================================\n",
      "Total params: 3,185,854\n",
      "Trainable params: 231,454\n",
      "Non-trainable params: 2,954,400\n",
      "_________________________________________________________________\n",
      "Train on 5172 samples, validate on 1294 samples\n",
      "Epoch 1/10\n",
      "5172/5172 [==============================] - 30s 6ms/step - loss: 0.2763 - categorical_accuracy: 0.7691 - val_loss: 0.1817 - val_categorical_accuracy: 0.8655\n",
      "Epoch 2/10\n",
      "5172/5172 [==============================] - 25s 5ms/step - loss: 0.1285 - categorical_accuracy: 0.9068 - val_loss: 0.1522 - val_categorical_accuracy: 0.8887\n",
      "Epoch 3/10\n",
      "5172/5172 [==============================] - 24s 5ms/step - loss: 0.0716 - categorical_accuracy: 0.9538 - val_loss: 0.1496 - val_categorical_accuracy: 0.8825\n",
      "Epoch 4/10\n",
      "5172/5172 [==============================] - 24s 5ms/step - loss: 0.0346 - categorical_accuracy: 0.9861 - val_loss: 0.1520 - val_categorical_accuracy: 0.8941\n",
      "Epoch 5/10\n",
      "5172/5172 [==============================] - 25s 5ms/step - loss: 0.0180 - categorical_accuracy: 0.9928 - val_loss: 0.1701 - val_categorical_accuracy: 0.8972\n",
      "Epoch 6/10\n",
      "5172/5172 [==============================] - 25s 5ms/step - loss: 0.0147 - categorical_accuracy: 0.9938 - val_loss: 0.1930 - val_categorical_accuracy: 0.8910\n",
      "Epoch 7/10\n",
      "5172/5172 [==============================] - 25s 5ms/step - loss: 0.0172 - categorical_accuracy: 0.9932 - val_loss: 0.1886 - val_categorical_accuracy: 0.8980\n",
      "Epoch 8/10\n",
      "5172/5172 [==============================] - 25s 5ms/step - loss: 0.0130 - categorical_accuracy: 0.9942 - val_loss: 0.1843 - val_categorical_accuracy: 0.8988\n",
      "Epoch 9/10\n",
      "5172/5172 [==============================] - 25s 5ms/step - loss: 0.0162 - categorical_accuracy: 0.9944 - val_loss: 0.1990 - val_categorical_accuracy: 0.8918\n",
      "Epoch 10/10\n",
      "5172/5172 [==============================] - 25s 5ms/step - loss: 0.0150 - categorical_accuracy: 0.9932 - val_loss: 0.1962 - val_categorical_accuracy: 0.8972\n"
     ]
    }
   ],
   "source": [
    "classifiers= HCM.subclassifiers(parenttoChildFeature,parenttoChildSubcategory,embedding_matrix,1100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_37 (Embedding)     (None, 1100, 300)         2954400   \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 1098, 200)         180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_37 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 9)                 2259      \n",
      "=================================================================\n",
      "Total params: 3,187,109\n",
      "Trainable params: 232,709\n",
      "Non-trainable params: 2,954,400\n",
      "_________________________________________________________________\n",
      "Train on 18261 samples, validate on 4566 samples\n",
      "Epoch 1/10\n",
      "18261/18261 [==============================] - 93s 5ms/step - loss: 0.0656 - categorical_accuracy: 0.9006 - val_loss: 0.0277 - val_categorical_accuracy: 0.9608\n",
      "Epoch 2/10\n",
      "18261/18261 [==============================] - 88s 5ms/step - loss: 0.0162 - categorical_accuracy: 0.9786 - val_loss: 0.0254 - val_categorical_accuracy: 0.9691\n",
      "Epoch 3/10\n",
      "18261/18261 [==============================] - 88s 5ms/step - loss: 0.0075 - categorical_accuracy: 0.9907 - val_loss: 0.0281 - val_categorical_accuracy: 0.9676\n",
      "Epoch 4/10\n",
      "18261/18261 [==============================] - 87s 5ms/step - loss: 0.0043 - categorical_accuracy: 0.9959 - val_loss: 0.0299 - val_categorical_accuracy: 0.9674\n",
      "Epoch 5/10\n",
      "18261/18261 [==============================] - 88s 5ms/step - loss: 0.0035 - categorical_accuracy: 0.9964 - val_loss: 0.0294 - val_categorical_accuracy: 0.9698\n",
      "Epoch 6/10\n",
      "18261/18261 [==============================] - 88s 5ms/step - loss: 0.0031 - categorical_accuracy: 0.9970 - val_loss: 0.0324 - val_categorical_accuracy: 0.9717\n",
      "Epoch 7/10\n",
      "18261/18261 [==============================] - 88s 5ms/step - loss: 0.0034 - categorical_accuracy: 0.9968 - val_loss: 0.0350 - val_categorical_accuracy: 0.9702\n",
      "Epoch 8/10\n",
      "18261/18261 [==============================] - 87s 5ms/step - loss: 0.0038 - categorical_accuracy: 0.9959 - val_loss: 0.0357 - val_categorical_accuracy: 0.9707\n",
      "Epoch 9/10\n",
      "18261/18261 [==============================] - 87s 5ms/step - loss: 0.0027 - categorical_accuracy: 0.9973 - val_loss: 0.0377 - val_categorical_accuracy: 0.9676\n",
      "Epoch 10/10\n",
      "18261/18261 [==============================] - 88s 5ms/step - loss: 0.0051 - categorical_accuracy: 0.9943 - val_loss: 0.0471 - val_categorical_accuracy: 0.9628\n",
      "CPU times: user 5 s, sys: 0 ns, total: 5 s\n",
      "Wall time: 9.3 s\n"
     ]
    }
   ],
   "source": [
    "y_pred = HCM.firstLevelModelTraining(sequences,sequences_test,embedding_matrix,1100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 s, sys: 1e+03 ns, total: 6 s\n",
      "Wall time: 10.3 s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96       174\n",
      "           1       1.00      0.53      0.69        17\n",
      "           2       0.73      0.66      0.70        74\n",
      "           3       1.00      0.94      0.97        18\n",
      "           4       0.97      0.95      0.96        39\n",
      "           5       0.67      0.40      0.50        10\n",
      "           6       0.94      0.89      0.92        37\n",
      "           7       1.00      0.38      0.55         8\n",
      "           8       0.82      1.00      0.90        18\n",
      "           9       0.97      1.00      0.99        77\n",
      "          10       0.75      0.92      0.83        26\n",
      "          11       0.50      0.60      0.55        15\n",
      "          12       1.00      1.00      1.00         9\n",
      "          13       0.73      0.73      0.73        11\n",
      "          14       0.86      0.97      0.91        99\n",
      "          15       0.84      0.99      0.91       229\n",
      "          16       1.00      0.71      0.83         7\n",
      "          17       0.98      0.96      0.97       952\n",
      "          18       1.00      0.79      0.88        19\n",
      "          19       0.99      0.99      0.99      1326\n",
      "          20       1.00      0.98      0.99       239\n",
      "          21       0.96      0.94      0.95       142\n",
      "          22       0.93      0.93      0.93        15\n",
      "          23       1.00      0.38      0.56        13\n",
      "          24       0.95      0.93      0.94       134\n",
      "          25       0.98      0.94      0.96       190\n",
      "          26       0.91      0.71      0.80        14\n",
      "          27       1.00      0.95      0.98       105\n",
      "          28       0.84      0.70      0.76       164\n",
      "          29       0.84      0.76      0.80       188\n",
      "          30       0.88      0.94      0.91      1060\n",
      "          31       0.84      0.75      0.79       223\n",
      "          32       0.83      0.96      0.89        52\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      5704\n",
      "   macro avg       0.90      0.83      0.85      5704\n",
      "weighted avg       0.93      0.93      0.93      5704\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_nd = HCM.PredictSecondLevel(classifiers,y_pred ,sequences_test,1100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_38 (Embedding)     (None, 1100, 300)         2954400   \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 1098, 200)         180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_38 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 33)                8283      \n",
      "=================================================================\n",
      "Total params: 3,193,133\n",
      "Trainable params: 238,733\n",
      "Non-trainable params: 2,954,400\n",
      "_________________________________________________________________\n",
      "Train on 18261 samples, validate on 4566 samples\n",
      "Epoch 1/10\n",
      "18261/18261 [==============================] - 94s 5ms/step - loss: 0.0344 - categorical_accuracy: 0.8027 - val_loss: 0.0195 - val_categorical_accuracy: 0.8839\n",
      "Epoch 2/10\n",
      "18261/18261 [==============================] - 89s 5ms/step - loss: 0.0125 - categorical_accuracy: 0.9296 - val_loss: 0.0147 - val_categorical_accuracy: 0.9207\n",
      "Epoch 3/10\n",
      "18261/18261 [==============================] - 88s 5ms/step - loss: 0.0069 - categorical_accuracy: 0.9642 - val_loss: 0.0159 - val_categorical_accuracy: 0.9179\n",
      "Epoch 4/10\n",
      "18261/18261 [==============================] - 88s 5ms/step - loss: 0.0041 - categorical_accuracy: 0.9812 - val_loss: 0.0156 - val_categorical_accuracy: 0.9236\n",
      "Epoch 5/10\n",
      "18261/18261 [==============================] - 88s 5ms/step - loss: 0.0028 - categorical_accuracy: 0.9877 - val_loss: 0.0163 - val_categorical_accuracy: 0.9253\n",
      "Epoch 6/10\n",
      "18261/18261 [==============================] - 87s 5ms/step - loss: 0.0021 - categorical_accuracy: 0.9913 - val_loss: 0.0188 - val_categorical_accuracy: 0.9220\n",
      "Epoch 7/10\n",
      "18261/18261 [==============================] - 88s 5ms/step - loss: 0.0020 - categorical_accuracy: 0.9926 - val_loss: 0.0194 - val_categorical_accuracy: 0.9133\n",
      "Epoch 8/10\n",
      "18261/18261 [==============================] - 87s 5ms/step - loss: 0.0019 - categorical_accuracy: 0.9927 - val_loss: 0.0191 - val_categorical_accuracy: 0.9249\n",
      "Epoch 9/10\n",
      "18261/18261 [==============================] - 88s 5ms/step - loss: 0.0019 - categorical_accuracy: 0.9936 - val_loss: 0.0184 - val_categorical_accuracy: 0.9282\n",
      "Epoch 10/10\n",
      "18261/18261 [==============================] - 88s 5ms/step - loss: 0.0015 - categorical_accuracy: 0.9950 - val_loss: 0.0184 - val_categorical_accuracy: 0.9279\n",
      "CPU times: user 5 s, sys: 0 ns, total: 5 s\n",
      "Wall time: 10 s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       174\n",
      "           1       0.72      0.76      0.74        17\n",
      "           2       0.72      0.62      0.67        74\n",
      "           3       0.94      0.89      0.91        18\n",
      "           4       1.00      0.95      0.97        39\n",
      "           5       0.55      0.60      0.57        10\n",
      "           6       1.00      0.95      0.97        37\n",
      "           7       0.33      0.38      0.35         8\n",
      "           8       0.94      0.94      0.94        18\n",
      "           9       1.00      0.99      0.99        77\n",
      "          10       1.00      0.92      0.96        26\n",
      "          11       0.67      0.53      0.59        15\n",
      "          12       0.60      1.00      0.75         9\n",
      "          13       0.91      0.91      0.91        11\n",
      "          14       0.94      0.96      0.95        99\n",
      "          15       0.97      0.99      0.98       229\n",
      "          16       0.83      0.71      0.77         7\n",
      "          17       0.98      0.97      0.97       952\n",
      "          18       0.94      0.89      0.92        19\n",
      "          19       0.98      0.99      0.99      1326\n",
      "          20       0.99      0.99      0.99       239\n",
      "          21       0.93      0.97      0.95       142\n",
      "          22       0.88      1.00      0.94        15\n",
      "          23       0.83      0.77      0.80        13\n",
      "          24       0.97      0.93      0.95       134\n",
      "          25       0.98      0.96      0.97       190\n",
      "          26       0.85      0.79      0.81        14\n",
      "          27       0.94      0.97      0.96       105\n",
      "          28       0.79      0.66      0.72       164\n",
      "          29       0.80      0.77      0.78       188\n",
      "          30       0.90      0.92      0.91      1060\n",
      "          31       0.76      0.78      0.77       223\n",
      "          32       0.94      0.96      0.95        52\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      5704\n",
      "   macro avg       0.87      0.86      0.86      5704\n",
      "weighted avg       0.93      0.93      0.93      5704\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_flat_nd = HCM.FlatApproach(sequences,sequences_test,embedding_matrix,1100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "openData = OpenData(3)\n",
    "trainData,trainLabel,testData,testLabel = openData.openFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "HCM = HierarchicalModel(trainData,trainLabel,testData,testLabel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Vocabulary size : 24650 ----- \n",
      "\n",
      "----- Convert train and test data to sequences ----- \n",
      "\n",
      "----- Total unique words : %d -----\n",
      " 107100\n",
      "----- Convert train data to vector in second level ----- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "parenttoChildFeature,parenttoChildSubcategory, sequences, sequences_test = HCM.wordToSequence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Use 300 dimension word vector ---- \n",
      "\n",
      "Found 400,000 word vectors in GloVe.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = HCM.openGloveEmbeddingMatrix(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = HCM.creatEmeddingMatrix(embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_39 (Embedding)     (None, 350, 300)          7395000   \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 348, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_39 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 5)                 1255      \n",
      "=================================================================\n",
      "Total params: 7,626,705\n",
      "Trainable params: 231,705\n",
      "Non-trainable params: 7,395,000\n",
      "_________________________________________________________________\n",
      "Train on 414 samples, validate on 104 samples\n",
      "Epoch 1/10\n",
      "414/414 [==============================] - 8s 19ms/step - loss: 0.5855 - categorical_accuracy: 0.3671 - val_loss: 0.4766 - val_categorical_accuracy: 0.5577\n",
      "Epoch 2/10\n",
      "414/414 [==============================] - 1s 2ms/step - loss: 0.4114 - categorical_accuracy: 0.5556 - val_loss: 0.4486 - val_categorical_accuracy: 0.3942\n",
      "Epoch 3/10\n",
      "414/414 [==============================] - 1s 2ms/step - loss: 0.3294 - categorical_accuracy: 0.6377 - val_loss: 0.3346 - val_categorical_accuracy: 0.6154\n",
      "Epoch 4/10\n",
      "414/414 [==============================] - 1s 2ms/step - loss: 0.2527 - categorical_accuracy: 0.7415 - val_loss: 0.3203 - val_categorical_accuracy: 0.6442\n",
      "Epoch 5/10\n",
      "414/414 [==============================] - 1s 2ms/step - loss: 0.2131 - categorical_accuracy: 0.7705 - val_loss: 0.3059 - val_categorical_accuracy: 0.6442\n",
      "Epoch 6/10\n",
      "414/414 [==============================] - 1s 2ms/step - loss: 0.1769 - categorical_accuracy: 0.8527 - val_loss: 0.2836 - val_categorical_accuracy: 0.6731\n",
      "Epoch 7/10\n",
      "414/414 [==============================] - 1s 2ms/step - loss: 0.1439 - categorical_accuracy: 0.8623 - val_loss: 0.2827 - val_categorical_accuracy: 0.6346\n",
      "Epoch 8/10\n",
      "414/414 [==============================] - 1s 2ms/step - loss: 0.1234 - categorical_accuracy: 0.9300 - val_loss: 0.2678 - val_categorical_accuracy: 0.7308\n",
      "Epoch 9/10\n",
      "414/414 [==============================] - 1s 2ms/step - loss: 0.1046 - categorical_accuracy: 0.9130 - val_loss: 0.2473 - val_categorical_accuracy: 0.7500\n",
      "Epoch 10/10\n",
      "414/414 [==============================] - 1s 2ms/step - loss: 0.0803 - categorical_accuracy: 0.9638 - val_loss: 0.2889 - val_categorical_accuracy: 0.6635\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_40 (Embedding)     (None, 350, 300)          7395000   \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 348, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_40 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 7)                 1757      \n",
      "=================================================================\n",
      "Total params: 7,627,207\n",
      "Trainable params: 232,207\n",
      "Non-trainable params: 7,395,000\n",
      "_________________________________________________________________\n",
      "Train on 793 samples, validate on 199 samples\n",
      "Epoch 1/10\n",
      "793/793 [==============================] - 9s 11ms/step - loss: 0.3769 - categorical_accuracy: 0.4540 - val_loss: 0.2504 - val_categorical_accuracy: 0.6683\n",
      "Epoch 2/10\n",
      "793/793 [==============================] - 1s 1ms/step - loss: 0.2224 - categorical_accuracy: 0.7276 - val_loss: 0.1969 - val_categorical_accuracy: 0.7487\n",
      "Epoch 3/10\n",
      "793/793 [==============================] - 1s 1ms/step - loss: 0.1598 - categorical_accuracy: 0.7995 - val_loss: 0.1622 - val_categorical_accuracy: 0.8191\n",
      "Epoch 4/10\n",
      "793/793 [==============================] - 1s 1ms/step - loss: 0.1205 - categorical_accuracy: 0.8726 - val_loss: 0.1369 - val_categorical_accuracy: 0.8392\n",
      "Epoch 5/10\n",
      "793/793 [==============================] - 1s 1ms/step - loss: 0.0860 - categorical_accuracy: 0.9117 - val_loss: 0.1239 - val_categorical_accuracy: 0.8442\n",
      "Epoch 6/10\n",
      "793/793 [==============================] - 1s 1ms/step - loss: 0.0607 - categorical_accuracy: 0.9596 - val_loss: 0.1036 - val_categorical_accuracy: 0.8643\n",
      "Epoch 7/10\n",
      "793/793 [==============================] - 1s 2ms/step - loss: 0.0402 - categorical_accuracy: 0.9748 - val_loss: 0.1015 - val_categorical_accuracy: 0.8643\n",
      "Epoch 8/10\n",
      "793/793 [==============================] - 1s 2ms/step - loss: 0.0268 - categorical_accuracy: 0.9912 - val_loss: 0.1014 - val_categorical_accuracy: 0.8844\n",
      "Epoch 9/10\n",
      "793/793 [==============================] - 1s 2ms/step - loss: 0.0183 - categorical_accuracy: 0.9924 - val_loss: 0.1022 - val_categorical_accuracy: 0.8844\n",
      "Epoch 10/10\n",
      "793/793 [==============================] - 1s 2ms/step - loss: 0.0140 - categorical_accuracy: 0.9924 - val_loss: 0.1048 - val_categorical_accuracy: 0.8744\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_41 (Embedding)     (None, 350, 300)          7395000   \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 348, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_41 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 7)                 1757      \n",
      "=================================================================\n",
      "Total params: 7,627,207\n",
      "Trainable params: 232,207\n",
      "Non-trainable params: 7,395,000\n",
      "_________________________________________________________________\n",
      "Train on 7500 samples, validate on 1876 samples\n",
      "Epoch 1/10\n",
      "7500/7500 [==============================] - 18s 2ms/step - loss: 0.1776 - categorical_accuracy: 0.7657 - val_loss: 0.1170 - val_categorical_accuracy: 0.8358\n",
      "Epoch 2/10\n",
      "7500/7500 [==============================] - 12s 2ms/step - loss: 0.1115 - categorical_accuracy: 0.8401 - val_loss: 0.1169 - val_categorical_accuracy: 0.8358\n",
      "Epoch 3/10\n",
      "7500/7500 [==============================] - 11s 1ms/step - loss: 0.0985 - categorical_accuracy: 0.8564 - val_loss: 0.1025 - val_categorical_accuracy: 0.8545\n",
      "Epoch 4/10\n",
      "7500/7500 [==============================] - 11s 1ms/step - loss: 0.0851 - categorical_accuracy: 0.8751 - val_loss: 0.1365 - val_categorical_accuracy: 0.8054\n",
      "Epoch 5/10\n",
      "7500/7500 [==============================] - 12s 2ms/step - loss: 0.0814 - categorical_accuracy: 0.8819 - val_loss: 0.1094 - val_categorical_accuracy: 0.8401\n",
      "Epoch 6/10\n",
      "7500/7500 [==============================] - 11s 2ms/step - loss: 0.0760 - categorical_accuracy: 0.8911 - val_loss: 0.1085 - val_categorical_accuracy: 0.8438\n",
      "Epoch 7/10\n",
      "7500/7500 [==============================] - 11s 2ms/step - loss: 0.0736 - categorical_accuracy: 0.9003 - val_loss: 0.1148 - val_categorical_accuracy: 0.8364\n",
      "Epoch 8/10\n",
      "7500/7500 [==============================] - 11s 1ms/step - loss: 0.0710 - categorical_accuracy: 0.9011 - val_loss: 0.1080 - val_categorical_accuracy: 0.8614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "7500/7500 [==============================] - 11s 1ms/step - loss: 0.0662 - categorical_accuracy: 0.9076 - val_loss: 0.1133 - val_categorical_accuracy: 0.8449\n",
      "Epoch 10/10\n",
      "7500/7500 [==============================] - 11s 1ms/step - loss: 0.0643 - categorical_accuracy: 0.9089 - val_loss: 0.1129 - val_categorical_accuracy: 0.8582\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_42 (Embedding)     (None, 350, 300)          7395000   \n",
      "_________________________________________________________________\n",
      "conv1d_42 (Conv1D)           (None, 348, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_42 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 23)                5773      \n",
      "=================================================================\n",
      "Total params: 7,631,223\n",
      "Trainable params: 236,223\n",
      "Non-trainable params: 7,395,000\n",
      "_________________________________________________________________\n",
      "Train on 6689 samples, validate on 1673 samples\n",
      "Epoch 1/10\n",
      "6689/6689 [==============================] - 18s 3ms/step - loss: 0.1203 - categorical_accuracy: 0.4811 - val_loss: 0.1054 - val_categorical_accuracy: 0.5386\n",
      "Epoch 2/10\n",
      "6689/6689 [==============================] - 10s 2ms/step - loss: 0.0938 - categorical_accuracy: 0.5847 - val_loss: 0.1026 - val_categorical_accuracy: 0.5649\n",
      "Epoch 3/10\n",
      "6689/6689 [==============================] - 10s 2ms/step - loss: 0.0790 - categorical_accuracy: 0.6512 - val_loss: 0.1024 - val_categorical_accuracy: 0.5463\n",
      "Epoch 4/10\n",
      "6689/6689 [==============================] - 10s 2ms/step - loss: 0.0633 - categorical_accuracy: 0.7315 - val_loss: 0.1045 - val_categorical_accuracy: 0.5601\n",
      "Epoch 5/10\n",
      "6689/6689 [==============================] - 10s 2ms/step - loss: 0.0499 - categorical_accuracy: 0.7935 - val_loss: 0.1149 - val_categorical_accuracy: 0.5260\n",
      "Epoch 6/10\n",
      "6689/6689 [==============================] - 10s 2ms/step - loss: 0.0390 - categorical_accuracy: 0.8490 - val_loss: 0.1232 - val_categorical_accuracy: 0.5326\n",
      "Epoch 7/10\n",
      "6689/6689 [==============================] - 10s 2ms/step - loss: 0.0320 - categorical_accuracy: 0.8810 - val_loss: 0.1300 - val_categorical_accuracy: 0.5081\n",
      "Epoch 8/10\n",
      "6689/6689 [==============================] - 10s 2ms/step - loss: 0.0257 - categorical_accuracy: 0.9069 - val_loss: 0.1352 - val_categorical_accuracy: 0.5087\n",
      "Epoch 9/10\n",
      "6689/6689 [==============================] - 10s 2ms/step - loss: 0.0221 - categorical_accuracy: 0.9211 - val_loss: 0.1400 - val_categorical_accuracy: 0.5111\n",
      "Epoch 10/10\n",
      "6689/6689 [==============================] - 10s 2ms/step - loss: 0.0201 - categorical_accuracy: 0.9293 - val_loss: 0.1634 - val_categorical_accuracy: 0.5188\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_43 (Embedding)     (None, 350, 300)          7395000   \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 348, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_43 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 7)                 1757      \n",
      "=================================================================\n",
      "Total params: 7,627,207\n",
      "Trainable params: 232,207\n",
      "Non-trainable params: 7,395,000\n",
      "_________________________________________________________________\n",
      "Train on 3489 samples, validate on 873 samples\n",
      "Epoch 1/10\n",
      "3489/3489 [==============================] - 13s 4ms/step - loss: 0.1923 - categorical_accuracy: 0.7420 - val_loss: 0.1250 - val_categorical_accuracy: 0.8305\n",
      "Epoch 2/10\n",
      "3489/3489 [==============================] - 5s 2ms/step - loss: 0.0923 - categorical_accuracy: 0.8851 - val_loss: 0.1039 - val_categorical_accuracy: 0.8591\n",
      "Epoch 3/10\n",
      "3489/3489 [==============================] - 5s 2ms/step - loss: 0.0602 - categorical_accuracy: 0.9344 - val_loss: 0.0871 - val_categorical_accuracy: 0.8866\n",
      "Epoch 4/10\n",
      "3489/3489 [==============================] - 5s 1ms/step - loss: 0.0368 - categorical_accuracy: 0.9610 - val_loss: 0.0880 - val_categorical_accuracy: 0.8969\n",
      "Epoch 5/10\n",
      "3489/3489 [==============================] - 5s 2ms/step - loss: 0.0298 - categorical_accuracy: 0.9742 - val_loss: 0.0884 - val_categorical_accuracy: 0.8900\n",
      "Epoch 6/10\n",
      "3489/3489 [==============================] - 5s 2ms/step - loss: 0.0282 - categorical_accuracy: 0.9705 - val_loss: 0.0945 - val_categorical_accuracy: 0.8912\n",
      "Epoch 7/10\n",
      "3489/3489 [==============================] - 5s 2ms/step - loss: 0.0231 - categorical_accuracy: 0.9799 - val_loss: 0.0977 - val_categorical_accuracy: 0.8900\n",
      "Epoch 8/10\n",
      "3489/3489 [==============================] - 5s 2ms/step - loss: 0.0242 - categorical_accuracy: 0.9771 - val_loss: 0.0958 - val_categorical_accuracy: 0.8969\n",
      "Epoch 9/10\n",
      "3489/3489 [==============================] - 5s 2ms/step - loss: 0.0248 - categorical_accuracy: 0.9799 - val_loss: 0.1115 - val_categorical_accuracy: 0.8751\n",
      "Epoch 10/10\n",
      "3489/3489 [==============================] - 5s 2ms/step - loss: 0.0267 - categorical_accuracy: 0.9776 - val_loss: 0.0947 - val_categorical_accuracy: 0.8981\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_44 (Embedding)     (None, 350, 300)          7395000   \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 348, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_44 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 10)                2510      \n",
      "=================================================================\n",
      "Total params: 7,627,960\n",
      "Trainable params: 232,960\n",
      "Non-trainable params: 7,395,000\n",
      "_________________________________________________________________\n",
      "Train on 19321 samples, validate on 4831 samples\n",
      "Epoch 1/10\n",
      "19321/19321 [==============================] - 37s 2ms/step - loss: 0.0707 - categorical_accuracy: 0.8723 - val_loss: 0.0460 - val_categorical_accuracy: 0.9251\n",
      "Epoch 2/10\n",
      "19321/19321 [==============================] - 30s 2ms/step - loss: 0.0332 - categorical_accuracy: 0.9430 - val_loss: 0.0448 - val_categorical_accuracy: 0.9234\n",
      "Epoch 3/10\n",
      "19321/19321 [==============================] - 30s 2ms/step - loss: 0.0232 - categorical_accuracy: 0.9631 - val_loss: 0.0464 - val_categorical_accuracy: 0.9284\n",
      "Epoch 4/10\n",
      "19321/19321 [==============================] - 30s 2ms/step - loss: 0.0187 - categorical_accuracy: 0.9742 - val_loss: 0.0403 - val_categorical_accuracy: 0.9375\n",
      "Epoch 5/10\n",
      "19321/19321 [==============================] - 30s 2ms/step - loss: 0.0150 - categorical_accuracy: 0.9807 - val_loss: 0.0401 - val_categorical_accuracy: 0.9348\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19321/19321 [==============================] - 30s 2ms/step - loss: 0.0142 - categorical_accuracy: 0.9824 - val_loss: 0.0415 - val_categorical_accuracy: 0.9396\n",
      "Epoch 7/10\n",
      "19321/19321 [==============================] - 30s 2ms/step - loss: 0.0133 - categorical_accuracy: 0.9836 - val_loss: 0.0442 - val_categorical_accuracy: 0.9387\n",
      "Epoch 8/10\n",
      "19321/19321 [==============================] - 30s 2ms/step - loss: 0.0134 - categorical_accuracy: 0.9842 - val_loss: 0.0448 - val_categorical_accuracy: 0.9365\n",
      "Epoch 9/10\n",
      "19321/19321 [==============================] - 30s 2ms/step - loss: 0.0120 - categorical_accuracy: 0.9858 - val_loss: 0.0433 - val_categorical_accuracy: 0.9358\n",
      "Epoch 10/10\n",
      "19321/19321 [==============================] - 29s 2ms/step - loss: 0.0128 - categorical_accuracy: 0.9861 - val_loss: 0.0472 - val_categorical_accuracy: 0.9321\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_45 (Embedding)     (None, 350, 300)          7395000   \n",
      "_________________________________________________________________\n",
      "conv1d_45 (Conv1D)           (None, 348, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_45 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 3)                 753       \n",
      "=================================================================\n",
      "Total params: 7,626,203\n",
      "Trainable params: 231,203\n",
      "Non-trainable params: 7,395,000\n",
      "_________________________________________________________________\n",
      "Train on 124 samples, validate on 32 samples\n",
      "Epoch 1/10\n",
      "124/124 [==============================] - 8s 63ms/step - loss: 0.7220 - categorical_accuracy: 0.3145 - val_loss: 0.2948 - val_categorical_accuracy: 0.9062\n",
      "Epoch 2/10\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 0.3384 - categorical_accuracy: 0.8226 - val_loss: 0.2064 - val_categorical_accuracy: 0.8750\n",
      "Epoch 3/10\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 0.2423 - categorical_accuracy: 0.8790 - val_loss: 0.1623 - val_categorical_accuracy: 0.9062\n",
      "Epoch 4/10\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 0.2112 - categorical_accuracy: 0.9194 - val_loss: 0.1543 - val_categorical_accuracy: 0.9062\n",
      "Epoch 5/10\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 0.2014 - categorical_accuracy: 0.9113 - val_loss: 0.1314 - val_categorical_accuracy: 0.9062\n",
      "Epoch 6/10\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 0.1607 - categorical_accuracy: 0.9355 - val_loss: 0.1198 - val_categorical_accuracy: 0.9375\n",
      "Epoch 7/10\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 0.1295 - categorical_accuracy: 0.9597 - val_loss: 0.1217 - val_categorical_accuracy: 0.9688\n",
      "Epoch 8/10\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 0.1193 - categorical_accuracy: 0.9597 - val_loss: 0.1311 - val_categorical_accuracy: 0.9062\n",
      "Epoch 9/10\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 0.0957 - categorical_accuracy: 0.9597 - val_loss: 0.1494 - val_categorical_accuracy: 0.9062\n",
      "Epoch 10/10\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 0.0868 - categorical_accuracy: 0.9677 - val_loss: 0.1672 - val_categorical_accuracy: 0.9062\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_46 (Embedding)     (None, 350, 300)          7395000   \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 348, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_46 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 3)                 753       \n",
      "=================================================================\n",
      "Total params: 7,626,203\n",
      "Trainable params: 231,203\n",
      "Non-trainable params: 7,395,000\n",
      "_________________________________________________________________\n",
      "Train on 129 samples, validate on 33 samples\n",
      "Epoch 1/10\n",
      "129/129 [==============================] - 8s 61ms/step - loss: 0.6445 - categorical_accuracy: 0.3023 - val_loss: 0.5163 - val_categorical_accuracy: 0.6970\n",
      "Epoch 2/10\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 0.4938 - categorical_accuracy: 0.7287 - val_loss: 0.4871 - val_categorical_accuracy: 0.6970\n",
      "Epoch 3/10\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 0.3998 - categorical_accuracy: 0.7442 - val_loss: 0.4411 - val_categorical_accuracy: 0.6970\n",
      "Epoch 4/10\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 0.3120 - categorical_accuracy: 0.8140 - val_loss: 0.4239 - val_categorical_accuracy: 0.6970\n",
      "Epoch 5/10\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 0.2783 - categorical_accuracy: 0.8760 - val_loss: 0.4231 - val_categorical_accuracy: 0.6970\n",
      "Epoch 6/10\n",
      "129/129 [==============================] - 0s 1ms/step - loss: 0.2447 - categorical_accuracy: 0.9225 - val_loss: 0.4263 - val_categorical_accuracy: 0.6970\n",
      "Epoch 7/10\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 0.2180 - categorical_accuracy: 0.9225 - val_loss: 0.4341 - val_categorical_accuracy: 0.6970\n",
      "Epoch 8/10\n",
      "129/129 [==============================] - 0s 1ms/step - loss: 0.1947 - categorical_accuracy: 0.9302 - val_loss: 0.4423 - val_categorical_accuracy: 0.7273\n",
      "Epoch 9/10\n",
      "129/129 [==============================] - 0s 1ms/step - loss: 0.1820 - categorical_accuracy: 0.9225 - val_loss: 0.4560 - val_categorical_accuracy: 0.7273\n",
      "Epoch 10/10\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 0.1680 - categorical_accuracy: 0.9302 - val_loss: 0.4710 - val_categorical_accuracy: 0.7273\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_47 (Embedding)     (None, 350, 300)          7395000   \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 348, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_47 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 6)                 1506      \n",
      "=================================================================\n",
      "Total params: 7,626,956\n",
      "Trainable params: 231,956\n",
      "Non-trainable params: 7,395,000\n",
      "_________________________________________________________________\n",
      "Train on 1788 samples, validate on 447 samples\n",
      "Epoch 1/10\n",
      "1788/1788 [==============================] - 10s 6ms/step - loss: 0.2917 - categorical_accuracy: 0.6443 - val_loss: 0.2256 - val_categorical_accuracy: 0.7092\n",
      "Epoch 2/10\n",
      "1788/1788 [==============================] - 3s 2ms/step - loss: 0.1473 - categorical_accuracy: 0.8328 - val_loss: 0.1553 - val_categorical_accuracy: 0.8188\n",
      "Epoch 3/10\n",
      "1788/1788 [==============================] - 3s 2ms/step - loss: 0.0875 - categorical_accuracy: 0.9072 - val_loss: 0.1280 - val_categorical_accuracy: 0.8523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "1788/1788 [==============================] - 3s 2ms/step - loss: 0.0484 - categorical_accuracy: 0.9670 - val_loss: 0.1149 - val_categorical_accuracy: 0.8635\n",
      "Epoch 5/10\n",
      "1788/1788 [==============================] - 3s 2ms/step - loss: 0.0246 - categorical_accuracy: 0.9871 - val_loss: 0.1058 - val_categorical_accuracy: 0.8814\n",
      "Epoch 6/10\n",
      "1788/1788 [==============================] - 3s 2ms/step - loss: 0.0128 - categorical_accuracy: 0.9972 - val_loss: 0.1046 - val_categorical_accuracy: 0.8814\n",
      "Epoch 7/10\n",
      "1788/1788 [==============================] - 3s 2ms/step - loss: 0.0080 - categorical_accuracy: 0.9989 - val_loss: 0.1097 - val_categorical_accuracy: 0.8770\n",
      "Epoch 8/10\n",
      "1788/1788 [==============================] - 3s 2ms/step - loss: 0.0057 - categorical_accuracy: 0.9994 - val_loss: 0.1065 - val_categorical_accuracy: 0.8881\n",
      "Epoch 9/10\n",
      "1788/1788 [==============================] - 3s 2ms/step - loss: 0.0045 - categorical_accuracy: 0.9994 - val_loss: 0.1074 - val_categorical_accuracy: 0.8926\n",
      "Epoch 10/10\n",
      "1788/1788 [==============================] - 3s 2ms/step - loss: 0.0038 - categorical_accuracy: 0.9994 - val_loss: 0.1075 - val_categorical_accuracy: 0.8926\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_48 (Embedding)     (None, 350, 300)          7395000   \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 348, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_48 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 12)                3012      \n",
      "=================================================================\n",
      "Total params: 7,628,462\n",
      "Trainable params: 233,462\n",
      "Non-trainable params: 7,395,000\n",
      "_________________________________________________________________\n",
      "Train on 1260 samples, validate on 315 samples\n",
      "Epoch 1/10\n",
      "1260/1260 [==============================] - 10s 8ms/step - loss: 0.2236 - categorical_accuracy: 0.4643 - val_loss: 0.1750 - val_categorical_accuracy: 0.5873\n",
      "Epoch 2/10\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1410 - categorical_accuracy: 0.6730 - val_loss: 0.1426 - val_categorical_accuracy: 0.6603\n",
      "Epoch 3/10\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0949 - categorical_accuracy: 0.7976 - val_loss: 0.1198 - val_categorical_accuracy: 0.7238\n",
      "Epoch 4/10\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0642 - categorical_accuracy: 0.8754 - val_loss: 0.1032 - val_categorical_accuracy: 0.7524\n",
      "Epoch 5/10\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0419 - categorical_accuracy: 0.9444 - val_loss: 0.0973 - val_categorical_accuracy: 0.7746\n",
      "Epoch 6/10\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0268 - categorical_accuracy: 0.9754 - val_loss: 0.0887 - val_categorical_accuracy: 0.7937\n",
      "Epoch 7/10\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0170 - categorical_accuracy: 0.9825 - val_loss: 0.0938 - val_categorical_accuracy: 0.7873\n",
      "Epoch 8/10\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0111 - categorical_accuracy: 0.9897 - val_loss: 0.0931 - val_categorical_accuracy: 0.7905\n",
      "Epoch 9/10\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0091 - categorical_accuracy: 0.9921 - val_loss: 0.0930 - val_categorical_accuracy: 0.7937\n",
      "Epoch 10/10\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0061 - categorical_accuracy: 0.9921 - val_loss: 0.0935 - val_categorical_accuracy: 0.7905\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_49 (Embedding)     (None, 350, 300)          7395000   \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 348, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_49 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 3)                 753       \n",
      "=================================================================\n",
      "Total params: 7,626,203\n",
      "Trainable params: 231,203\n",
      "Non-trainable params: 7,395,000\n",
      "_________________________________________________________________\n",
      "Train on 138 samples, validate on 35 samples\n",
      "Epoch 1/10\n",
      "138/138 [==============================] - 8s 58ms/step - loss: 0.8052 - categorical_accuracy: 0.4565 - val_loss: 0.8931 - val_categorical_accuracy: 0.4857\n",
      "Epoch 2/10\n",
      "138/138 [==============================] - 0s 1ms/step - loss: 0.8272 - categorical_accuracy: 0.5000 - val_loss: 0.4012 - val_categorical_accuracy: 0.7143\n",
      "Epoch 3/10\n",
      "138/138 [==============================] - 0s 1ms/step - loss: 0.3248 - categorical_accuracy: 0.7391 - val_loss: 0.7397 - val_categorical_accuracy: 0.5429\n",
      "Epoch 4/10\n",
      "138/138 [==============================] - 0s 1ms/step - loss: 0.3973 - categorical_accuracy: 0.7174 - val_loss: 0.3292 - val_categorical_accuracy: 0.7143\n",
      "Epoch 5/10\n",
      "138/138 [==============================] - 0s 1ms/step - loss: 0.1440 - categorical_accuracy: 0.9275 - val_loss: 0.1856 - val_categorical_accuracy: 0.9143\n",
      "Epoch 6/10\n",
      "138/138 [==============================] - 0s 1ms/step - loss: 0.1066 - categorical_accuracy: 0.9565 - val_loss: 0.1777 - val_categorical_accuracy: 0.8857\n",
      "Epoch 7/10\n",
      "138/138 [==============================] - 0s 1ms/step - loss: 0.1075 - categorical_accuracy: 0.9493 - val_loss: 0.1665 - val_categorical_accuracy: 0.8857\n",
      "Epoch 8/10\n",
      "138/138 [==============================] - 0s 1ms/step - loss: 0.0854 - categorical_accuracy: 0.9420 - val_loss: 0.1249 - val_categorical_accuracy: 0.9143\n",
      "Epoch 9/10\n",
      "138/138 [==============================] - 0s 1ms/step - loss: 0.0376 - categorical_accuracy: 0.9855 - val_loss: 0.1320 - val_categorical_accuracy: 0.9429\n",
      "Epoch 10/10\n",
      "138/138 [==============================] - 0s 1ms/step - loss: 0.0205 - categorical_accuracy: 1.0000 - val_loss: 0.1817 - val_categorical_accuracy: 0.8286\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_50 (Embedding)     (None, 350, 300)          7395000   \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 348, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_50 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 6)                 1506      \n",
      "=================================================================\n",
      "Total params: 7,626,956\n",
      "Trainable params: 231,956\n",
      "Non-trainable params: 7,395,000\n",
      "_________________________________________________________________\n",
      "Train on 774 samples, validate on 194 samples\n",
      "Epoch 1/10\n",
      "774/774 [==============================] - 9s 12ms/step - loss: 0.4477 - categorical_accuracy: 0.3941 - val_loss: 0.3047 - val_categorical_accuracy: 0.6082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.2584 - categorical_accuracy: 0.6602 - val_loss: 0.2134 - val_categorical_accuracy: 0.7732\n",
      "Epoch 3/10\n",
      "774/774 [==============================] - 1s 2ms/step - loss: 0.1541 - categorical_accuracy: 0.8605 - val_loss: 0.1612 - val_categorical_accuracy: 0.8299\n",
      "Epoch 4/10\n",
      "774/774 [==============================] - 1s 2ms/step - loss: 0.0966 - categorical_accuracy: 0.9225 - val_loss: 0.1177 - val_categorical_accuracy: 0.8814\n",
      "Epoch 5/10\n",
      "774/774 [==============================] - 1s 2ms/step - loss: 0.0588 - categorical_accuracy: 0.9716 - val_loss: 0.1031 - val_categorical_accuracy: 0.8918\n",
      "Epoch 6/10\n",
      "774/774 [==============================] - 1s 2ms/step - loss: 0.0387 - categorical_accuracy: 0.9845 - val_loss: 0.0890 - val_categorical_accuracy: 0.9124\n",
      "Epoch 7/10\n",
      "774/774 [==============================] - 1s 2ms/step - loss: 0.0245 - categorical_accuracy: 0.9897 - val_loss: 0.0827 - val_categorical_accuracy: 0.9124\n",
      "Epoch 8/10\n",
      "774/774 [==============================] - 1s 2ms/step - loss: 0.0158 - categorical_accuracy: 0.9948 - val_loss: 0.0805 - val_categorical_accuracy: 0.9175\n",
      "Epoch 9/10\n",
      "774/774 [==============================] - 1s 1ms/step - loss: 0.0101 - categorical_accuracy: 0.9974 - val_loss: 0.0777 - val_categorical_accuracy: 0.9124\n",
      "Epoch 10/10\n",
      "774/774 [==============================] - 1s 2ms/step - loss: 0.0081 - categorical_accuracy: 0.9974 - val_loss: 0.0775 - val_categorical_accuracy: 0.9124\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_51 (Embedding)     (None, 350, 300)          7395000   \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 348, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_51 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 13)                3263      \n",
      "=================================================================\n",
      "Total params: 7,628,713\n",
      "Trainable params: 233,713\n",
      "Non-trainable params: 7,395,000\n",
      "_________________________________________________________________\n",
      "Train on 14502 samples, validate on 3626 samples\n",
      "Epoch 1/10\n",
      "14502/14502 [==============================] - 30s 2ms/step - loss: 0.1247 - categorical_accuracy: 0.6771 - val_loss: 0.0880 - val_categorical_accuracy: 0.7841\n",
      "Epoch 2/10\n",
      "14502/14502 [==============================] - 22s 2ms/step - loss: 0.0734 - categorical_accuracy: 0.8195 - val_loss: 0.0804 - val_categorical_accuracy: 0.7978\n",
      "Epoch 3/10\n",
      "14502/14502 [==============================] - 22s 2ms/step - loss: 0.0596 - categorical_accuracy: 0.8554 - val_loss: 0.0833 - val_categorical_accuracy: 0.8053\n",
      "Epoch 4/10\n",
      "14502/14502 [==============================] - 22s 2ms/step - loss: 0.0475 - categorical_accuracy: 0.8857 - val_loss: 0.0962 - val_categorical_accuracy: 0.7728\n",
      "Epoch 5/10\n",
      "14502/14502 [==============================] - 22s 2ms/step - loss: 0.0485 - categorical_accuracy: 0.8848 - val_loss: 0.0760 - val_categorical_accuracy: 0.8271\n",
      "Epoch 6/10\n",
      "14502/14502 [==============================] - 22s 2ms/step - loss: 0.0381 - categorical_accuracy: 0.9133 - val_loss: 0.0820 - val_categorical_accuracy: 0.8221\n",
      "Epoch 7/10\n",
      "14502/14502 [==============================] - 22s 2ms/step - loss: 0.0366 - categorical_accuracy: 0.9134 - val_loss: 0.0847 - val_categorical_accuracy: 0.8081\n",
      "Epoch 8/10\n",
      "14502/14502 [==============================] - 22s 2ms/step - loss: 0.0372 - categorical_accuracy: 0.9206 - val_loss: 0.0836 - val_categorical_accuracy: 0.8287\n",
      "Epoch 9/10\n",
      "14502/14502 [==============================] - 23s 2ms/step - loss: 0.0294 - categorical_accuracy: 0.9340 - val_loss: 0.0841 - val_categorical_accuracy: 0.8174\n",
      "Epoch 10/10\n",
      "14502/14502 [==============================] - 22s 2ms/step - loss: 0.0281 - categorical_accuracy: 0.9364 - val_loss: 0.1244 - val_categorical_accuracy: 0.7733\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_52 (Embedding)     (None, 350, 300)          7395000   \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 348, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_52 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 2)                 502       \n",
      "=================================================================\n",
      "Total params: 7,625,952\n",
      "Trainable params: 230,952\n",
      "Non-trainable params: 7,395,000\n",
      "_________________________________________________________________\n",
      "Train on 431 samples, validate on 108 samples\n",
      "Epoch 1/10\n",
      "431/431 [==============================] - 9s 21ms/step - loss: 0.5755 - categorical_accuracy: 0.8329 - val_loss: 0.3707 - val_categorical_accuracy: 0.7963\n",
      "Epoch 2/10\n",
      "431/431 [==============================] - 1s 1ms/step - loss: 0.2699 - categorical_accuracy: 0.8747 - val_loss: 0.2686 - val_categorical_accuracy: 0.8796\n",
      "Epoch 3/10\n",
      "431/431 [==============================] - 1s 1ms/step - loss: 0.1515 - categorical_accuracy: 0.9420 - val_loss: 0.1370 - val_categorical_accuracy: 0.9630\n",
      "Epoch 4/10\n",
      "431/431 [==============================] - 1s 1ms/step - loss: 0.1036 - categorical_accuracy: 0.9652 - val_loss: 0.1673 - val_categorical_accuracy: 0.8981\n",
      "Epoch 5/10\n",
      "431/431 [==============================] - 1s 2ms/step - loss: 0.0793 - categorical_accuracy: 0.9652 - val_loss: 0.0637 - val_categorical_accuracy: 0.9815\n",
      "Epoch 6/10\n",
      "431/431 [==============================] - 1s 2ms/step - loss: 0.0370 - categorical_accuracy: 0.9930 - val_loss: 0.0483 - val_categorical_accuracy: 0.9907\n",
      "Epoch 7/10\n",
      "431/431 [==============================] - 1s 2ms/step - loss: 0.0191 - categorical_accuracy: 0.9977 - val_loss: 0.0673 - val_categorical_accuracy: 0.9630\n",
      "Epoch 8/10\n",
      "431/431 [==============================] - 1s 2ms/step - loss: 0.0144 - categorical_accuracy: 1.0000 - val_loss: 0.0809 - val_categorical_accuracy: 0.9630\n",
      "Epoch 9/10\n",
      "431/431 [==============================] - 1s 2ms/step - loss: 0.0087 - categorical_accuracy: 1.0000 - val_loss: 0.0445 - val_categorical_accuracy: 0.9722\n",
      "Epoch 10/10\n",
      "431/431 [==============================] - 1s 2ms/step - loss: 0.0060 - categorical_accuracy: 1.0000 - val_loss: 0.0274 - val_categorical_accuracy: 0.9907\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_53 (Embedding)     (None, 350, 300)          7395000   \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 348, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_53 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 17)                4267      \n",
      "=================================================================\n",
      "Total params: 7,629,717\n",
      "Trainable params: 234,717\n",
      "Non-trainable params: 7,395,000\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4878 samples, validate on 1220 samples\n",
      "Epoch 1/10\n",
      "4878/4878 [==============================] - 16s 3ms/step - loss: 0.1135 - categorical_accuracy: 0.6712 - val_loss: 0.0768 - val_categorical_accuracy: 0.7762\n",
      "Epoch 2/10\n",
      "4878/4878 [==============================] - 7s 2ms/step - loss: 0.0596 - categorical_accuracy: 0.8227 - val_loss: 0.0618 - val_categorical_accuracy: 0.8172\n",
      "Epoch 3/10\n",
      "4878/4878 [==============================] - 7s 2ms/step - loss: 0.0388 - categorical_accuracy: 0.8862 - val_loss: 0.0532 - val_categorical_accuracy: 0.8418\n",
      "Epoch 4/10\n",
      "4878/4878 [==============================] - 7s 2ms/step - loss: 0.0249 - categorical_accuracy: 0.9309 - val_loss: 0.0574 - val_categorical_accuracy: 0.8418\n",
      "Epoch 5/10\n",
      "4878/4878 [==============================] - 7s 2ms/step - loss: 0.0184 - categorical_accuracy: 0.9578 - val_loss: 0.0661 - val_categorical_accuracy: 0.8320\n",
      "Epoch 6/10\n",
      "4878/4878 [==============================] - 7s 2ms/step - loss: 0.0162 - categorical_accuracy: 0.9641 - val_loss: 0.0559 - val_categorical_accuracy: 0.8377\n",
      "Epoch 7/10\n",
      "4878/4878 [==============================] - 7s 2ms/step - loss: 0.0128 - categorical_accuracy: 0.9731 - val_loss: 0.0600 - val_categorical_accuracy: 0.8402\n",
      "Epoch 8/10\n",
      "4878/4878 [==============================] - 7s 2ms/step - loss: 0.0110 - categorical_accuracy: 0.9762 - val_loss: 0.0639 - val_categorical_accuracy: 0.8426\n",
      "Epoch 9/10\n",
      "4878/4878 [==============================] - 7s 2ms/step - loss: 0.0103 - categorical_accuracy: 0.9754 - val_loss: 0.0640 - val_categorical_accuracy: 0.8426\n",
      "Epoch 10/10\n",
      "4878/4878 [==============================] - 8s 2ms/step - loss: 0.0114 - categorical_accuracy: 0.9733 - val_loss: 0.0589 - val_categorical_accuracy: 0.8566\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_54 (Embedding)     (None, 350, 300)          7395000   \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 348, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_54 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 7)                 1757      \n",
      "=================================================================\n",
      "Total params: 7,627,207\n",
      "Trainable params: 232,207\n",
      "Non-trainable params: 7,395,000\n",
      "_________________________________________________________________\n",
      "Train on 611 samples, validate on 153 samples\n",
      "Epoch 1/10\n",
      "611/611 [==============================] - 10s 16ms/step - loss: 0.2729 - categorical_accuracy: 0.5990 - val_loss: 0.1646 - val_categorical_accuracy: 0.7974\n",
      "Epoch 2/10\n",
      "611/611 [==============================] - 1s 2ms/step - loss: 0.1369 - categorical_accuracy: 0.8347 - val_loss: 0.1317 - val_categorical_accuracy: 0.8366\n",
      "Epoch 3/10\n",
      "611/611 [==============================] - 1s 2ms/step - loss: 0.0947 - categorical_accuracy: 0.8822 - val_loss: 0.1096 - val_categorical_accuracy: 0.8824\n",
      "Epoch 4/10\n",
      "611/611 [==============================] - 1s 2ms/step - loss: 0.0686 - categorical_accuracy: 0.9149 - val_loss: 0.1021 - val_categorical_accuracy: 0.8758\n",
      "Epoch 5/10\n",
      "611/611 [==============================] - 1s 2ms/step - loss: 0.0521 - categorical_accuracy: 0.9509 - val_loss: 0.0992 - val_categorical_accuracy: 0.8562\n",
      "Epoch 6/10\n",
      "611/611 [==============================] - 1s 2ms/step - loss: 0.0371 - categorical_accuracy: 0.9542 - val_loss: 0.0939 - val_categorical_accuracy: 0.8889\n",
      "Epoch 7/10\n",
      "611/611 [==============================] - 1s 2ms/step - loss: 0.0198 - categorical_accuracy: 0.9853 - val_loss: 0.0996 - val_categorical_accuracy: 0.8627\n",
      "Epoch 8/10\n",
      "611/611 [==============================] - 1s 2ms/step - loss: 0.0140 - categorical_accuracy: 0.9902 - val_loss: 0.0888 - val_categorical_accuracy: 0.8824\n",
      "Epoch 9/10\n",
      "611/611 [==============================] - 1s 2ms/step - loss: 0.0124 - categorical_accuracy: 0.9853 - val_loss: 0.0896 - val_categorical_accuracy: 0.8889\n",
      "Epoch 10/10\n",
      "611/611 [==============================] - 1s 2ms/step - loss: 0.0078 - categorical_accuracy: 0.9967 - val_loss: 0.0851 - val_categorical_accuracy: 0.8758\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_55 (Embedding)     (None, 350, 300)          7395000   \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 348, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_55 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 5)                 1255      \n",
      "=================================================================\n",
      "Total params: 7,626,705\n",
      "Trainable params: 231,705\n",
      "Non-trainable params: 7,395,000\n",
      "_________________________________________________________________\n",
      "Train on 364 samples, validate on 92 samples\n",
      "Epoch 1/10\n",
      "364/364 [==============================] - 9s 26ms/step - loss: 0.4248 - categorical_accuracy: 0.5357 - val_loss: 0.2042 - val_categorical_accuracy: 0.8913\n",
      "Epoch 2/10\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.2696 - categorical_accuracy: 0.7995 - val_loss: 0.1487 - val_categorical_accuracy: 0.8804\n",
      "Epoch 3/10\n",
      "364/364 [==============================] - 1s 1ms/step - loss: 0.1818 - categorical_accuracy: 0.8489 - val_loss: 0.1155 - val_categorical_accuracy: 0.9022\n",
      "Epoch 4/10\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 0.1081 - categorical_accuracy: 0.9203 - val_loss: 0.0827 - val_categorical_accuracy: 0.9348\n",
      "Epoch 5/10\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 0.0628 - categorical_accuracy: 0.9615 - val_loss: 0.0786 - val_categorical_accuracy: 0.9239\n",
      "Epoch 6/10\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 0.0383 - categorical_accuracy: 0.9890 - val_loss: 0.0516 - val_categorical_accuracy: 0.9674\n",
      "Epoch 7/10\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 0.0207 - categorical_accuracy: 0.9945 - val_loss: 0.0417 - val_categorical_accuracy: 0.9783\n",
      "Epoch 8/10\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 0.0153 - categorical_accuracy: 0.9973 - val_loss: 0.0382 - val_categorical_accuracy: 0.9783\n",
      "Epoch 9/10\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 0.0124 - categorical_accuracy: 0.9973 - val_loss: 0.0360 - val_categorical_accuracy: 0.9783\n",
      "Epoch 10/10\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 0.0080 - categorical_accuracy: 1.0000 - val_loss: 0.0356 - val_categorical_accuracy: 0.9783\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_56 (Embedding)     (None, 350, 300)          7395000   \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 348, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_56 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 8)                 2008      \n",
      "=================================================================\n",
      "Total params: 7,627,458\n",
      "Trainable params: 232,458\n",
      "Non-trainable params: 7,395,000\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 560 samples, validate on 140 samples\n",
      "Epoch 1/10\n",
      "560/560 [==============================] - 10s 18ms/step - loss: 0.3354 - categorical_accuracy: 0.4411 - val_loss: 0.2323 - val_categorical_accuracy: 0.6286\n",
      "Epoch 2/10\n",
      "560/560 [==============================] - 1s 1ms/step - loss: 0.1869 - categorical_accuracy: 0.7196 - val_loss: 0.1531 - val_categorical_accuracy: 0.7786\n",
      "Epoch 3/10\n",
      "560/560 [==============================] - 1s 1ms/step - loss: 0.1064 - categorical_accuracy: 0.8554 - val_loss: 0.1100 - val_categorical_accuracy: 0.8643\n",
      "Epoch 4/10\n",
      "560/560 [==============================] - 1s 1ms/step - loss: 0.0627 - categorical_accuracy: 0.9536 - val_loss: 0.0821 - val_categorical_accuracy: 0.8929\n",
      "Epoch 5/10\n",
      "560/560 [==============================] - 1s 2ms/step - loss: 0.0361 - categorical_accuracy: 0.9714 - val_loss: 0.0685 - val_categorical_accuracy: 0.8929\n",
      "Epoch 6/10\n",
      "560/560 [==============================] - 1s 2ms/step - loss: 0.0206 - categorical_accuracy: 0.9982 - val_loss: 0.0578 - val_categorical_accuracy: 0.9286\n",
      "Epoch 7/10\n",
      "560/560 [==============================] - 1s 2ms/step - loss: 0.0113 - categorical_accuracy: 0.9982 - val_loss: 0.0530 - val_categorical_accuracy: 0.9571\n",
      "Epoch 8/10\n",
      "560/560 [==============================] - 1s 2ms/step - loss: 0.0067 - categorical_accuracy: 1.0000 - val_loss: 0.0483 - val_categorical_accuracy: 0.9571\n",
      "Epoch 9/10\n",
      "560/560 [==============================] - 1s 2ms/step - loss: 0.0041 - categorical_accuracy: 1.0000 - val_loss: 0.0465 - val_categorical_accuracy: 0.9286\n",
      "Epoch 10/10\n",
      "560/560 [==============================] - 1s 2ms/step - loss: 0.0031 - categorical_accuracy: 1.0000 - val_loss: 0.0457 - val_categorical_accuracy: 0.9286\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_57 (Embedding)     (None, 350, 300)          7395000   \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 348, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_57 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 13)                3263      \n",
      "=================================================================\n",
      "Total params: 7,628,713\n",
      "Trainable params: 233,713\n",
      "Non-trainable params: 7,395,000\n",
      "_________________________________________________________________\n",
      "Train on 2132 samples, validate on 533 samples\n",
      "Epoch 1/10\n",
      "2132/2132 [==============================] - 12s 6ms/step - loss: 0.1872 - categorical_accuracy: 0.4686 - val_loss: 0.1322 - val_categorical_accuracy: 0.6567\n",
      "Epoch 2/10\n",
      "2132/2132 [==============================] - 4s 2ms/step - loss: 0.1059 - categorical_accuracy: 0.7444 - val_loss: 0.1030 - val_categorical_accuracy: 0.7448\n",
      "Epoch 3/10\n",
      "2132/2132 [==============================] - 3s 2ms/step - loss: 0.0688 - categorical_accuracy: 0.8504 - val_loss: 0.0846 - val_categorical_accuracy: 0.7992\n",
      "Epoch 4/10\n",
      "2132/2132 [==============================] - 3s 2ms/step - loss: 0.0431 - categorical_accuracy: 0.9118 - val_loss: 0.0730 - val_categorical_accuracy: 0.8143\n",
      "Epoch 5/10\n",
      "2132/2132 [==============================] - 3s 2ms/step - loss: 0.0258 - categorical_accuracy: 0.9648 - val_loss: 0.0736 - val_categorical_accuracy: 0.8105\n",
      "Epoch 6/10\n",
      "2132/2132 [==============================] - 3s 2ms/step - loss: 0.0158 - categorical_accuracy: 0.9765 - val_loss: 0.0700 - val_categorical_accuracy: 0.8161\n",
      "Epoch 7/10\n",
      "2132/2132 [==============================] - 3s 2ms/step - loss: 0.0112 - categorical_accuracy: 0.9873 - val_loss: 0.0702 - val_categorical_accuracy: 0.8311\n",
      "Epoch 8/10\n",
      "2132/2132 [==============================] - 3s 2ms/step - loss: 0.0081 - categorical_accuracy: 0.9873 - val_loss: 0.0717 - val_categorical_accuracy: 0.8180\n",
      "Epoch 9/10\n",
      "2132/2132 [==============================] - 3s 2ms/step - loss: 0.0069 - categorical_accuracy: 0.9906 - val_loss: 0.0748 - val_categorical_accuracy: 0.8180\n",
      "Epoch 10/10\n",
      "2132/2132 [==============================] - 3s 2ms/step - loss: 0.0059 - categorical_accuracy: 0.9920 - val_loss: 0.0720 - val_categorical_accuracy: 0.8199\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_58 (Embedding)     (None, 350, 300)          7395000   \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 348, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_58 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 2)                 502       \n",
      "=================================================================\n",
      "Total params: 7,625,952\n",
      "Trainable params: 230,952\n",
      "Non-trainable params: 7,395,000\n",
      "_________________________________________________________________\n",
      "Train on 101 samples, validate on 26 samples\n",
      "Epoch 1/10\n",
      "101/101 [==============================] - 9s 94ms/step - loss: 2.3432 - categorical_accuracy: 0.2673 - val_loss: 0.5056 - val_categorical_accuracy: 0.8462\n",
      "Epoch 2/10\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9279 - categorical_accuracy: 0.7327 - val_loss: 0.3990 - val_categorical_accuracy: 0.8462\n",
      "Epoch 3/10\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.4957 - categorical_accuracy: 0.7723 - val_loss: 1.8066 - val_categorical_accuracy: 0.1538\n",
      "Epoch 4/10\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.5213 - categorical_accuracy: 0.2871 - val_loss: 2.2837 - val_categorical_accuracy: 0.1538\n",
      "Epoch 5/10\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.9120 - categorical_accuracy: 0.3168 - val_loss: 0.9339 - val_categorical_accuracy: 0.2308\n",
      "Epoch 6/10\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.7342 - categorical_accuracy: 0.5446 - val_loss: 0.2917 - val_categorical_accuracy: 0.8846\n",
      "Epoch 7/10\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.3528 - categorical_accuracy: 0.8515 - val_loss: 0.6480 - val_categorical_accuracy: 0.8462\n",
      "Epoch 8/10\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9961 - categorical_accuracy: 0.7426 - val_loss: 0.9279 - val_categorical_accuracy: 0.8462\n",
      "Epoch 9/10\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.4633 - categorical_accuracy: 0.7327 - val_loss: 1.0687 - val_categorical_accuracy: 0.8462\n",
      "Epoch 10/10\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.6922 - categorical_accuracy: 0.7327 - val_loss: 1.0908 - val_categorical_accuracy: 0.8462\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_59 (Embedding)     (None, 350, 300)          7395000   \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 348, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_59 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 6)                 1506      \n",
      "=================================================================\n",
      "Total params: 7,626,956\n",
      "Trainable params: 231,956\n",
      "Non-trainable params: 7,395,000\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 894 samples, validate on 224 samples\n",
      "Epoch 1/10\n",
      "894/894 [==============================] - 11s 12ms/step - loss: 0.3876 - categorical_accuracy: 0.4922 - val_loss: 0.2467 - val_categorical_accuracy: 0.6741\n",
      "Epoch 2/10\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.2073 - categorical_accuracy: 0.7897 - val_loss: 0.1696 - val_categorical_accuracy: 0.8304\n",
      "Epoch 3/10\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.1165 - categorical_accuracy: 0.8714 - val_loss: 0.1598 - val_categorical_accuracy: 0.8125\n",
      "Epoch 4/10\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0799 - categorical_accuracy: 0.9273 - val_loss: 0.1278 - val_categorical_accuracy: 0.8571\n",
      "Epoch 5/10\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0538 - categorical_accuracy: 0.9418 - val_loss: 0.1248 - val_categorical_accuracy: 0.8705\n",
      "Epoch 6/10\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0348 - categorical_accuracy: 0.9743 - val_loss: 0.1208 - val_categorical_accuracy: 0.8705\n",
      "Epoch 7/10\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0239 - categorical_accuracy: 0.9911 - val_loss: 0.1181 - val_categorical_accuracy: 0.8795\n",
      "Epoch 8/10\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0170 - categorical_accuracy: 0.9933 - val_loss: 0.1236 - val_categorical_accuracy: 0.8616\n",
      "Epoch 9/10\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0125 - categorical_accuracy: 0.9944 - val_loss: 0.1174 - val_categorical_accuracy: 0.8750\n",
      "Epoch 10/10\n",
      "894/894 [==============================] - 1s 2ms/step - loss: 0.0102 - categorical_accuracy: 0.9955 - val_loss: 0.1202 - val_categorical_accuracy: 0.8705\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_60 (Embedding)     (None, 350, 300)          7395000   \n",
      "_________________________________________________________________\n",
      "conv1d_60 (Conv1D)           (None, 348, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_60 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 3)                 753       \n",
      "=================================================================\n",
      "Total params: 7,626,203\n",
      "Trainable params: 231,203\n",
      "Non-trainable params: 7,395,000\n",
      "_________________________________________________________________\n",
      "Train on 2768 samples, validate on 692 samples\n",
      "Epoch 1/10\n",
      "2768/2768 [==============================] - 14s 5ms/step - loss: 0.1520 - categorical_accuracy: 0.9516 - val_loss: 0.0999 - val_categorical_accuracy: 0.9783\n",
      "Epoch 2/10\n",
      "2768/2768 [==============================] - 4s 2ms/step - loss: 0.0876 - categorical_accuracy: 0.9805 - val_loss: 0.0741 - val_categorical_accuracy: 0.9827\n",
      "Epoch 3/10\n",
      "2768/2768 [==============================] - 4s 2ms/step - loss: 0.0400 - categorical_accuracy: 0.9841 - val_loss: 0.0299 - val_categorical_accuracy: 0.9827\n",
      "Epoch 4/10\n",
      "2768/2768 [==============================] - 4s 2ms/step - loss: 0.0113 - categorical_accuracy: 0.9953 - val_loss: 0.0260 - val_categorical_accuracy: 0.9827\n",
      "Epoch 5/10\n",
      "2768/2768 [==============================] - 4s 2ms/step - loss: 0.0054 - categorical_accuracy: 0.9982 - val_loss: 0.0217 - val_categorical_accuracy: 0.9855\n",
      "Epoch 6/10\n",
      "2768/2768 [==============================] - 4s 2ms/step - loss: 0.0026 - categorical_accuracy: 0.9996 - val_loss: 0.0195 - val_categorical_accuracy: 0.9855\n",
      "Epoch 7/10\n",
      "2768/2768 [==============================] - 4s 2ms/step - loss: 0.0022 - categorical_accuracy: 0.9993 - val_loss: 0.0200 - val_categorical_accuracy: 0.9884\n",
      "Epoch 8/10\n",
      "2768/2768 [==============================] - 4s 2ms/step - loss: 0.0011 - categorical_accuracy: 1.0000 - val_loss: 0.0235 - val_categorical_accuracy: 0.9855\n",
      "Epoch 9/10\n",
      "2768/2768 [==============================] - 4s 2ms/step - loss: 0.0015 - categorical_accuracy: 0.9996 - val_loss: 0.0186 - val_categorical_accuracy: 0.9884\n",
      "Epoch 10/10\n",
      "2768/2768 [==============================] - 4s 2ms/step - loss: 9.3027e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0204 - val_categorical_accuracy: 0.9855\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_61 (Embedding)     (None, 350, 300)          7395000   \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 348, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_61 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 3)                 753       \n",
      "=================================================================\n",
      "Total params: 7,626,203\n",
      "Trainable params: 231,203\n",
      "Non-trainable params: 7,395,000\n",
      "_________________________________________________________________\n",
      "Train on 682 samples, validate on 171 samples\n",
      "Epoch 1/10\n",
      "682/682 [==============================] - 11s 16ms/step - loss: 0.3623 - categorical_accuracy: 0.7947 - val_loss: 0.2283 - val_categorical_accuracy: 0.8596\n",
      "Epoch 2/10\n",
      "682/682 [==============================] - 1s 2ms/step - loss: 0.1146 - categorical_accuracy: 0.9223 - val_loss: 0.1038 - val_categorical_accuracy: 0.9357\n",
      "Epoch 3/10\n",
      "682/682 [==============================] - 1s 2ms/step - loss: 0.0500 - categorical_accuracy: 0.9721 - val_loss: 0.0832 - val_categorical_accuracy: 0.9532\n",
      "Epoch 4/10\n",
      "682/682 [==============================] - 1s 2ms/step - loss: 0.0252 - categorical_accuracy: 0.9839 - val_loss: 0.0614 - val_categorical_accuracy: 0.9532\n",
      "Epoch 5/10\n",
      "682/682 [==============================] - 1s 2ms/step - loss: 0.0156 - categorical_accuracy: 0.9927 - val_loss: 0.0422 - val_categorical_accuracy: 0.9708\n",
      "Epoch 6/10\n",
      "682/682 [==============================] - 1s 2ms/step - loss: 0.0068 - categorical_accuracy: 1.0000 - val_loss: 0.0548 - val_categorical_accuracy: 0.9649\n",
      "Epoch 7/10\n",
      "682/682 [==============================] - 1s 2ms/step - loss: 0.0042 - categorical_accuracy: 1.0000 - val_loss: 0.0638 - val_categorical_accuracy: 0.9591\n",
      "Epoch 8/10\n",
      "682/682 [==============================] - 1s 2ms/step - loss: 0.0032 - categorical_accuracy: 1.0000 - val_loss: 0.0538 - val_categorical_accuracy: 0.9649\n",
      "Epoch 9/10\n",
      "682/682 [==============================] - 1s 2ms/step - loss: 0.0018 - categorical_accuracy: 1.0000 - val_loss: 0.0482 - val_categorical_accuracy: 0.9708\n",
      "Epoch 10/10\n",
      "682/682 [==============================] - 1s 2ms/step - loss: 0.0015 - categorical_accuracy: 1.0000 - val_loss: 0.0463 - val_categorical_accuracy: 0.9766\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_62 (Embedding)     (None, 350, 300)          7395000   \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 348, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_62 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 9)                 2259      \n",
      "=================================================================\n",
      "Total params: 7,627,709\n",
      "Trainable params: 232,709\n",
      "Non-trainable params: 7,395,000\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 656 samples, validate on 164 samples\n",
      "Epoch 1/10\n",
      "656/656 [==============================] - 11s 16ms/step - loss: 0.2806 - categorical_accuracy: 0.4238 - val_loss: 0.2040 - val_categorical_accuracy: 0.6280\n",
      "Epoch 2/10\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1531 - categorical_accuracy: 0.6997 - val_loss: 0.1614 - val_categorical_accuracy: 0.6646\n",
      "Epoch 3/10\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1031 - categorical_accuracy: 0.8323 - val_loss: 0.1383 - val_categorical_accuracy: 0.7073\n",
      "Epoch 4/10\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.0703 - categorical_accuracy: 0.8872 - val_loss: 0.1168 - val_categorical_accuracy: 0.8110\n",
      "Epoch 5/10\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.0467 - categorical_accuracy: 0.9512 - val_loss: 0.1088 - val_categorical_accuracy: 0.8293\n",
      "Epoch 6/10\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.0337 - categorical_accuracy: 0.9680 - val_loss: 0.0986 - val_categorical_accuracy: 0.8415\n",
      "Epoch 7/10\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.0219 - categorical_accuracy: 0.9878 - val_loss: 0.0914 - val_categorical_accuracy: 0.8537\n",
      "Epoch 8/10\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.0154 - categorical_accuracy: 0.9939 - val_loss: 0.0889 - val_categorical_accuracy: 0.8537\n",
      "Epoch 9/10\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.0109 - categorical_accuracy: 0.9954 - val_loss: 0.0941 - val_categorical_accuracy: 0.8537\n",
      "Epoch 10/10\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.0079 - categorical_accuracy: 0.9954 - val_loss: 0.0818 - val_categorical_accuracy: 0.8659\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_63 (Embedding)     (None, 350, 300)          7395000   \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 348, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_63 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 10)                2510      \n",
      "=================================================================\n",
      "Total params: 7,627,960\n",
      "Trainable params: 232,960\n",
      "Non-trainable params: 7,395,000\n",
      "_________________________________________________________________\n",
      "Train on 3201 samples, validate on 801 samples\n",
      "Epoch 1/10\n",
      "3201/3201 [==============================] - 15s 5ms/step - loss: 0.2388 - categorical_accuracy: 0.4764 - val_loss: 0.1721 - val_categorical_accuracy: 0.7054\n",
      "Epoch 2/10\n",
      "3201/3201 [==============================] - 5s 2ms/step - loss: 0.1517 - categorical_accuracy: 0.7020 - val_loss: 0.1466 - val_categorical_accuracy: 0.7016\n",
      "Epoch 3/10\n",
      "3201/3201 [==============================] - 5s 2ms/step - loss: 0.1000 - categorical_accuracy: 0.8166 - val_loss: 0.1150 - val_categorical_accuracy: 0.7790\n",
      "Epoch 4/10\n",
      "3201/3201 [==============================] - 5s 2ms/step - loss: 0.0658 - categorical_accuracy: 0.8928 - val_loss: 0.1219 - val_categorical_accuracy: 0.7591\n",
      "Epoch 5/10\n",
      "3201/3201 [==============================] - 5s 2ms/step - loss: 0.0630 - categorical_accuracy: 0.8947 - val_loss: 0.1129 - val_categorical_accuracy: 0.7790\n",
      "Epoch 6/10\n",
      "3201/3201 [==============================] - 5s 2ms/step - loss: 0.0351 - categorical_accuracy: 0.9541 - val_loss: 0.1028 - val_categorical_accuracy: 0.8077\n",
      "Epoch 7/10\n",
      "3201/3201 [==============================] - 5s 2ms/step - loss: 0.0217 - categorical_accuracy: 0.9747 - val_loss: 0.1027 - val_categorical_accuracy: 0.8177\n",
      "Epoch 8/10\n",
      "3201/3201 [==============================] - 5s 2ms/step - loss: 0.0152 - categorical_accuracy: 0.9866 - val_loss: 0.1058 - val_categorical_accuracy: 0.8165\n",
      "Epoch 9/10\n",
      "3201/3201 [==============================] - 5s 2ms/step - loss: 0.0128 - categorical_accuracy: 0.9881 - val_loss: 0.1151 - val_categorical_accuracy: 0.7778\n",
      "Epoch 10/10\n",
      "3201/3201 [==============================] - 5s 2ms/step - loss: 0.0197 - categorical_accuracy: 0.9719 - val_loss: 0.1151 - val_categorical_accuracy: 0.7928\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_64 (Embedding)     (None, 350, 300)          7395000   \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 348, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_64 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 5)                 1255      \n",
      "=================================================================\n",
      "Total params: 7,626,705\n",
      "Trainable params: 231,705\n",
      "Non-trainable params: 7,395,000\n",
      "_________________________________________________________________\n",
      "Train on 368 samples, validate on 93 samples\n",
      "Epoch 1/10\n",
      "368/368 [==============================] - 11s 29ms/step - loss: 0.4716 - categorical_accuracy: 0.4783 - val_loss: 0.3053 - val_categorical_accuracy: 0.6882\n",
      "Epoch 2/10\n",
      "368/368 [==============================] - 1s 2ms/step - loss: 0.2349 - categorical_accuracy: 0.7826 - val_loss: 0.2112 - val_categorical_accuracy: 0.7957\n",
      "Epoch 3/10\n",
      "368/368 [==============================] - 1s 2ms/step - loss: 0.1532 - categorical_accuracy: 0.8533 - val_loss: 0.1614 - val_categorical_accuracy: 0.8495\n",
      "Epoch 4/10\n",
      "368/368 [==============================] - 1s 2ms/step - loss: 0.0864 - categorical_accuracy: 0.9348 - val_loss: 0.1041 - val_categorical_accuracy: 0.9140\n",
      "Epoch 5/10\n",
      "368/368 [==============================] - 1s 2ms/step - loss: 0.0521 - categorical_accuracy: 0.9783 - val_loss: 0.0827 - val_categorical_accuracy: 0.9570\n",
      "Epoch 6/10\n",
      "368/368 [==============================] - 1s 2ms/step - loss: 0.0334 - categorical_accuracy: 0.9891 - val_loss: 0.0646 - val_categorical_accuracy: 0.9462\n",
      "Epoch 7/10\n",
      "368/368 [==============================] - 1s 2ms/step - loss: 0.0192 - categorical_accuracy: 0.9973 - val_loss: 0.0541 - val_categorical_accuracy: 0.9677\n",
      "Epoch 8/10\n",
      "368/368 [==============================] - 1s 2ms/step - loss: 0.0127 - categorical_accuracy: 0.9973 - val_loss: 0.0467 - val_categorical_accuracy: 0.9785\n",
      "Epoch 9/10\n",
      "368/368 [==============================] - 1s 2ms/step - loss: 0.0079 - categorical_accuracy: 0.9973 - val_loss: 0.0406 - val_categorical_accuracy: 0.9785\n",
      "Epoch 10/10\n",
      "368/368 [==============================] - 1s 2ms/step - loss: 0.0059 - categorical_accuracy: 1.0000 - val_loss: 0.0363 - val_categorical_accuracy: 0.9785\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_65 (Embedding)     (None, 350, 300)          7395000   \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 348, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_65 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_130 (Dense)            (None, 3)                 753       \n",
      "=================================================================\n",
      "Total params: 7,626,203\n",
      "Trainable params: 231,203\n",
      "Non-trainable params: 7,395,000\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 221 samples, validate on 56 samples\n",
      "Epoch 1/10\n",
      "221/221 [==============================] - 11s 50ms/step - loss: 0.5466 - categorical_accuracy: 0.5520 - val_loss: 0.4484 - val_categorical_accuracy: 0.6607\n",
      "Epoch 2/10\n",
      "221/221 [==============================] - 0s 2ms/step - loss: 0.3203 - categorical_accuracy: 0.7511 - val_loss: 0.2764 - val_categorical_accuracy: 0.8750\n",
      "Epoch 3/10\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.1670 - categorical_accuracy: 0.9186 - val_loss: 0.1862 - val_categorical_accuracy: 0.8750\n",
      "Epoch 4/10\n",
      "221/221 [==============================] - 0s 2ms/step - loss: 0.1349 - categorical_accuracy: 0.9412 - val_loss: 0.1379 - val_categorical_accuracy: 0.9286\n",
      "Epoch 5/10\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.0620 - categorical_accuracy: 0.9774 - val_loss: 0.1882 - val_categorical_accuracy: 0.8571\n",
      "Epoch 6/10\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.0694 - categorical_accuracy: 0.9638 - val_loss: 0.1649 - val_categorical_accuracy: 0.8571\n",
      "Epoch 7/10\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.0336 - categorical_accuracy: 0.9910 - val_loss: 0.1006 - val_categorical_accuracy: 0.9107\n",
      "Epoch 8/10\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.0181 - categorical_accuracy: 1.0000 - val_loss: 0.0853 - val_categorical_accuracy: 0.9643\n",
      "Epoch 9/10\n",
      "221/221 [==============================] - 0s 2ms/step - loss: 0.0171 - categorical_accuracy: 1.0000 - val_loss: 0.0833 - val_categorical_accuracy: 0.9464\n",
      "Epoch 10/10\n",
      "221/221 [==============================] - 0s 2ms/step - loss: 0.0152 - categorical_accuracy: 1.0000 - val_loss: 0.0691 - val_categorical_accuracy: 0.9643\n"
     ]
    }
   ],
   "source": [
    "classifiers= HCM.subclassifiers(parenttoChildFeature,parenttoChildSubcategory,embedding_matrix,350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_66 (Embedding)     (None, 350, 300)          7395000   \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 348, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_66 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_131 (Dense)            (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_132 (Dense)            (None, 32)                8032      \n",
      "=================================================================\n",
      "Total params: 7,633,482\n",
      "Trainable params: 238,482\n",
      "Non-trainable params: 7,395,000\n",
      "_________________________________________________________________\n",
      "Train on 75150 samples, validate on 18788 samples\n",
      "Epoch 1/10\n",
      "75150/75150 [==============================] - 127s 2ms/step - loss: 0.0371 - categorical_accuracy: 0.7962 - val_loss: 0.0275 - val_categorical_accuracy: 0.8522\n",
      "Epoch 2/10\n",
      "75150/75150 [==============================] - 118s 2ms/step - loss: 0.0230 - categorical_accuracy: 0.8758 - val_loss: 0.0248 - val_categorical_accuracy: 0.8658\n",
      "Epoch 3/10\n",
      "75150/75150 [==============================] - 116s 2ms/step - loss: 0.0184 - categorical_accuracy: 0.9012 - val_loss: 0.0260 - val_categorical_accuracy: 0.8614\n",
      "Epoch 4/10\n",
      "75150/75150 [==============================] - 116s 2ms/step - loss: 0.0150 - categorical_accuracy: 0.9195 - val_loss: 0.0265 - val_categorical_accuracy: 0.8647\n",
      "Epoch 5/10\n",
      "75150/75150 [==============================] - 116s 2ms/step - loss: 0.0128 - categorical_accuracy: 0.9329 - val_loss: 0.0288 - val_categorical_accuracy: 0.8551\n",
      "Epoch 6/10\n",
      "75150/75150 [==============================] - 115s 2ms/step - loss: 0.0111 - categorical_accuracy: 0.9432 - val_loss: 0.0306 - val_categorical_accuracy: 0.8624\n",
      "Epoch 7/10\n",
      "75150/75150 [==============================] - 116s 2ms/step - loss: 0.0101 - categorical_accuracy: 0.9496 - val_loss: 0.0317 - val_categorical_accuracy: 0.8636\n",
      "Epoch 8/10\n",
      "75150/75150 [==============================] - 116s 2ms/step - loss: 0.0095 - categorical_accuracy: 0.9537 - val_loss: 0.0323 - val_categorical_accuracy: 0.8632\n",
      "Epoch 9/10\n",
      "75150/75150 [==============================] - 115s 2ms/step - loss: 0.0088 - categorical_accuracy: 0.9576 - val_loss: 0.0350 - val_categorical_accuracy: 0.8643\n",
      "Epoch 10/10\n",
      "75150/75150 [==============================] - 116s 2ms/step - loss: 0.0084 - categorical_accuracy: 0.9603 - val_loss: 0.0350 - val_categorical_accuracy: 0.8633\n",
      "CPU times: user 5 s, sys: 0 ns, total: 5 s\n",
      "Wall time: 9.78 s\n"
     ]
    }
   ],
   "source": [
    "y_pred = HCM.firstLevelModelTraining(sequences,sequences_test,embedding_matrix,350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 s, sys: 0 ns, total: 5 s\n",
      "Wall time: 10 s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.86      0.91       207\n",
      "           1       0.79      0.50      0.61        30\n",
      "           2       0.68      0.88      0.77       523\n",
      "           3       0.83      0.56      0.67        18\n",
      "           4       0.45      0.29      0.36        34\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.33      0.14      0.20        35\n",
      "           7       0.50      0.17      0.25         6\n",
      "           8       0.75      0.27      0.40        44\n",
      "           9       0.71      0.27      0.39        44\n",
      "          10       0.14      0.09      0.11        11\n",
      "          11       0.38      0.21      0.27        14\n",
      "          12       1.00      0.64      0.78        11\n",
      "          13       1.00      0.33      0.50         6\n",
      "          14       0.50      0.33      0.40        36\n",
      "          15       0.96      0.66      0.78        38\n",
      "          16       0.76      0.45      0.57        29\n",
      "          17       0.83      0.70      0.76       180\n",
      "          18       0.44      0.41      0.42        83\n",
      "          19       0.69      0.73      0.71        62\n",
      "          20       0.79      0.78      0.79       505\n",
      "          21       0.88      0.94      0.91      4198\n",
      "          22       0.80      0.81      0.80        63\n",
      "          23       0.90      0.64      0.75        14\n",
      "          24       0.92      0.91      0.91       778\n",
      "          25       0.86      0.68      0.76      1681\n",
      "          26       0.70      0.61      0.65       108\n",
      "          27       0.59      0.91      0.72      1347\n",
      "          28       0.75      0.21      0.33        42\n",
      "          29       0.80      0.52      0.63       208\n",
      "          30       0.48      0.65      0.56        23\n",
      "          31       0.67      0.58      0.62        24\n",
      "          32       0.59      0.68      0.63        78\n",
      "          33       0.42      0.50      0.45        10\n",
      "          34       0.90      0.70      0.79        37\n",
      "          35       0.80      0.81      0.80       116\n",
      "          36       1.00      0.85      0.92        13\n",
      "          37       0.82      0.43      0.56        21\n",
      "          38       1.00      0.43      0.60         7\n",
      "          39       0.47      0.54      0.50        13\n",
      "          40       0.88      0.70      0.78        10\n",
      "          41       1.00      0.33      0.50         6\n",
      "          42       0.77      0.84      0.80       120\n",
      "          43       0.93      0.75      0.83       214\n",
      "          44       0.68      0.62      0.65       302\n",
      "          45       0.58      0.28      0.38       183\n",
      "          46       0.65      0.47      0.55       176\n",
      "          47       0.47      0.62      0.53       652\n",
      "          48       0.07      0.02      0.03        48\n",
      "          49       0.49      0.70      0.57       653\n",
      "          50       0.21      0.11      0.15        27\n",
      "          51       0.00      0.00      0.00         4\n",
      "          52       0.28      0.29      0.29        17\n",
      "          53       0.70      0.65      0.67       419\n",
      "          54       0.68      0.62      0.65        94\n",
      "          55       0.50      0.54      0.52       161\n",
      "          56       0.00      0.00      0.00        11\n",
      "          57       0.89      0.89      0.89        18\n",
      "          58       1.00      0.88      0.93         8\n",
      "          59       0.64      0.57      0.60        28\n",
      "          60       0.38      0.33      0.36        15\n",
      "          61       0.36      0.40      0.38        20\n",
      "          62       0.88      0.70      0.78        30\n",
      "          63       0.93      1.00      0.96        13\n",
      "          64       1.00      0.07      0.13        14\n",
      "          65       0.69      0.67      0.68        66\n",
      "          66       0.50      0.67      0.57        24\n",
      "          67       0.51      0.69      0.59       119\n",
      "          68       0.67      0.76      0.72       102\n",
      "          69       0.90      0.82      0.86        11\n",
      "          70       0.96      0.68      0.79        34\n",
      "          71       0.28      0.47      0.35       101\n",
      "          72       0.66      0.67      0.67       132\n",
      "          73       0.60      0.37      0.46       196\n",
      "          74       0.81      0.85      0.83       447\n",
      "          75       0.56      0.55      0.55        88\n",
      "          76       0.50      0.56      0.53        32\n",
      "          77       0.56      0.38      0.45        13\n",
      "          78       0.89      0.90      0.89       224\n",
      "          79       0.84      0.87      0.86       256\n",
      "          80       0.39      0.52      0.45        64\n",
      "          81       0.47      1.00      0.64         8\n",
      "          82       0.73      0.58      0.65       200\n",
      "          83       0.64      0.78      0.70         9\n",
      "          84       0.60      0.40      0.48        45\n",
      "          85       0.50      0.56      0.53        50\n",
      "          86       0.56      0.38      0.45        13\n",
      "          87       0.75      0.34      0.47        35\n",
      "          88       0.69      0.77      0.73        98\n",
      "          89       1.00      0.33      0.50         6\n",
      "          90       0.67      0.77      0.72       875\n",
      "          91       0.62      0.50      0.56        10\n",
      "          92       0.58      0.73      0.64        26\n",
      "          93       0.67      0.50      0.57        48\n",
      "          94       0.56      0.31      0.40        74\n",
      "          95       0.92      0.96      0.94       310\n",
      "          96       0.80      0.70      0.75        63\n",
      "          97       0.67      0.33      0.44        12\n",
      "          98       0.60      0.19      0.29        31\n",
      "          99       0.67      0.67      0.67         9\n",
      "         100       0.78      0.78      0.78        23\n",
      "         101       0.72      0.72      0.72        18\n",
      "         102       0.00      0.00      0.00         9\n",
      "         103       0.71      0.69      0.70       288\n",
      "         104       0.84      0.94      0.89        84\n",
      "         105       0.50      0.50      0.50        10\n",
      "         106       0.57      0.48      0.52        96\n",
      "         107       1.00      0.50      0.67         6\n",
      "         108       0.66      0.91      0.76        90\n",
      "         109       0.89      0.94      0.91        34\n",
      "         110       0.41      0.26      0.32        34\n",
      "         111       0.81      0.78      0.79       230\n",
      "         112       0.50      0.08      0.14        12\n",
      "         113       0.79      0.92      0.85        12\n",
      "         114       1.00      0.07      0.12        15\n",
      "         115       0.27      0.33      0.30         9\n",
      "         116       0.00      0.00      0.00         6\n",
      "         117       0.55      0.43      0.48        14\n",
      "         118       0.97      0.69      0.80       166\n",
      "         119       0.93      1.00      0.96        13\n",
      "         120       1.00      0.12      0.22         8\n",
      "         121       0.60      0.33      0.43         9\n",
      "         122       0.57      0.50      0.53         8\n",
      "         123       0.88      0.86      0.87        49\n",
      "         124       0.40      0.18      0.25        22\n",
      "         125       0.33      0.09      0.14        11\n",
      "         126       0.85      0.46      0.59       210\n",
      "         127       0.93      0.56      0.70        70\n",
      "         128       0.80      0.82      0.81        39\n",
      "         129       0.60      0.60      0.60         5\n",
      "         130       0.22      0.25      0.23        20\n",
      "         131       0.81      0.35      0.49        37\n",
      "         132       0.42      0.22      0.29       125\n",
      "         133       0.23      0.20      0.21        15\n",
      "         134       0.00      0.00      0.00        11\n",
      "         135       0.00      0.00      0.00         7\n",
      "         136       0.50      0.54      0.52        13\n",
      "         137       0.43      0.25      0.32        12\n",
      "         138       0.70      0.58      0.64        12\n",
      "         139       0.28      0.15      0.19        62\n",
      "         140       0.00      0.00      0.00         6\n",
      "         141       0.60      0.21      0.32        14\n",
      "         142       1.00      1.00      1.00         4\n",
      "         143       0.00      0.00      0.00         9\n",
      "         144       0.86      0.75      0.80        16\n",
      "         145       0.42      0.44      0.43        18\n",
      "         146       1.00      0.23      0.38        13\n",
      "         147       0.00      0.00      0.00         6\n",
      "         148       0.88      1.00      0.93         7\n",
      "         149       0.75      0.50      0.60         6\n",
      "         150       0.00      0.00      0.00         8\n",
      "         151       0.80      0.64      0.71        99\n",
      "         152       0.44      0.15      0.23        26\n",
      "         153       0.12      0.25      0.17        16\n",
      "         154       0.53      0.69      0.60        13\n",
      "         155       0.50      0.33      0.40        12\n",
      "         156       0.52      0.53      0.52        32\n",
      "         157       0.41      0.21      0.28        43\n",
      "         158       0.40      0.44      0.42         9\n",
      "         159       0.62      0.93      0.75        54\n",
      "         160       0.06      0.03      0.04        34\n",
      "         161       0.00      0.00      0.00         7\n",
      "         162       0.92      0.63      0.75        19\n",
      "         163       0.22      0.06      0.10        32\n",
      "         164       0.25      0.29      0.27         7\n",
      "         165       0.00      0.00      0.00        12\n",
      "         166       0.69      0.62      0.65       230\n",
      "         167       0.20      0.04      0.06        26\n",
      "         168       0.62      0.44      0.52        90\n",
      "         169       0.57      0.36      0.44        11\n",
      "         170       0.44      0.44      0.44       156\n",
      "         171       0.55      0.27      0.36        22\n",
      "         172       0.25      0.51      0.34        47\n",
      "         173       0.80      0.40      0.53        10\n",
      "         174       0.57      0.31      0.40        13\n",
      "         175       0.00      0.00      0.00         8\n",
      "         176       0.71      0.59      0.64        29\n",
      "         177       0.00      0.00      0.00         7\n",
      "         178       0.14      0.40      0.21         5\n",
      "         179       1.00      0.43      0.60         7\n",
      "         180       1.00      0.50      0.67        10\n",
      "         181       0.93      0.58      0.72        24\n",
      "         182       0.89      0.62      0.73        13\n",
      "         183       0.94      0.54      0.68       430\n",
      "         184       0.77      0.75      0.76        32\n",
      "         185       0.51      0.68      0.58        56\n",
      "         186       0.33      0.20      0.25        10\n",
      "         187       1.00      0.65      0.79        23\n",
      "         188       0.37      0.33      0.35        21\n",
      "         189       0.46      0.30      0.36        20\n",
      "         190       0.88      0.78      0.82         9\n",
      "         191       0.53      0.52      0.52       102\n",
      "         192       0.35      0.12      0.18        56\n",
      "         193       0.85      0.89      0.87      1648\n",
      "         194       0.00      0.00      0.00        22\n",
      "         195       0.00      0.00      0.00         7\n",
      "         196       0.47      0.31      0.38        29\n",
      "         197       0.50      0.06      0.11        16\n",
      "         198       0.30      0.46      0.36        13\n",
      "         199       0.50      0.33      0.40         6\n",
      "         200       0.91      0.70      0.79        43\n",
      "         201       0.22      0.11      0.15        18\n",
      "\n",
      "   micro avg       0.73      0.73      0.73     23485\n",
      "   macro avg       0.59      0.48      0.51     23485\n",
      "weighted avg       0.74      0.73      0.72     23485\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/justin/classification/app/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_nd = HCM.PredictSecondLevel(classifiers,y_pred ,sequences_test,350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_67 (Embedding)     (None, 350, 300)          7395000   \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 348, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_67 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_133 (Dense)            (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_134 (Dense)            (None, 202)               50702     \n",
      "=================================================================\n",
      "Total params: 7,676,152\n",
      "Trainable params: 281,152\n",
      "Non-trainable params: 7,395,000\n",
      "_________________________________________________________________\n",
      "Train on 75150 samples, validate on 18788 samples\n",
      "Epoch 1/10\n",
      "75150/75150 [==============================] - 129s 2ms/step - loss: 0.0117 - categorical_accuracy: 0.6109 - val_loss: 0.0087 - val_categorical_accuracy: 0.7028\n",
      "Epoch 2/10\n",
      "75150/75150 [==============================] - 120s 2ms/step - loss: 0.0078 - categorical_accuracy: 0.7290 - val_loss: 0.0079 - val_categorical_accuracy: 0.7219\n",
      "Epoch 3/10\n",
      "75150/75150 [==============================] - 119s 2ms/step - loss: 0.0065 - categorical_accuracy: 0.7689 - val_loss: 0.0077 - val_categorical_accuracy: 0.7379\n",
      "Epoch 4/10\n",
      "75150/75150 [==============================] - 119s 2ms/step - loss: 0.0057 - categorical_accuracy: 0.7958 - val_loss: 0.0079 - val_categorical_accuracy: 0.7326\n",
      "Epoch 5/10\n",
      "75150/75150 [==============================] - 117s 2ms/step - loss: 0.0051 - categorical_accuracy: 0.8178 - val_loss: 0.0080 - val_categorical_accuracy: 0.7405\n",
      "Epoch 6/10\n",
      "75150/75150 [==============================] - 117s 2ms/step - loss: 0.0047 - categorical_accuracy: 0.8328 - val_loss: 0.0081 - val_categorical_accuracy: 0.7443\n",
      "Epoch 7/10\n",
      "75150/75150 [==============================] - 118s 2ms/step - loss: 0.0043 - categorical_accuracy: 0.8491 - val_loss: 0.0087 - val_categorical_accuracy: 0.7305\n",
      "Epoch 8/10\n",
      "75150/75150 [==============================] - 117s 2ms/step - loss: 0.0040 - categorical_accuracy: 0.8591 - val_loss: 0.0089 - val_categorical_accuracy: 0.7326\n",
      "Epoch 9/10\n",
      "75150/75150 [==============================] - 118s 2ms/step - loss: 0.0037 - categorical_accuracy: 0.8692 - val_loss: 0.0091 - val_categorical_accuracy: 0.7349\n",
      "Epoch 10/10\n",
      "75150/75150 [==============================] - 119s 2ms/step - loss: 0.0035 - categorical_accuracy: 0.8769 - val_loss: 0.0095 - val_categorical_accuracy: 0.7390\n",
      "CPU times: user 5 s, sys: 0 ns, total: 5 s\n",
      "Wall time: 10.3 s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88       207\n",
      "           1       0.54      0.73      0.62        30\n",
      "           2       0.80      0.83      0.81       523\n",
      "           3       0.68      0.72      0.70        18\n",
      "           4       0.67      0.35      0.46        34\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.43      0.29      0.34        35\n",
      "           7       0.40      0.33      0.36         6\n",
      "           8       0.56      0.55      0.55        44\n",
      "           9       0.71      0.23      0.34        44\n",
      "          10       0.33      0.18      0.24        11\n",
      "          11       0.15      0.14      0.15        14\n",
      "          12       0.75      0.55      0.63        11\n",
      "          13       0.80      0.67      0.73         6\n",
      "          14       0.63      0.33      0.44        36\n",
      "          15       0.77      0.79      0.78        38\n",
      "          16       0.54      0.52      0.53        29\n",
      "          17       0.79      0.72      0.76       180\n",
      "          18       0.52      0.36      0.43        83\n",
      "          19       0.70      0.63      0.66        62\n",
      "          20       0.79      0.75      0.77       505\n",
      "          21       0.89      0.94      0.92      4198\n",
      "          22       0.79      0.79      0.79        63\n",
      "          23       0.59      0.93      0.72        14\n",
      "          24       0.94      0.88      0.91       778\n",
      "          25       0.79      0.79      0.79      1681\n",
      "          26       0.67      0.55      0.60       108\n",
      "          27       0.69      0.83      0.76      1347\n",
      "          28       0.47      0.17      0.25        42\n",
      "          29       0.90      0.44      0.59       208\n",
      "          30       0.35      0.57      0.43        23\n",
      "          31       0.75      0.50      0.60        24\n",
      "          32       0.55      0.65      0.60        78\n",
      "          33       0.45      0.50      0.48        10\n",
      "          34       0.82      0.62      0.71        37\n",
      "          35       0.91      0.71      0.80       116\n",
      "          36       0.58      0.85      0.69        13\n",
      "          37       0.79      0.71      0.75        21\n",
      "          38       0.00      0.00      0.00         7\n",
      "          39       0.58      0.54      0.56        13\n",
      "          40       0.78      0.70      0.74        10\n",
      "          41       0.67      0.67      0.67         6\n",
      "          42       0.87      0.79      0.83       120\n",
      "          43       0.89      0.75      0.82       214\n",
      "          44       0.66      0.50      0.57       302\n",
      "          45       0.44      0.40      0.42       183\n",
      "          46       0.55      0.50      0.52       176\n",
      "          47       0.46      0.58      0.52       652\n",
      "          48       0.21      0.19      0.20        48\n",
      "          49       0.50      0.68      0.58       653\n",
      "          50       0.05      0.04      0.04        27\n",
      "          51       0.00      0.00      0.00         4\n",
      "          52       0.11      0.12      0.11        17\n",
      "          53       0.60      0.73      0.66       419\n",
      "          54       0.70      0.60      0.64        94\n",
      "          55       0.66      0.48      0.56       161\n",
      "          56       0.00      0.00      0.00        11\n",
      "          57       0.94      0.83      0.88        18\n",
      "          58       0.80      1.00      0.89         8\n",
      "          59       0.55      0.39      0.46        28\n",
      "          60       0.31      0.27      0.29        15\n",
      "          61       0.62      0.25      0.36        20\n",
      "          62       0.91      0.70      0.79        30\n",
      "          63       0.87      1.00      0.93        13\n",
      "          64       0.00      0.00      0.00        14\n",
      "          65       0.59      0.74      0.66        66\n",
      "          66       0.57      0.33      0.42        24\n",
      "          67       0.69      0.53      0.60       119\n",
      "          68       0.64      0.77      0.70       102\n",
      "          69       1.00      0.82      0.90        11\n",
      "          70       0.92      0.68      0.78        34\n",
      "          71       0.42      0.32      0.36       101\n",
      "          72       0.77      0.59      0.67       132\n",
      "          73       0.47      0.51      0.49       196\n",
      "          74       0.78      0.88      0.83       447\n",
      "          75       0.37      0.49      0.42        88\n",
      "          76       0.42      0.25      0.31        32\n",
      "          77       0.67      0.31      0.42        13\n",
      "          78       0.90      0.88      0.89       224\n",
      "          79       0.74      0.91      0.82       256\n",
      "          80       0.62      0.38      0.47        64\n",
      "          81       0.64      0.88      0.74         8\n",
      "          82       0.81      0.52      0.63       200\n",
      "          83       0.64      0.78      0.70         9\n",
      "          84       0.57      0.47      0.51        45\n",
      "          85       0.43      0.52      0.47        50\n",
      "          86       0.44      0.31      0.36        13\n",
      "          87       0.90      0.51      0.65        35\n",
      "          88       0.68      0.83      0.74        98\n",
      "          89       0.20      0.17      0.18         6\n",
      "          90       0.68      0.78      0.73       875\n",
      "          91       0.80      0.40      0.53        10\n",
      "          92       0.73      0.31      0.43        26\n",
      "          93       0.70      0.40      0.51        48\n",
      "          94       0.47      0.26      0.33        74\n",
      "          95       0.90      0.94      0.91       310\n",
      "          96       0.77      0.70      0.73        63\n",
      "          97       1.00      0.17      0.29        12\n",
      "          98       0.26      0.29      0.28        31\n",
      "          99       0.83      0.56      0.67         9\n",
      "         100       1.00      0.39      0.56        23\n",
      "         101       1.00      0.61      0.76        18\n",
      "         102       0.43      0.33      0.38         9\n",
      "         103       0.66      0.66      0.66       288\n",
      "         104       0.90      0.94      0.92        84\n",
      "         105       0.57      0.40      0.47        10\n",
      "         106       0.71      0.42      0.53        96\n",
      "         107       1.00      0.17      0.29         6\n",
      "         108       0.65      0.88      0.75        90\n",
      "         109       0.91      0.94      0.93        34\n",
      "         110       0.68      0.38      0.49        34\n",
      "         111       0.69      0.84      0.76       230\n",
      "         112       0.00      0.00      0.00        12\n",
      "         113       0.70      0.58      0.64        12\n",
      "         114       0.67      0.40      0.50        15\n",
      "         115       0.12      0.33      0.18         9\n",
      "         116       0.00      0.00      0.00         6\n",
      "         117       0.50      0.21      0.30        14\n",
      "         118       0.83      0.87      0.85       166\n",
      "         119       0.87      1.00      0.93        13\n",
      "         120       0.40      0.25      0.31         8\n",
      "         121       0.00      0.00      0.00         9\n",
      "         122       0.40      0.25      0.31         8\n",
      "         123       0.95      0.71      0.81        49\n",
      "         124       0.62      0.23      0.33        22\n",
      "         125       0.67      0.18      0.29        11\n",
      "         126       0.84      0.38      0.52       210\n",
      "         127       0.83      0.64      0.73        70\n",
      "         128       0.62      0.95      0.75        39\n",
      "         129       0.60      0.60      0.60         5\n",
      "         130       0.47      0.40      0.43        20\n",
      "         131       0.93      0.38      0.54        37\n",
      "         132       0.49      0.29      0.36       125\n",
      "         133       0.33      0.13      0.19        15\n",
      "         134       0.00      0.00      0.00        11\n",
      "         135       0.00      0.00      0.00         7\n",
      "         136       0.50      0.15      0.24        13\n",
      "         137       0.40      0.17      0.24        12\n",
      "         138       0.40      0.33      0.36        12\n",
      "         139       0.36      0.08      0.13        62\n",
      "         140       0.67      0.33      0.44         6\n",
      "         141       0.67      0.14      0.24        14\n",
      "         142       1.00      1.00      1.00         4\n",
      "         143       0.00      0.00      0.00         9\n",
      "         144       0.86      0.75      0.80        16\n",
      "         145       0.70      0.39      0.50        18\n",
      "         146       0.54      0.54      0.54        13\n",
      "         147       0.00      0.00      0.00         6\n",
      "         148       0.88      1.00      0.93         7\n",
      "         149       1.00      0.33      0.50         6\n",
      "         150       0.00      0.00      0.00         8\n",
      "         151       0.57      0.69      0.62        99\n",
      "         152       0.31      0.19      0.24        26\n",
      "         153       0.20      0.06      0.10        16\n",
      "         154       0.45      0.69      0.55        13\n",
      "         155       0.80      0.67      0.73        12\n",
      "         156       0.48      0.50      0.49        32\n",
      "         157       0.32      0.28      0.30        43\n",
      "         158       0.50      0.33      0.40         9\n",
      "         159       0.81      0.93      0.86        54\n",
      "         160       0.09      0.03      0.04        34\n",
      "         161       0.25      0.57      0.35         7\n",
      "         162       1.00      0.47      0.64        19\n",
      "         163       0.05      0.03      0.04        32\n",
      "         164       0.50      0.57      0.53         7\n",
      "         165       0.10      0.08      0.09        12\n",
      "         166       0.62      0.69      0.65       230\n",
      "         167       0.00      0.00      0.00        26\n",
      "         168       0.79      0.33      0.47        90\n",
      "         169       0.27      0.27      0.27        11\n",
      "         170       0.65      0.36      0.46       156\n",
      "         171       0.50      0.23      0.31        22\n",
      "         172       0.71      0.51      0.59        47\n",
      "         173       0.00      0.00      0.00        10\n",
      "         174       0.80      0.31      0.44        13\n",
      "         175       0.00      0.00      0.00         8\n",
      "         176       0.81      0.45      0.58        29\n",
      "         177       0.50      0.14      0.22         7\n",
      "         178       0.00      0.00      0.00         5\n",
      "         179       0.40      0.29      0.33         7\n",
      "         180       0.71      0.50      0.59        10\n",
      "         181       0.86      0.75      0.80        24\n",
      "         182       0.78      0.54      0.64        13\n",
      "         183       0.77      0.71      0.74       430\n",
      "         184       0.80      0.50      0.62        32\n",
      "         185       0.51      0.70      0.59        56\n",
      "         186       0.20      0.10      0.13        10\n",
      "         187       0.84      0.70      0.76        23\n",
      "         188       0.36      0.19      0.25        21\n",
      "         189       0.44      0.40      0.42        20\n",
      "         190       1.00      0.56      0.71         9\n",
      "         191       0.36      0.46      0.40       102\n",
      "         192       0.29      0.11      0.16        56\n",
      "         193       0.80      0.93      0.86      1648\n",
      "         194       0.00      0.00      0.00        22\n",
      "         195       0.00      0.00      0.00         7\n",
      "         196       0.53      0.31      0.39        29\n",
      "         197       0.17      0.12      0.14        16\n",
      "         198       0.28      0.38      0.32        13\n",
      "         199       0.62      0.83      0.71         6\n",
      "         200       0.69      0.67      0.68        43\n",
      "         201       0.14      0.06      0.08        18\n",
      "\n",
      "   micro avg       0.73      0.73      0.73     23485\n",
      "   macro avg       0.56      0.47      0.49     23485\n",
      "weighted avg       0.73      0.73      0.72     23485\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/justin/classification/app/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_flat_nd = HCM.FlatApproach(sequences,sequences_test,embedding_matrix,350)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
