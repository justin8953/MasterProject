{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.feature_selection import SelectKBest,chi2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  \n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Conv1D, Dense, Embedding, Flatten, Input,Dropout,GlobalMaxPooling1D,MaxPooling1D,LSTM\n",
    "from keras.metrics import categorical_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose folder\n",
    "folder = ['Amazon','FlipKart','Combine','Walmart']\n",
    "class OpenData:\n",
    "    def __init__(self,num):\n",
    "        self.num = num\n",
    "    def openFile(self):\n",
    "        num = self.num\n",
    "        trainData = pd.read_csv(folder[num]+'/X_train.csv')\n",
    "        trainLabel = pd.read_csv(folder[num]+'/y_train.csv')\n",
    "        testData = pd.read_csv(folder[num]+'/X_test.csv')\n",
    "        testLabel = pd.read_csv(folder[num]+'/y_test.csv')\n",
    "        if(num==0 or num==2):\n",
    "            # For Description has nan row\n",
    "            df = pd.concat([trainData,trainLabel], axis = 1)\n",
    "            df = df.dropna(subset=['X_train'])\n",
    "            trainData = pd.DataFrame({'X_train':df.X_train})\n",
    "            trainLabel = pd.DataFrame({'category':df.category,'subcategory':df.subcategory})\n",
    "            df = pd.concat([testData,testLabel], axis = 1)\n",
    "            df = df.dropna(subset=['X_test'])\n",
    "            testData = pd.DataFrame({'X_test':df.X_test})\n",
    "            testLabel = pd.DataFrame({'category':df.category,'subcategory':df.subcategory})\n",
    "        return trainData,trainLabel,testData,testLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DLFeatureSelect:\n",
    "    def __init__(self,train,trainLabel, test, testLabel, name):\n",
    "        self.title = name\n",
    "        self.X_train = trainData['X_train']\n",
    "        self.X_test =  testData['X_test']\n",
    "        self.y_train = trainLabel['category']\n",
    "        self.y_test = testLabel['category']\n",
    "        self.ynd_train = trainLabel['subcategory']\n",
    "        self.ynd_test = testLabel['subcategory']\n",
    "        self.target = np.unique(trainLabel['category'])\n",
    "        self.outputnum = len(np.unique(trainLabel['category']))\n",
    "        self.labels = to_categorical(trainLabel['category'])\n",
    "        self.subtarget = np.unique(trainLabel['subcategory'])\n",
    "        self.suboutputnum = len(np.unique(trainLabel['subcategory']))\n",
    "        self.sublabels = to_categorical(trainLabel['subcategory'])\n",
    "\n",
    "    def wordtoSequence(self):\n",
    "        tfidfconverter = TfidfVectorizer(min_df=5, max_df=0.7)\n",
    "        tfidfconverter.fit_transform(self.X_train)\n",
    "        vocab_size = len(tfidfconverter.get_feature_names())\n",
    "        print(\"Total vocabulary size: \" +str(vocab_size)+'\\n')\n",
    "        self.vocabSize = vocab_size\n",
    "        # Tranform Text to sequences   \n",
    "        print(\"---- Word to sequence ---- \\n\")\n",
    "        tokenizer = Tokenizer(num_words=vocab_size) # Setup tokenizer\n",
    "        tokenizer.fit_on_texts(self.X_train)\n",
    "        sequences = tokenizer.texts_to_sequences(self.X_train)\n",
    "        sequences_test = tokenizer.texts_to_sequences(self.X_test)\n",
    "        word_index = tokenizer.word_index\n",
    "        print(\"Total unique words : \" +str(len(word_index))+'\\n')\n",
    "        self.wordIndex = word_index\n",
    "        return sequences,sequences_test\n",
    "    def openGloveEmbeddingMatrix(self,dim):\n",
    "        embedding_dim = dim \n",
    "        self.embeddingDim = embedding_dim\n",
    "        print(\"---- Use \"+ str(dim) +\" dimension word vector ---- \\n\")\n",
    "\n",
    "        glove_dir = '../glove.6B' # This is the folder with the dataset\n",
    "        embeddings_index = {} # We create a dictionary of word -> embedding\n",
    "        with open(os.path.join(glove_dir, 'glove.6B.'+str(dim)+'d.txt')) as f:\n",
    "            for line in f:\n",
    "                values = line.split()\n",
    "                word = values[0] # The first value is the word, the rest are the values of the embedding\n",
    "                embedding = np.asarray(values[1:], dtype='float32') # Load embedding\n",
    "                embeddings_index[word] = embedding # Add embedding to our embedding dictionary\n",
    "        print('Found {:,} word vectors in GloVe.'.format(len(embeddings_index)))\n",
    "        return embeddings_index\n",
    "    def creatEmeddingMatrix(self,embeddings_index):\n",
    "        word_index = self.wordIndex\n",
    "        vocab_size = self.vocabSize\n",
    "        embedding_dim = self.embeddingDim\n",
    "        nb_words = min(vocab_size, len(word_index)) # How many words are there actually\n",
    "        embedding_matrix = np.zeros((nb_words, embedding_dim))\n",
    "        # The vectors need to be in the same position as their index. \n",
    "        # Meaning a word with token 1 needs to be in the second row (rows start with zero) and so on\n",
    "        # Loop over all words in the word index\n",
    "        for word, i in word_index.items():\n",
    "            # If we are above the amount of words we want to use we do nothing\n",
    "            if i >= vocab_size: \n",
    "                continue\n",
    "            # Get the embedding vector for the word\n",
    "            embedding_vector = embeddings_index.get(word)\n",
    "            # If there is an embedding vector, put it in the embedding matrix\n",
    "            if embedding_vector is not None: \n",
    "                embedding_matrix[i] = embedding_vector\n",
    "        return embedding_matrix\n",
    "    def selectBestFeature(self,X,y,X_test,num):\n",
    "        select = SelectKBest(chi2, k=num)\n",
    "        select.fit(X, y)\n",
    "        X = select.transform(X)\n",
    "        XTest=select.transform(X_test)\n",
    "        return X, XTest\n",
    "    def model_settings(self,length,embeddingMatrix,outputnum):\n",
    "        vocab_size = self.vocabSize\n",
    "        embedding_dim = self.embeddingDim\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(vocab_size, embedding_dim, input_length=length, weights = [embedding_matrix], \n",
    "                                trainable = False))\n",
    "        model.add(Conv1D(200,3,padding='valid',activation='relu',strides=1))        \n",
    "        # we use max pooling:\n",
    "        model.add(GlobalMaxPooling1D())\n",
    "        # We add a vanilla hidden layer:\n",
    "        model.add(Dense(250))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(outputnum, activation='softmax'))\n",
    "        model.summary()\n",
    "        return model\n",
    "    def model_settingsnd(self,length,embeddingMatrix,outputnum):\n",
    "        vocab_size = self.vocabSize\n",
    "        embedding_dim = self.embeddingDim\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(vocab_size, embedding_dim, input_length=length, weights = [embedding_matrix], \n",
    "                                trainable = False))\n",
    "        model.add(Conv1D(125,5,padding='valid',activation='relu',strides=1))        \n",
    "        # we use max pooling:\n",
    "        model.add(MaxPooling1D(3))\n",
    "        model.add(Conv1D(125,5,padding='valid',activation='relu',strides=1))        \n",
    "        # we use max pooling:\n",
    "        model.add(MaxPooling1D(3))\n",
    "        model.add(Conv1D(125,5,padding='valid',activation='relu',strides=1))        \n",
    "        # we use max pooling:\n",
    "        model.add(MaxPooling1D(3))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(outputnum, activation='softmax'))\n",
    "        model.summary()\n",
    "        return model\n",
    "    def model_settingsrd(self,length,embeddingMatrix,outputnum):\n",
    "        vocab_size = self.vocabSize\n",
    "        embedding_dim = self.embeddingDim\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(vocab_size, embedding_dim, input_length=length, weights = [embedding_matrix], \n",
    "                                trainable = False))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv1D(128,5,padding='valid',activation='relu',strides=1))        \n",
    "        # we use max pooling:\n",
    "        model.add(MaxPooling1D(4))\n",
    "        model.add(LSTM(70))\n",
    "#         model.add(Flatten())\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(outputnum, activation='softmax'))\n",
    "        model.summary()\n",
    "        return model\n",
    "    def creatmodel(self,sequences,sequences_test,embeddingMatrix, num):\n",
    "        outputnum = self.outputnum\n",
    "        trainlengths = [len(ele) for ele in sequences]\n",
    "        testlengths = [len(ele) for ele in sequences_test]\n",
    "        max_length = max(max(trainlengths),max(testlengths))\n",
    "        train = pad_sequences(sequences,maxlen= max_length)\n",
    "        test = pad_sequences(sequences_test,maxlen = max_length)\n",
    "        y_train = self.labels\n",
    "        y_test = self.y_test\n",
    "        batch_size = 100\n",
    "        epochs = 10\n",
    "        scores = []\n",
    "        X, XTest = self.selectBestFeature(train,y_train,test,num)\n",
    "        model = self.model_settings(num,embeddingMatrix,outputnum)\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[categorical_accuracy])\n",
    "        history = model.fit(X, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_split=0.2)\n",
    "        loss, accuracy = model.evaluate(XTest, to_categorical(y_test))\n",
    "        print(\"Accuracy: \"+str(accuracy)+\" Loss: \"+str(loss)+\"\\n\")\n",
    "        return accuracy,loss\n",
    "    \n",
    "    \n",
    "    def creatndmodel(self,sequences,sequences_test,embeddingMatrix,num):\n",
    "        outputnum = self.outputnum\n",
    "        trainlengths = [len(ele) for ele in sequences]\n",
    "        testlengths = [len(ele) for ele in sequences_test]\n",
    "        max_length = max(max(trainlengths),max(testlengths))\n",
    "        train = pad_sequences(sequences,maxlen= max_length)\n",
    "        test = pad_sequences(sequences_test,maxlen = max_length)\n",
    "        y_train = self.labels\n",
    "        y_test = self.y_test\n",
    "        batch_size = 100\n",
    "        epochs = 10\n",
    "        scores = []\n",
    "        X, XTest = self.selectBestFeature(train,y_train,test,num)\n",
    "        model = self.model_settingsnd(num,embeddingMatrix,outputnum)\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[categorical_accuracy])\n",
    "        history = model.fit(X, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_split=0.2)\n",
    "        loss, accuracy = model.evaluate(XTest, to_categorical(y_test))\n",
    "        print(\"Accuracy: \"+str(accuracy)+\" Loss: \"+str(loss)+\"\\n\")\n",
    "        return accuracy,loss\n",
    "    def creatrdmodel(self,sequences,sequences_test,embeddingMatrix,num):\n",
    "        outputnum = self.outputnum\n",
    "        trainlengths = [len(ele) for ele in sequences]\n",
    "        testlengths = [len(ele) for ele in sequences_test]\n",
    "        max_length = max(max(trainlengths),max(testlengths))\n",
    "        train = pad_sequences(sequences,maxlen= max_length)\n",
    "        test = pad_sequences(sequences_test,maxlen = max_length)\n",
    "        y_train = self.labels\n",
    "        y_test = self.y_test\n",
    "        batch_size = 100\n",
    "        epochs = 10\n",
    "        scores = []\n",
    "        X, XTest = self.selectBestFeature(train,y_train,test,num)\n",
    "        model = self.model_settingsrd(num,embeddingMatrix,outputnum)\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[categorical_accuracy])\n",
    "        history = model.fit(X, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_split=0.2)\n",
    "        loss, accuracy = model.evaluate(XTest, to_categorical(y_test))\n",
    "        print(\"Accuracy: \"+str(accuracy)+\" Loss: \"+str(loss)+\"\\n\")\n",
    "        return accuracy,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "openData = OpenData(0)\n",
    "trainData,trainLabel,testData,testLabel = openData.openFile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vocabulary size: 5927\n",
      "\n",
      "---- Word to sequence ---- \n",
      "\n",
      "Total unique words : 24058\n",
      "\n",
      "---- Use 300 dimension word vector ---- \n",
      "\n",
      "Found 400,000 word vectors in GloVe.\n"
     ]
    }
   ],
   "source": [
    "dlFS = DLFeatureSelect(trainData,trainLabel,testData,testLabel,folder[0])\n",
    "sequences,sequences_test =dlFS.wordtoSequence()\n",
    "embeddings_index = dlFS.openGloveEmbeddingMatrix(300)\n",
    "embedding_matrix = dlFS.creatEmeddingMatrix(embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0726 13:00:01.013914 140022623635264 deprecation_wrapper.py:119] From /home/justin/classification/app/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0726 13:00:01.036250 140022623635264 deprecation_wrapper.py:119] From /home/justin/classification/app/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0726 13:00:01.039340 140022623635264 deprecation_wrapper.py:119] From /home/justin/classification/app/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0726 13:00:01.048329 140022623635264 deprecation_wrapper.py:119] From /home/justin/classification/app/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0726 13:00:01.049282 140022623635264 deprecation_wrapper.py:119] From /home/justin/classification/app/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0726 13:00:01.149148 140022623635264 deprecation.py:506] From /home/justin/classification/app/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0726 13:00:01.177620 140022623635264 deprecation_wrapper.py:119] From /home/justin/classification/app/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0726 13:00:01.200825 140022623635264 deprecation.py:323] From /home/justin/classification/app/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 650, 300)          1778100   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 648, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 14)                3514      \n",
      "=================================================================\n",
      "Total params: 2,012,064\n",
      "Trainable params: 233,964\n",
      "Non-trainable params: 1,778,100\n",
      "_________________________________________________________________\n",
      "Train on 5219 samples, validate on 1305 samples\n",
      "Epoch 1/10\n",
      "5219/5219 [==============================] - 14s 3ms/step - loss: 0.1695 - categorical_accuracy: 0.4995 - val_loss: 0.0994 - val_categorical_accuracy: 0.7525\n",
      "Epoch 2/10\n",
      "5219/5219 [==============================] - 14s 3ms/step - loss: 0.0804 - categorical_accuracy: 0.7952 - val_loss: 0.0791 - val_categorical_accuracy: 0.7985\n",
      "Epoch 3/10\n",
      "5219/5219 [==============================] - 14s 3ms/step - loss: 0.0518 - categorical_accuracy: 0.8705 - val_loss: 0.0798 - val_categorical_accuracy: 0.7962\n",
      "Epoch 4/10\n",
      "5219/5219 [==============================] - 14s 3ms/step - loss: 0.0331 - categorical_accuracy: 0.9308 - val_loss: 0.0742 - val_categorical_accuracy: 0.8061\n",
      "Epoch 5/10\n",
      "5219/5219 [==============================] - 14s 3ms/step - loss: 0.0213 - categorical_accuracy: 0.9621 - val_loss: 0.0722 - val_categorical_accuracy: 0.8268\n",
      "Epoch 6/10\n",
      "5219/5219 [==============================] - 14s 3ms/step - loss: 0.0155 - categorical_accuracy: 0.9753 - val_loss: 0.0756 - val_categorical_accuracy: 0.8253\n",
      "Epoch 7/10\n",
      "5219/5219 [==============================] - 14s 3ms/step - loss: 0.0116 - categorical_accuracy: 0.9814 - val_loss: 0.0839 - val_categorical_accuracy: 0.8138\n",
      "Epoch 8/10\n",
      "5219/5219 [==============================] - 14s 3ms/step - loss: 0.0106 - categorical_accuracy: 0.9837 - val_loss: 0.0799 - val_categorical_accuracy: 0.8230\n",
      "Epoch 9/10\n",
      "5219/5219 [==============================] - 14s 3ms/step - loss: 0.0097 - categorical_accuracy: 0.9841 - val_loss: 0.0841 - val_categorical_accuracy: 0.8245\n",
      "Epoch 10/10\n",
      "5219/5219 [==============================] - 14s 3ms/step - loss: 0.0092 - categorical_accuracy: 0.9854 - val_loss: 0.0889 - val_categorical_accuracy: 0.8130\n",
      "1633/1633 [==============================] - 2s 925us/step\n",
      "Accuracy: 0.7587262706674831 Loss: 0.11300876692276748\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7587262706674831, 0.11300876692276748)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlFS.creatmodel(sequences,sequences_test,embedding_matrix, 650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0726 13:02:34.234203 140022623635264 deprecation_wrapper.py:119] From /home/justin/classification/app/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 650, 300)          1778100   \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 646, 125)          187625    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 215, 125)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 211, 125)          78250     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 70, 125)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 66, 125)           78250     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 22, 125)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2750)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2750)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 14)                38514     \n",
      "=================================================================\n",
      "Total params: 2,160,739\n",
      "Trainable params: 382,639\n",
      "Non-trainable params: 1,778,100\n",
      "_________________________________________________________________\n",
      "Train on 5219 samples, validate on 1305 samples\n",
      "Epoch 1/10\n",
      "5219/5219 [==============================] - 19s 4ms/step - loss: 0.2253 - categorical_accuracy: 0.2372 - val_loss: 0.1862 - val_categorical_accuracy: 0.4238\n",
      "Epoch 2/10\n",
      "5219/5219 [==============================] - 18s 4ms/step - loss: 0.1685 - categorical_accuracy: 0.4840 - val_loss: 0.1528 - val_categorical_accuracy: 0.5333\n",
      "Epoch 3/10\n",
      "5219/5219 [==============================] - 18s 4ms/step - loss: 0.1306 - categorical_accuracy: 0.6156 - val_loss: 0.1273 - val_categorical_accuracy: 0.6291\n",
      "Epoch 4/10\n",
      "5219/5219 [==============================] - 18s 3ms/step - loss: 0.1028 - categorical_accuracy: 0.7068 - val_loss: 0.1092 - val_categorical_accuracy: 0.6897\n",
      "Epoch 5/10\n",
      "5219/5219 [==============================] - 18s 3ms/step - loss: 0.0804 - categorical_accuracy: 0.7758 - val_loss: 0.1105 - val_categorical_accuracy: 0.7119\n",
      "Epoch 6/10\n",
      "5219/5219 [==============================] - 18s 3ms/step - loss: 0.0676 - categorical_accuracy: 0.8155 - val_loss: 0.1107 - val_categorical_accuracy: 0.7050\n",
      "Epoch 7/10\n",
      "5219/5219 [==============================] - 18s 3ms/step - loss: 0.0530 - categorical_accuracy: 0.8548 - val_loss: 0.1165 - val_categorical_accuracy: 0.7050\n",
      "Epoch 8/10\n",
      "5219/5219 [==============================] - 18s 3ms/step - loss: 0.0434 - categorical_accuracy: 0.8789 - val_loss: 0.1252 - val_categorical_accuracy: 0.7088\n",
      "Epoch 9/10\n",
      "5219/5219 [==============================] - 18s 4ms/step - loss: 0.0385 - categorical_accuracy: 0.8940 - val_loss: 0.1182 - val_categorical_accuracy: 0.7211\n",
      "Epoch 10/10\n",
      "5219/5219 [==============================] - 18s 4ms/step - loss: 0.0331 - categorical_accuracy: 0.9019 - val_loss: 0.1392 - val_categorical_accuracy: 0.7218\n",
      "1633/1633 [==============================] - 2s 1ms/step\n",
      "Accuracy: 0.6631965707287202 Loss: 0.16382945274439123\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6631965707287202, 0.16382945274439123)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlFS.creatndmodel(sequences,sequences_test,embedding_matrix, 650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 650, 300)          1778100   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 650, 300)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 646, 128)          192128    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 161, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 70)                55720     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 14)                994       \n",
      "=================================================================\n",
      "Total params: 2,026,942\n",
      "Trainable params: 248,842\n",
      "Non-trainable params: 1,778,100\n",
      "_________________________________________________________________\n",
      "Train on 5219 samples, validate on 1305 samples\n",
      "Epoch 1/10\n",
      "5219/5219 [==============================] - 26s 5ms/step - loss: 0.1978 - categorical_accuracy: 0.3892 - val_loss: 0.1407 - val_categorical_accuracy: 0.6176\n",
      "Epoch 2/10\n",
      "5219/5219 [==============================] - 25s 5ms/step - loss: 0.1322 - categorical_accuracy: 0.6321 - val_loss: 0.1154 - val_categorical_accuracy: 0.6866\n",
      "Epoch 3/10\n",
      "5219/5219 [==============================] - 26s 5ms/step - loss: 0.1135 - categorical_accuracy: 0.6919 - val_loss: 0.1039 - val_categorical_accuracy: 0.7234\n",
      "Epoch 4/10\n",
      "5219/5219 [==============================] - 25s 5ms/step - loss: 0.0992 - categorical_accuracy: 0.7367 - val_loss: 0.1006 - val_categorical_accuracy: 0.7142\n",
      "Epoch 5/10\n",
      "5219/5219 [==============================] - 25s 5ms/step - loss: 0.0893 - categorical_accuracy: 0.7553 - val_loss: 0.0961 - val_categorical_accuracy: 0.7287\n",
      "Epoch 6/10\n",
      "5219/5219 [==============================] - 25s 5ms/step - loss: 0.0813 - categorical_accuracy: 0.7842 - val_loss: 0.0912 - val_categorical_accuracy: 0.7602\n",
      "Epoch 7/10\n",
      "5219/5219 [==============================] - 24s 5ms/step - loss: 0.0739 - categorical_accuracy: 0.8002 - val_loss: 0.0912 - val_categorical_accuracy: 0.7525\n",
      "Epoch 8/10\n",
      "5219/5219 [==============================] - 24s 5ms/step - loss: 0.0662 - categorical_accuracy: 0.8208 - val_loss: 0.0903 - val_categorical_accuracy: 0.7609\n",
      "Epoch 9/10\n",
      "5219/5219 [==============================] - 25s 5ms/step - loss: 0.0576 - categorical_accuracy: 0.8467 - val_loss: 0.0885 - val_categorical_accuracy: 0.7678\n",
      "Epoch 10/10\n",
      "5219/5219 [==============================] - 25s 5ms/step - loss: 0.0512 - categorical_accuracy: 0.8643 - val_loss: 0.0961 - val_categorical_accuracy: 0.7548\n",
      "1633/1633 [==============================] - 3s 2ms/step\n",
      "Accuracy: 0.6950398040416411 Loss: 0.11353956748488624\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6950398040416411, 0.11353956748488624)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlFS.creatrdmodel(sequences,sequences_test,embedding_matrix, 650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "openData = OpenData(1)\n",
    "trainData,trainLabel,testData,testLabel = openData.openFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vocabulary size: 4742\n",
      "\n",
      "---- Word to sequence ---- \n",
      "\n",
      "Total unique words : 16399\n",
      "\n",
      "---- Use 300 dimension word vector ---- \n",
      "\n",
      "Found 400,000 word vectors in GloVe.\n"
     ]
    }
   ],
   "source": [
    "dlFS = DLFeatureSelect(trainData,trainLabel,testData,testLabel,folder[1])\n",
    "sequences,sequences_test =dlFS.wordtoSequence()\n",
    "embeddings_index = dlFS.openGloveEmbeddingMatrix(300)\n",
    "embedding_matrix = dlFS.creatEmeddingMatrix(embeddings_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 500, 300)          1422600   \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 498, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 18)                4518      \n",
      "=================================================================\n",
      "Total params: 1,657,568\n",
      "Trainable params: 234,968\n",
      "Non-trainable params: 1,422,600\n",
      "_________________________________________________________________\n",
      "Train on 9911 samples, validate on 2478 samples\n",
      "Epoch 1/10\n",
      "9911/9911 [==============================] - 21s 2ms/step - loss: 0.0440 - categorical_accuracy: 0.8652 - val_loss: 0.0082 - val_categorical_accuracy: 0.9774\n",
      "Epoch 2/10\n",
      "9911/9911 [==============================] - 20s 2ms/step - loss: 0.0051 - categorical_accuracy: 0.9866 - val_loss: 0.0057 - val_categorical_accuracy: 0.9822\n",
      "Epoch 3/10\n",
      "9911/9911 [==============================] - 20s 2ms/step - loss: 0.0032 - categorical_accuracy: 0.9912 - val_loss: 0.0065 - val_categorical_accuracy: 0.9843\n",
      "Epoch 4/10\n",
      "9911/9911 [==============================] - 19s 2ms/step - loss: 0.0018 - categorical_accuracy: 0.9959 - val_loss: 0.0030 - val_categorical_accuracy: 0.9895\n",
      "Epoch 5/10\n",
      "9911/9911 [==============================] - 20s 2ms/step - loss: 0.0015 - categorical_accuracy: 0.9962 - val_loss: 0.0045 - val_categorical_accuracy: 0.9859\n",
      "Epoch 6/10\n",
      "9911/9911 [==============================] - 20s 2ms/step - loss: 0.0010 - categorical_accuracy: 0.9972 - val_loss: 0.0030 - val_categorical_accuracy: 0.9907\n",
      "Epoch 7/10\n",
      "9911/9911 [==============================] - 20s 2ms/step - loss: 8.6669e-04 - categorical_accuracy: 0.9979 - val_loss: 0.0047 - val_categorical_accuracy: 0.9875\n",
      "Epoch 8/10\n",
      "9911/9911 [==============================] - 20s 2ms/step - loss: 0.0017 - categorical_accuracy: 0.9946 - val_loss: 0.0042 - val_categorical_accuracy: 0.9863\n",
      "Epoch 9/10\n",
      "9911/9911 [==============================] - 20s 2ms/step - loss: 0.0014 - categorical_accuracy: 0.9961 - val_loss: 0.0042 - val_categorical_accuracy: 0.9899\n",
      "Epoch 10/10\n",
      "9911/9911 [==============================] - 20s 2ms/step - loss: 8.9867e-04 - categorical_accuracy: 0.9974 - val_loss: 0.0047 - val_categorical_accuracy: 0.9891\n",
      "3098/3098 [==============================] - 2s 712us/step\n",
      "Accuracy: 0.9893479664299548 Loss: 0.0055019580614669265\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9893479664299548, 0.0055019580614669265)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlFS.creatmodel(sequences,sequences_test,embedding_matrix, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 500, 300)          1422600   \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 496, 125)          187625    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 165, 125)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 161, 125)          78250     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 53, 125)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 49, 125)           78250     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 16, 125)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 18)                36018     \n",
      "=================================================================\n",
      "Total params: 1,802,743\n",
      "Trainable params: 380,143\n",
      "Non-trainable params: 1,422,600\n",
      "_________________________________________________________________\n",
      "Train on 9911 samples, validate on 2478 samples\n",
      "Epoch 1/10\n",
      "9911/9911 [==============================] - 27s 3ms/step - loss: 0.0977 - categorical_accuracy: 0.6312 - val_loss: 0.0490 - val_categorical_accuracy: 0.8398\n",
      "Epoch 2/10\n",
      "9911/9911 [==============================] - 26s 3ms/step - loss: 0.0310 - categorical_accuracy: 0.8980 - val_loss: 0.0186 - val_categorical_accuracy: 0.9487\n",
      "Epoch 3/10\n",
      "9911/9911 [==============================] - 26s 3ms/step - loss: 0.0132 - categorical_accuracy: 0.9583 - val_loss: 0.0136 - val_categorical_accuracy: 0.9629\n",
      "Epoch 4/10\n",
      "9911/9911 [==============================] - 26s 3ms/step - loss: 0.0093 - categorical_accuracy: 0.9705 - val_loss: 0.0106 - val_categorical_accuracy: 0.9713\n",
      "Epoch 5/10\n",
      "9911/9911 [==============================] - 26s 3ms/step - loss: 0.0057 - categorical_accuracy: 0.9818 - val_loss: 0.0106 - val_categorical_accuracy: 0.9685\n",
      "Epoch 6/10\n",
      "9911/9911 [==============================] - 26s 3ms/step - loss: 0.0044 - categorical_accuracy: 0.9849 - val_loss: 0.0123 - val_categorical_accuracy: 0.9685\n",
      "Epoch 7/10\n",
      "9911/9911 [==============================] - 26s 3ms/step - loss: 0.0043 - categorical_accuracy: 0.9865 - val_loss: 0.0124 - val_categorical_accuracy: 0.9697\n",
      "Epoch 8/10\n",
      "9911/9911 [==============================] - 26s 3ms/step - loss: 0.0039 - categorical_accuracy: 0.9868 - val_loss: 0.0100 - val_categorical_accuracy: 0.9722\n",
      "Epoch 9/10\n",
      "9911/9911 [==============================] - 26s 3ms/step - loss: 0.0040 - categorical_accuracy: 0.9866 - val_loss: 0.0081 - val_categorical_accuracy: 0.9790\n",
      "Epoch 10/10\n",
      "9911/9911 [==============================] - 26s 3ms/step - loss: 0.0030 - categorical_accuracy: 0.9909 - val_loss: 0.0101 - val_categorical_accuracy: 0.9754\n",
      "3098/3098 [==============================] - 3s 935us/step\n",
      "Accuracy: 0.9738540994189799 Loss: 0.01220400532760918\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9738540994189799, 0.01220400532760918)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlFS.creatndmodel(sequences,sequences_test,embedding_matrix, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 500, 300)          1422600   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 500, 300)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 496, 128)          192128    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 124, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 70)                55720     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 18)                1278      \n",
      "=================================================================\n",
      "Total params: 1,671,726\n",
      "Trainable params: 249,126\n",
      "Non-trainable params: 1,422,600\n",
      "_________________________________________________________________\n",
      "Train on 9911 samples, validate on 2478 samples\n",
      "Epoch 1/10\n",
      "9911/9911 [==============================] - 37s 4ms/step - loss: 0.0811 - categorical_accuracy: 0.7272 - val_loss: 0.0288 - val_categorical_accuracy: 0.9221\n",
      "Epoch 2/10\n",
      "9911/9911 [==============================] - 35s 4ms/step - loss: 0.0268 - categorical_accuracy: 0.9266 - val_loss: 0.0220 - val_categorical_accuracy: 0.9403\n",
      "Epoch 3/10\n",
      "9911/9911 [==============================] - 35s 4ms/step - loss: 0.0163 - categorical_accuracy: 0.9576 - val_loss: 0.0103 - val_categorical_accuracy: 0.9726\n",
      "Epoch 4/10\n",
      "9911/9911 [==============================] - 36s 4ms/step - loss: 0.0114 - categorical_accuracy: 0.9707 - val_loss: 0.0096 - val_categorical_accuracy: 0.9746\n",
      "Epoch 5/10\n",
      "9911/9911 [==============================] - 35s 3ms/step - loss: 0.0078 - categorical_accuracy: 0.9796 - val_loss: 0.0070 - val_categorical_accuracy: 0.9810\n",
      "Epoch 6/10\n",
      "9911/9911 [==============================] - 35s 4ms/step - loss: 0.0069 - categorical_accuracy: 0.9820 - val_loss: 0.0076 - val_categorical_accuracy: 0.9778\n",
      "Epoch 7/10\n",
      "9911/9911 [==============================] - 35s 4ms/step - loss: 0.0056 - categorical_accuracy: 0.9856 - val_loss: 0.0081 - val_categorical_accuracy: 0.9746\n",
      "Epoch 8/10\n",
      "9911/9911 [==============================] - 35s 4ms/step - loss: 0.0078 - categorical_accuracy: 0.9803 - val_loss: 0.0065 - val_categorical_accuracy: 0.9822\n",
      "Epoch 9/10\n",
      "9911/9911 [==============================] - 35s 4ms/step - loss: 0.0053 - categorical_accuracy: 0.9872 - val_loss: 0.0057 - val_categorical_accuracy: 0.9839\n",
      "Epoch 10/10\n",
      "9911/9911 [==============================] - 35s 4ms/step - loss: 0.0041 - categorical_accuracy: 0.9894 - val_loss: 0.0065 - val_categorical_accuracy: 0.9786\n",
      "3098/3098 [==============================] - 4s 1ms/step\n",
      "Accuracy: 0.9838605551969012 Loss: 0.00636588723947077\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9838605551969012, 0.00636588723947077)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlFS.creatrdmodel(sequences,sequences_test,embedding_matrix, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "openData = OpenData(2)\n",
    "trainData,trainLabel,testData,testLabel = openData.openFile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vocabulary size: 9848\n",
      "\n",
      "---- Word to sequence ---- \n",
      "\n",
      "Total unique words : 37793\n",
      "\n",
      "---- Use 300 dimension word vector ---- \n",
      "\n",
      "Found 400,000 word vectors in GloVe.\n"
     ]
    }
   ],
   "source": [
    "dlFS = DLFeatureSelect(trainData,trainLabel,testData,testLabel,folder[2])\n",
    "sequences,sequences_test =dlFS.wordtoSequence()\n",
    "embeddings_index = dlFS.openGloveEmbeddingMatrix(300)\n",
    "embedding_matrix = dlFS.creatEmeddingMatrix(embeddings_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 1100, 300)         2954400   \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 1098, 200)         180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 9)                 2259      \n",
      "=================================================================\n",
      "Total params: 3,187,109\n",
      "Trainable params: 232,709\n",
      "Non-trainable params: 2,954,400\n",
      "_________________________________________________________________\n",
      "Train on 18261 samples, validate on 4566 samples\n",
      "Epoch 1/10\n",
      "18261/18261 [==============================] - 84s 5ms/step - loss: 0.0627 - categorical_accuracy: 0.9053 - val_loss: 0.0266 - val_categorical_accuracy: 0.9643\n",
      "Epoch 2/10\n",
      "18261/18261 [==============================] - 81s 4ms/step - loss: 0.0160 - categorical_accuracy: 0.9789 - val_loss: 0.0254 - val_categorical_accuracy: 0.9676\n",
      "Epoch 3/10\n",
      "18261/18261 [==============================] - 82s 4ms/step - loss: 0.0074 - categorical_accuracy: 0.9910 - val_loss: 0.0248 - val_categorical_accuracy: 0.9682\n",
      "Epoch 4/10\n",
      "18261/18261 [==============================] - 82s 4ms/step - loss: 0.0045 - categorical_accuracy: 0.9954 - val_loss: 0.0276 - val_categorical_accuracy: 0.9696\n",
      "Epoch 5/10\n",
      "18261/18261 [==============================] - 82s 4ms/step - loss: 0.0033 - categorical_accuracy: 0.9970 - val_loss: 0.0305 - val_categorical_accuracy: 0.9707\n",
      "Epoch 6/10\n",
      "18261/18261 [==============================] - 82s 4ms/step - loss: 0.0032 - categorical_accuracy: 0.9967 - val_loss: 0.0310 - val_categorical_accuracy: 0.9715\n",
      "Epoch 7/10\n",
      "18261/18261 [==============================] - 82s 4ms/step - loss: 0.0035 - categorical_accuracy: 0.9966 - val_loss: 0.0339 - val_categorical_accuracy: 0.9704\n",
      "Epoch 8/10\n",
      "18261/18261 [==============================] - 82s 5ms/step - loss: 0.0038 - categorical_accuracy: 0.9964 - val_loss: 0.0377 - val_categorical_accuracy: 0.9693\n",
      "Epoch 9/10\n",
      "18261/18261 [==============================] - 82s 4ms/step - loss: 0.0026 - categorical_accuracy: 0.9979 - val_loss: 0.0386 - val_categorical_accuracy: 0.9702\n",
      "Epoch 10/10\n",
      "18261/18261 [==============================] - 81s 4ms/step - loss: 0.0035 - categorical_accuracy: 0.9966 - val_loss: 0.0408 - val_categorical_accuracy: 0.9687\n",
      "5704/5704 [==============================] - 9s 2ms/step\n",
      "Accuracy: 0.9735273492286115 Loss: 0.030606828285291193\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9735273492286115, 0.030606828285291193)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlFS.creatmodel(sequences,sequences_test,embedding_matrix,1100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 1100, 300)         2954400   \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 1096, 125)         187625    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 365, 125)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 361, 125)          78250     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 120, 125)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 116, 125)          78250     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 38, 125)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 4750)              0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 4750)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 9)                 42759     \n",
      "=================================================================\n",
      "Total params: 3,341,284\n",
      "Trainable params: 386,884\n",
      "Non-trainable params: 2,954,400\n",
      "_________________________________________________________________\n",
      "Train on 18261 samples, validate on 4566 samples\n",
      "Epoch 1/10\n",
      "18261/18261 [==============================] - 112s 6ms/step - loss: 0.1887 - categorical_accuracy: 0.6091 - val_loss: 0.1410 - val_categorical_accuracy: 0.7153\n",
      "Epoch 2/10\n",
      "18261/18261 [==============================] - 110s 6ms/step - loss: 0.1271 - categorical_accuracy: 0.7310 - val_loss: 0.1269 - val_categorical_accuracy: 0.7361\n",
      "Epoch 3/10\n",
      "18261/18261 [==============================] - 110s 6ms/step - loss: 0.1115 - categorical_accuracy: 0.7577 - val_loss: 0.1269 - val_categorical_accuracy: 0.7479\n",
      "Epoch 4/10\n",
      "18261/18261 [==============================] - 110s 6ms/step - loss: 0.1025 - categorical_accuracy: 0.7729 - val_loss: 0.1263 - val_categorical_accuracy: 0.7330\n",
      "Epoch 5/10\n",
      "18261/18261 [==============================] - 109s 6ms/step - loss: 0.0984 - categorical_accuracy: 0.7810 - val_loss: 0.1256 - val_categorical_accuracy: 0.7541\n",
      "Epoch 6/10\n",
      "18261/18261 [==============================] - 110s 6ms/step - loss: 0.0945 - categorical_accuracy: 0.7848 - val_loss: 0.1308 - val_categorical_accuracy: 0.7519\n",
      "Epoch 7/10\n",
      "18261/18261 [==============================] - 109s 6ms/step - loss: 0.0927 - categorical_accuracy: 0.7868 - val_loss: 0.1299 - val_categorical_accuracy: 0.7514\n",
      "Epoch 8/10\n",
      "18261/18261 [==============================] - 109s 6ms/step - loss: 0.0924 - categorical_accuracy: 0.7884 - val_loss: 0.1275 - val_categorical_accuracy: 0.7571\n",
      "Epoch 9/10\n",
      "18261/18261 [==============================] - 111s 6ms/step - loss: 0.0905 - categorical_accuracy: 0.7910 - val_loss: 0.1394 - val_categorical_accuracy: 0.7541\n",
      "Epoch 10/10\n",
      "18261/18261 [==============================] - 110s 6ms/step - loss: 0.0919 - categorical_accuracy: 0.7904 - val_loss: 0.1345 - val_categorical_accuracy: 0.7549\n",
      "5704/5704 [==============================] - 11s 2ms/step\n",
      "Accuracy: 0.760343618513324 Loss: 0.1273609535614496\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.760343618513324, 0.1273609535614496)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlFS.creatndmodel(sequences,sequences_test,embedding_matrix,1100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 1100, 300)         2954400   \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1100, 300)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 1096, 128)         192128    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 274, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 70)                55720     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 9)                 639       \n",
      "=================================================================\n",
      "Total params: 3,202,887\n",
      "Trainable params: 248,487\n",
      "Non-trainable params: 2,954,400\n",
      "_________________________________________________________________\n",
      "Train on 18261 samples, validate on 4566 samples\n",
      "Epoch 1/10\n",
      "18261/18261 [==============================] - 153s 8ms/step - loss: 0.1000 - categorical_accuracy: 0.8418 - val_loss: 0.0489 - val_categorical_accuracy: 0.9273\n",
      "Epoch 2/10\n",
      "18261/18261 [==============================] - 151s 8ms/step - loss: 0.0449 - categorical_accuracy: 0.9336 - val_loss: 0.0346 - val_categorical_accuracy: 0.9485\n",
      "Epoch 3/10\n",
      "18261/18261 [==============================] - 149s 8ms/step - loss: 0.0317 - categorical_accuracy: 0.9550 - val_loss: 0.0298 - val_categorical_accuracy: 0.9593\n",
      "Epoch 4/10\n",
      "18261/18261 [==============================] - 150s 8ms/step - loss: 0.0243 - categorical_accuracy: 0.9650 - val_loss: 0.0313 - val_categorical_accuracy: 0.9569\n",
      "Epoch 5/10\n",
      "18261/18261 [==============================] - 148s 8ms/step - loss: 0.0199 - categorical_accuracy: 0.9723 - val_loss: 0.0269 - val_categorical_accuracy: 0.9621\n",
      "Epoch 6/10\n",
      "18261/18261 [==============================] - 152s 8ms/step - loss: 0.0151 - categorical_accuracy: 0.9784 - val_loss: 0.0272 - val_categorical_accuracy: 0.9608\n",
      "Epoch 7/10\n",
      "18261/18261 [==============================] - 149s 8ms/step - loss: 0.0128 - categorical_accuracy: 0.9824 - val_loss: 0.0315 - val_categorical_accuracy: 0.9577\n",
      "Epoch 8/10\n",
      "18261/18261 [==============================] - 151s 8ms/step - loss: 0.0117 - categorical_accuracy: 0.9837 - val_loss: 0.0253 - val_categorical_accuracy: 0.9698\n",
      "Epoch 9/10\n",
      "18261/18261 [==============================] - 148s 8ms/step - loss: 0.0093 - categorical_accuracy: 0.9875 - val_loss: 0.0268 - val_categorical_accuracy: 0.9663\n",
      "Epoch 10/10\n",
      "18261/18261 [==============================] - 151s 8ms/step - loss: 0.0091 - categorical_accuracy: 0.9875 - val_loss: 0.0279 - val_categorical_accuracy: 0.9669\n",
      "5704/5704 [==============================] - 15s 3ms/step\n",
      "Accuracy: 0.9773842917251052 Loss: 0.01965912789516843\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9773842917251052, 0.01965912789516843)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlFS.creatrdmodel(sequences,sequences_test,embedding_matrix, 1100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "openData = OpenData(3)\n",
    "trainData,trainLabel,testData,testLabel = openData.openFile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vocabulary size: 24650\n",
      "\n",
      "---- Word to sequence ---- \n",
      "\n",
      "Total unique words : 107100\n",
      "\n",
      "---- Use 300 dimension word vector ---- \n",
      "\n",
      "Found 400,000 word vectors in GloVe.\n"
     ]
    }
   ],
   "source": [
    "dlFS = DLFeatureSelect(trainData,trainLabel,testData,testLabel,folder[3])\n",
    "sequences,sequences_test =dlFS.wordtoSequence()\n",
    "embeddings_index = dlFS.openGloveEmbeddingMatrix(300)\n",
    "embedding_matrix = dlFS.creatEmeddingMatrix(embeddings_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 350, 300)          7395000   \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 348, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_4 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 32)                8032      \n",
      "=================================================================\n",
      "Total params: 7,633,482\n",
      "Trainable params: 238,482\n",
      "Non-trainable params: 7,395,000\n",
      "_________________________________________________________________\n",
      "Train on 75150 samples, validate on 18788 samples\n",
      "Epoch 1/10\n",
      "75150/75150 [==============================] - 106s 1ms/step - loss: 0.0368 - categorical_accuracy: 0.7969 - val_loss: 0.0269 - val_categorical_accuracy: 0.8530\n",
      "Epoch 2/10\n",
      "75150/75150 [==============================] - 104s 1ms/step - loss: 0.0231 - categorical_accuracy: 0.8750 - val_loss: 0.0247 - val_categorical_accuracy: 0.8671\n",
      "Epoch 3/10\n",
      "75150/75150 [==============================] - 103s 1ms/step - loss: 0.0182 - categorical_accuracy: 0.9013 - val_loss: 0.0254 - val_categorical_accuracy: 0.8694\n",
      "Epoch 4/10\n",
      "75150/75150 [==============================] - 103s 1ms/step - loss: 0.0152 - categorical_accuracy: 0.9188 - val_loss: 0.0276 - val_categorical_accuracy: 0.8632\n",
      "Epoch 5/10\n",
      "75150/75150 [==============================] - 104s 1ms/step - loss: 0.0129 - categorical_accuracy: 0.9334 - val_loss: 0.0303 - val_categorical_accuracy: 0.8590\n",
      "Epoch 6/10\n",
      "75150/75150 [==============================] - 103s 1ms/step - loss: 0.0114 - categorical_accuracy: 0.9420 - val_loss: 0.0304 - val_categorical_accuracy: 0.8647\n",
      "Epoch 7/10\n",
      "75150/75150 [==============================] - 103s 1ms/step - loss: 0.0098 - categorical_accuracy: 0.9514 - val_loss: 0.0317 - val_categorical_accuracy: 0.8509\n",
      "Epoch 8/10\n",
      "75150/75150 [==============================] - 104s 1ms/step - loss: 0.0095 - categorical_accuracy: 0.9539 - val_loss: 0.0319 - val_categorical_accuracy: 0.8653\n",
      "Epoch 9/10\n",
      "75150/75150 [==============================] - 104s 1ms/step - loss: 0.0086 - categorical_accuracy: 0.9585 - val_loss: 0.0327 - val_categorical_accuracy: 0.8677\n",
      "Epoch 10/10\n",
      "75150/75150 [==============================] - 104s 1ms/step - loss: 0.0085 - categorical_accuracy: 0.9606 - val_loss: 0.0355 - val_categorical_accuracy: 0.8616\n",
      "23485/23485 [==============================] - 12s 530us/step\n",
      "Accuracy: 0.8581222056504993 Loss: 0.03641261019907957\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8581222056504993, 0.03641261019907957)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlFS.creatmodel(sequences,sequences_test,embedding_matrix,350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 350, 300)          7395000   \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 346, 125)          187625    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 115, 125)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 111, 125)          78250     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 37, 125)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 33, 125)           78250     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 11, 125)           0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1375)              0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 1375)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 32)                44032     \n",
      "=================================================================\n",
      "Total params: 7,783,157\n",
      "Trainable params: 388,157\n",
      "Non-trainable params: 7,395,000\n",
      "_________________________________________________________________\n",
      "Train on 75150 samples, validate on 18788 samples\n",
      "Epoch 1/10\n",
      "75150/75150 [==============================] - 143s 2ms/step - loss: 0.0528 - categorical_accuracy: 0.6919 - val_loss: 0.0374 - val_categorical_accuracy: 0.7906\n",
      "Epoch 2/10\n",
      "75150/75150 [==============================] - 141s 2ms/step - loss: 0.0334 - categorical_accuracy: 0.8134 - val_loss: 0.0341 - val_categorical_accuracy: 0.8099\n",
      "Epoch 3/10\n",
      "75150/75150 [==============================] - 140s 2ms/step - loss: 0.0269 - categorical_accuracy: 0.8500 - val_loss: 0.0305 - val_categorical_accuracy: 0.8323\n",
      "Epoch 4/10\n",
      "75150/75150 [==============================] - 140s 2ms/step - loss: 0.0224 - categorical_accuracy: 0.8753 - val_loss: 0.0315 - val_categorical_accuracy: 0.8324\n",
      "Epoch 5/10\n",
      "75150/75150 [==============================] - 140s 2ms/step - loss: 0.0189 - categorical_accuracy: 0.8959 - val_loss: 0.0317 - val_categorical_accuracy: 0.8406\n",
      "Epoch 6/10\n",
      "75150/75150 [==============================] - 140s 2ms/step - loss: 0.0162 - categorical_accuracy: 0.9111 - val_loss: 0.0342 - val_categorical_accuracy: 0.8334\n",
      "Epoch 7/10\n",
      "75150/75150 [==============================] - 141s 2ms/step - loss: 0.0142 - categorical_accuracy: 0.9226 - val_loss: 0.0342 - val_categorical_accuracy: 0.8387\n",
      "Epoch 8/10\n",
      "75150/75150 [==============================] - 140s 2ms/step - loss: 0.0129 - categorical_accuracy: 0.9305 - val_loss: 0.0357 - val_categorical_accuracy: 0.8397\n",
      "Epoch 9/10\n",
      "75150/75150 [==============================] - 140s 2ms/step - loss: 0.0116 - categorical_accuracy: 0.9374 - val_loss: 0.0380 - val_categorical_accuracy: 0.8420\n",
      "Epoch 10/10\n",
      "75150/75150 [==============================] - 140s 2ms/step - loss: 0.0106 - categorical_accuracy: 0.9434 - val_loss: 0.0404 - val_categorical_accuracy: 0.8365\n",
      "23485/23485 [==============================] - 16s 686us/step\n",
      "Accuracy: 0.8364913775079779 Loss: 0.040383666406381837\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8364913775079779, 0.040383666406381837)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlFS.creatndmodel(sequences,sequences_test,embedding_matrix,350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, 350, 300)          7395000   \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 350, 300)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 346, 128)          192128    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 86, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 70)                55720     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 32)                2272      \n",
      "=================================================================\n",
      "Total params: 7,645,120\n",
      "Trainable params: 250,120\n",
      "Non-trainable params: 7,395,000\n",
      "_________________________________________________________________\n",
      "Train on 75150 samples, validate on 18788 samples\n",
      "Epoch 1/10\n",
      "75150/75150 [==============================] - 194s 3ms/step - loss: 0.0536 - categorical_accuracy: 0.6977 - val_loss: 0.0408 - val_categorical_accuracy: 0.7735\n",
      "Epoch 2/10\n",
      "75150/75150 [==============================] - 191s 3ms/step - loss: 0.0383 - categorical_accuracy: 0.7858 - val_loss: 0.0354 - val_categorical_accuracy: 0.8065\n",
      "Epoch 3/10\n",
      "75150/75150 [==============================] - 188s 3ms/step - loss: 0.0335 - categorical_accuracy: 0.8149 - val_loss: 0.0329 - val_categorical_accuracy: 0.8202\n",
      "Epoch 4/10\n",
      "75150/75150 [==============================] - 190s 3ms/step - loss: 0.0306 - categorical_accuracy: 0.8317 - val_loss: 0.0308 - val_categorical_accuracy: 0.8322\n",
      "Epoch 5/10\n",
      "75150/75150 [==============================] - 189s 3ms/step - loss: 0.0282 - categorical_accuracy: 0.8460 - val_loss: 0.0300 - val_categorical_accuracy: 0.8371\n",
      "Epoch 6/10\n",
      "75150/75150 [==============================] - 189s 3ms/step - loss: 0.0265 - categorical_accuracy: 0.8558 - val_loss: 0.0291 - val_categorical_accuracy: 0.8414\n",
      "Epoch 7/10\n",
      "75150/75150 [==============================] - 190s 3ms/step - loss: 0.0250 - categorical_accuracy: 0.8634 - val_loss: 0.0297 - val_categorical_accuracy: 0.8411\n",
      "Epoch 8/10\n",
      "75150/75150 [==============================] - 188s 2ms/step - loss: 0.0239 - categorical_accuracy: 0.8698 - val_loss: 0.0293 - val_categorical_accuracy: 0.8438\n",
      "Epoch 9/10\n",
      "75150/75150 [==============================] - 189s 3ms/step - loss: 0.0228 - categorical_accuracy: 0.8760 - val_loss: 0.0294 - val_categorical_accuracy: 0.8419\n",
      "Epoch 10/10\n",
      "75150/75150 [==============================] - 189s 3ms/step - loss: 0.0221 - categorical_accuracy: 0.8799 - val_loss: 0.0295 - val_categorical_accuracy: 0.8436\n",
      "23485/23485 [==============================] - 21s 880us/step\n",
      "Accuracy: 0.8436022993501562 Loss: 0.029303839993566966\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8436022993501562, 0.029303839993566966)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlFS.creatrdmodel(sequences,sequences_test,embedding_matrix, 350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
