{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import RandomOverSampler,SMOTE\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.feature_selection import SelectKBest,chi2\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.svm import LinearSVC\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data sources list \n",
    "folder = ['Amazon','FlipKart','Combine','Walmart']\n",
    "class SamplingApproach:\n",
    "    def __init__(self,num):\n",
    "        self.num = num\n",
    "    # initialise the train and test data\n",
    "    def openFile(self):\n",
    "        num = self.num\n",
    "        print(\"----- OPEN \"+folder[num]+\" data ----- \\n\")\n",
    "        trainData = pd.read_csv(folder[num]+'/X_train.csv')\n",
    "        trainLabel = pd.read_csv(folder[num]+'/y_train.csv')\n",
    "        testData = pd.read_csv(folder[num]+'/X_test.csv')\n",
    "        testLabel = pd.read_csv(folder[num]+'/y_test.csv')\n",
    "        if(num==0 or num==2):\n",
    "            # For Description has nan row\n",
    "            df = pd.concat([trainData,trainLabel], axis = 1)\n",
    "            df = df.dropna(subset=['X_train'])\n",
    "            trainData = pd.DataFrame({'X_train':df.X_train})\n",
    "            trainLabel = pd.DataFrame({'category':df.category,'subcategory':df.subcategory})\n",
    "            df = pd.concat([testData,testLabel], axis = 1)\n",
    "            df = df.dropna(subset=['X_test'])\n",
    "            testData = pd.DataFrame({'X_test':df.X_test})\n",
    "            testLabel = pd.DataFrame({'category':df.category,'subcategory':df.subcategory})\n",
    "        X_train = trainData['X_train']\n",
    "        y_train = trainLabel['category']\n",
    "        X_test = testData['X_test']\n",
    "        y_test = testLabel['category']\n",
    "        return X_train,y_train,X_test,y_test\n",
    "\n",
    "    def tfidfConvert(self,Xtrain, Xtest):\n",
    "        tfidfconverter = TfidfVectorizer(min_df=5, max_df=0.7)\n",
    "        print(\"----- Convert train data and test data to vector ----- \\n\")\n",
    "        X = tfidfconverter.fit_transform(Xtrain)\n",
    "        XTest = tfidfconverter.transform(Xtest)\n",
    "        originTrainFeatures = X\n",
    "        originTestFeatures = XTest\n",
    "        print(\"----- Total # features: \"+str(X.shape[1])+\" ----- \\n\")\n",
    "        total_feature = X.shape[1]\n",
    "        return originTrainFeatures,originTestFeatures,total_feature\n",
    "    def selectBestfeatureViaChi2(self,Xtrain, Xtest,yTrain,num):\n",
    "        print(\"----- Select Best \"+str(num)+\" features ----- \\n\")\n",
    "        selectBest = SelectKBest(chi2, k=num).fit(Xtrain, yTrain)\n",
    "        select_feature = selectBest.transform(Xtrain)\n",
    "        test_features = selectBest.transform(Xtest)\n",
    "        return select_feature, test_features\n",
    "    def ros (self, Xtrain, Ytrain):\n",
    "        ros = RandomOverSampler(random_state=42)\n",
    "        X_resampled, y_resampled = ros.fit_resample(Xtrain, Ytrain)\n",
    "        return X_resampled, y_resampled\n",
    "    def SMOTE (self,Xtrain, Ytrain):\n",
    "        smote = SMOTE(random_state=42, sampling_strategy= 'minority',k_neighbors=5)\n",
    "        X_resampled, y_resampled = smote.fit_resample(Xtrain, Ytrain)\n",
    "        return X_resampled,y_resampled\n",
    "    def MNBC(self, Xtrain, Xtest, Ytrain, Ytest,num):\n",
    "        select_feature, test_features = self.selectBestfeatureViaChi2(Xtrain, Xtest,Ytrain,num)\n",
    "        MNB = ComplementNB()\n",
    "        print(\"----- CNBC fitting -----\")\n",
    "        MNB.fit(select_feature,Ytrain)\n",
    "        main_category = np.unique(Ytrain)\n",
    "        score = MNB.score(test_features,Ytest)\n",
    "        y_pred =MNB.predict(test_features)\n",
    "        print(classification_report(Ytest, y_pred,labels=main_category))\n",
    "        return score\n",
    "\n",
    "    def SVC(self,  Xtrain, Xtest, Ytrain, Ytest,num):\n",
    "        select_feature, test_features = self.selectBestfeatureViaChi2(Xtrain, Xtest,Ytrain,num)\n",
    "        svc = LinearSVC(random_state=42,class_weight=\"balanced\")\n",
    "        print(\"----- SVC fitting -----\")\n",
    "        svc.fit(select_feature,Ytrain)\n",
    "        main_category = np.unique(Ytrain)\n",
    "        score = svc.score(test_features,Ytest)\n",
    "        y_pred =svc.predict(test_features)\n",
    "        print(classification_report(Ytest, y_pred,labels=main_category))\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = SamplingApproach(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- OPEN Amazon data ----- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train,y_train,X_test,y_test = sa.openFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Convert train data and test data to vector ----- \n",
      "\n",
      "----- Total # features: 5927 ----- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "originTrainFeatures,originTestFeatures,total_feature = sa.tfidfConvert(X_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Select Best 5000 features ----- \n",
      "\n",
      "----- CNBC fitting -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       143\n",
      "           1       1.00      0.50      0.67         4\n",
      "           2       0.81      0.51      0.63       181\n",
      "           3       0.80      0.82      0.81       233\n",
      "           4       0.73      0.87      0.79        46\n",
      "           5       0.87      0.88      0.88       113\n",
      "           6       0.73      0.81      0.77       208\n",
      "           7       0.80      0.87      0.83       165\n",
      "           8       0.78      0.74      0.76       260\n",
      "           9       0.66      0.78      0.72        50\n",
      "          10       0.85      0.91      0.88       109\n",
      "          11       0.67      0.20      0.31        10\n",
      "          12       0.86      0.98      0.91        44\n",
      "          13       0.84      0.76      0.80        67\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      1633\n",
      "   macro avg       0.80      0.75      0.76      1633\n",
      "weighted avg       0.79      0.79      0.79      1633\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7930189834660135"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa.MNBC(originTrainFeatures,originTestFeatures,y_train,y_test,5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Select Best 5000 features ----- \n",
      "\n",
      "----- CNBC fitting -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84       143\n",
      "           1       0.13      1.00      0.24         4\n",
      "           2       0.78      0.48      0.59       181\n",
      "           3       0.79      0.81      0.80       233\n",
      "           4       0.63      0.83      0.72        46\n",
      "           5       0.81      0.85      0.83       113\n",
      "           6       0.74      0.71      0.73       208\n",
      "           7       0.81      0.82      0.82       165\n",
      "           8       0.81      0.66      0.73       260\n",
      "           9       0.57      0.86      0.68        50\n",
      "          10       0.85      0.91      0.88       109\n",
      "          11       0.29      0.80      0.42        10\n",
      "          12       0.81      0.98      0.89        44\n",
      "          13       0.68      0.79      0.73        67\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      1633\n",
      "   macro avg       0.68      0.81      0.71      1633\n",
      "weighted avg       0.78      0.76      0.76      1633\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7562767911818739"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled, y_resampled = sa.ros(originTrainFeatures,y_train)\n",
    "sa.MNBC(X_resampled,originTestFeatures,y_resampled,y_test,5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Select Best 5000 features ----- \n",
      "\n",
      "----- CNBC fitting -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83       143\n",
      "           1       0.08      1.00      0.14         4\n",
      "           2       0.81      0.51      0.63       181\n",
      "           3       0.80      0.80      0.80       233\n",
      "           4       0.82      0.89      0.85        46\n",
      "           5       0.88      0.88      0.88       113\n",
      "           6       0.73      0.79      0.76       208\n",
      "           7       0.82      0.84      0.83       165\n",
      "           8       0.79      0.76      0.77       260\n",
      "           9       0.73      0.70      0.71        50\n",
      "          10       0.84      0.91      0.87       109\n",
      "          11       0.50      0.10      0.17        10\n",
      "          12       0.90      0.98      0.93        44\n",
      "          13       0.83      0.73      0.78        67\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      1633\n",
      "   macro avg       0.74      0.77      0.71      1633\n",
      "weighted avg       0.80      0.78      0.78      1633\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7783221065523577"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled, y_resampled = sa.SMOTE(originTrainFeatures,y_train)\n",
    "sa.MNBC(X_resampled,originTestFeatures,y_resampled,y_test,5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Select Best 3000 features ----- \n",
      "\n",
      "----- SVC fitting -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87       143\n",
      "           1       0.43      0.75      0.55         4\n",
      "           2       0.76      0.65      0.70       181\n",
      "           3       0.85      0.87      0.86       233\n",
      "           4       0.79      0.91      0.85        46\n",
      "           5       0.86      0.88      0.87       113\n",
      "           6       0.75      0.81      0.78       208\n",
      "           7       0.82      0.84      0.83       165\n",
      "           8       0.78      0.76      0.77       260\n",
      "           9       0.77      0.80      0.78        50\n",
      "          10       0.93      0.94      0.94       109\n",
      "          11       0.62      0.50      0.56        10\n",
      "          12       0.93      0.98      0.96        44\n",
      "          13       0.82      0.73      0.77        67\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      1633\n",
      "   macro avg       0.79      0.81      0.79      1633\n",
      "weighted avg       0.82      0.82      0.82      1633\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8162890385793019"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa.SVC(originTrainFeatures,originTestFeatures,y_train,y_test,3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Select Best 3000 features ----- \n",
      "\n",
      "----- SVC fitting -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.87       143\n",
      "           1       0.50      0.75      0.60         4\n",
      "           2       0.74      0.66      0.70       181\n",
      "           3       0.83      0.85      0.84       233\n",
      "           4       0.84      0.89      0.86        46\n",
      "           5       0.85      0.86      0.85       113\n",
      "           6       0.76      0.80      0.78       208\n",
      "           7       0.80      0.84      0.82       165\n",
      "           8       0.76      0.76      0.76       260\n",
      "           9       0.80      0.80      0.80        50\n",
      "          10       0.90      0.92      0.91       109\n",
      "          11       0.67      0.60      0.63        10\n",
      "          12       0.95      0.93      0.94        44\n",
      "          13       0.81      0.72      0.76        67\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      1633\n",
      "   macro avg       0.79      0.80      0.80      1633\n",
      "weighted avg       0.81      0.81      0.81      1633\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8089406001224739"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled, y_resampled = sa.ros(originTrainFeatures,y_train)\n",
    "sa.SVC(X_resampled,originTestFeatures,y_resampled,y_test,3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Select Best 3000 features ----- \n",
      "\n",
      "----- SVC fitting -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87       143\n",
      "           1       0.43      0.75      0.55         4\n",
      "           2       0.75      0.65      0.69       181\n",
      "           3       0.85      0.86      0.85       233\n",
      "           4       0.78      0.91      0.84        46\n",
      "           5       0.86      0.89      0.87       113\n",
      "           6       0.76      0.80      0.78       208\n",
      "           7       0.82      0.83      0.82       165\n",
      "           8       0.78      0.77      0.78       260\n",
      "           9       0.78      0.80      0.79        50\n",
      "          10       0.93      0.94      0.93       109\n",
      "          11       0.67      0.60      0.63        10\n",
      "          12       0.93      0.98      0.96        44\n",
      "          13       0.82      0.73      0.77        67\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      1633\n",
      "   macro avg       0.79      0.81      0.80      1633\n",
      "weighted avg       0.81      0.82      0.81      1633\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8150642988364972"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled, y_resampled = sa.SMOTE(originTrainFeatures,y_train)\n",
    "sa.SVC(X_resampled,originTestFeatures,y_resampled,y_test,3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = SamplingApproach(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- OPEN FlipKart data ----- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train,y_train,X_test,y_test = sa.openFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Convert train data and test data to vector ----- \n",
      "\n",
      "----- Total # features: 4742 ----- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "originTrainFeatures,originTestFeatures,total_feature = sa.tfidfConvert(X_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Select Best 4000 features ----- \n",
      "\n",
      "----- CNBC fitting -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       163\n",
      "           1       1.00      0.59      0.74        82\n",
      "           2       1.00      0.94      0.97        35\n",
      "           3       0.98      0.92      0.95        95\n",
      "           4       1.00      1.00      1.00        13\n",
      "           5       0.97      1.00      0.98      1231\n",
      "           6       0.97      0.89      0.93       105\n",
      "           7       1.00      1.00      1.00       208\n",
      "           8       1.00      0.91      0.95        11\n",
      "           9       0.99      0.97      0.98       117\n",
      "          10       0.99      0.99      0.99        84\n",
      "          11       0.97      1.00      0.98       487\n",
      "          12       1.00      0.96      0.98       107\n",
      "          13       0.95      0.99      0.97       197\n",
      "          14       0.93      0.50      0.65        28\n",
      "          15       1.00      0.99      0.99        67\n",
      "          16       0.73      0.93      0.82        41\n",
      "          17       1.00      1.00      1.00        27\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      3098\n",
      "   macro avg       0.97      0.92      0.94      3098\n",
      "weighted avg       0.97      0.97      0.97      3098\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9706262104583603"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa.MNBC(originTrainFeatures,originTestFeatures,y_train,y_test,4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Select Best 4000 features ----- \n",
      "\n",
      "----- CNBC fitting -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       163\n",
      "           1       0.54      0.96      0.70        82\n",
      "           2       0.92      1.00      0.96        35\n",
      "           3       0.96      0.98      0.97        95\n",
      "           4       0.76      1.00      0.87        13\n",
      "           5       1.00      0.92      0.96      1231\n",
      "           6       0.96      0.90      0.93       105\n",
      "           7       0.98      1.00      0.99       208\n",
      "           8       1.00      1.00      1.00        11\n",
      "           9       0.96      0.96      0.96       117\n",
      "          10       0.94      0.99      0.97        84\n",
      "          11       1.00      1.00      1.00       487\n",
      "          12       0.93      0.98      0.95       107\n",
      "          13       0.94      0.98      0.96       197\n",
      "          14       0.67      0.64      0.65        28\n",
      "          15       0.99      0.99      0.99        67\n",
      "          16       0.70      0.76      0.73        41\n",
      "          17       0.96      1.00      0.98        27\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      3098\n",
      "   macro avg       0.90      0.95      0.92      3098\n",
      "weighted avg       0.96      0.95      0.96      3098\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9528728211749515"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled, y_resampled = sa.ros(originTrainFeatures,y_train)\n",
    "sa.MNBC(X_resampled,originTestFeatures,y_resampled,y_test,4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Select Best 4000 features ----- \n",
      "\n",
      "----- CNBC fitting -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       163\n",
      "           1       1.00      0.51      0.68        82\n",
      "           2       1.00      0.91      0.96        35\n",
      "           3       0.99      0.85      0.92        95\n",
      "           4       0.42      1.00      0.59        13\n",
      "           5       0.96      1.00      0.98      1231\n",
      "           6       0.98      0.89      0.93       105\n",
      "           7       1.00      0.99      1.00       208\n",
      "           8       1.00      0.91      0.95        11\n",
      "           9       0.99      0.96      0.97       117\n",
      "          10       0.99      0.99      0.99        84\n",
      "          11       0.98      1.00      0.99       487\n",
      "          12       1.00      0.96      0.98       107\n",
      "          13       0.95      0.99      0.97       197\n",
      "          14       0.93      0.50      0.65        28\n",
      "          15       1.00      0.99      0.99        67\n",
      "          16       0.75      0.93      0.83        41\n",
      "          17       1.00      1.00      1.00        27\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      3098\n",
      "   macro avg       0.94      0.91      0.91      3098\n",
      "weighted avg       0.97      0.97      0.96      3098\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9651387992253067"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled, y_resampled = sa.SMOTE(originTrainFeatures,y_train)\n",
    "sa.MNBC(X_resampled,originTestFeatures,y_resampled,y_test,4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Select Best 4000 features ----- \n",
      "\n",
      "----- SVC fitting -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       163\n",
      "           1       0.94      0.96      0.95        82\n",
      "           2       1.00      0.97      0.99        35\n",
      "           3       1.00      1.00      1.00        95\n",
      "           4       1.00      1.00      1.00        13\n",
      "           5       1.00      1.00      1.00      1231\n",
      "           6       0.99      0.96      0.98       105\n",
      "           7       1.00      1.00      1.00       208\n",
      "           8       1.00      0.91      0.95        11\n",
      "           9       0.99      1.00      1.00       117\n",
      "          10       1.00      0.99      0.99        84\n",
      "          11       1.00      1.00      1.00       487\n",
      "          12       1.00      1.00      1.00       107\n",
      "          13       0.98      0.99      0.99       197\n",
      "          14       0.78      0.75      0.76        28\n",
      "          15       1.00      1.00      1.00        67\n",
      "          16       0.83      0.85      0.84        41\n",
      "          17       1.00      1.00      1.00        27\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3098\n",
      "   macro avg       0.97      0.97      0.97      3098\n",
      "weighted avg       0.99      0.99      0.99      3098\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9903163331181407"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa.SVC(originTrainFeatures,originTestFeatures,y_train,y_test,4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Select Best 4000 features ----- \n",
      "\n",
      "----- SVC fitting -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       163\n",
      "           1       0.94      0.96      0.95        82\n",
      "           2       1.00      0.97      0.99        35\n",
      "           3       1.00      1.00      1.00        95\n",
      "           4       1.00      1.00      1.00        13\n",
      "           5       1.00      1.00      1.00      1231\n",
      "           6       0.99      0.96      0.98       105\n",
      "           7       1.00      1.00      1.00       208\n",
      "           8       1.00      0.91      0.95        11\n",
      "           9       0.98      1.00      0.99       117\n",
      "          10       1.00      0.99      0.99        84\n",
      "          11       1.00      1.00      1.00       487\n",
      "          12       1.00      1.00      1.00       107\n",
      "          13       0.98      0.99      0.99       197\n",
      "          14       0.76      0.89      0.82        28\n",
      "          15       1.00      1.00      1.00        67\n",
      "          16       0.92      0.80      0.86        41\n",
      "          17       1.00      1.00      1.00        27\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3098\n",
      "   macro avg       0.98      0.97      0.97      3098\n",
      "weighted avg       0.99      0.99      0.99      3098\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9909619109102646"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled, y_resampled = sa.ros(originTrainFeatures,y_train)\n",
    "sa.SVC(X_resampled,originTestFeatures,y_resampled,y_test,4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Select Best 4000 features ----- \n",
      "\n",
      "----- SVC fitting -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       163\n",
      "           1       0.94      0.96      0.95        82\n",
      "           2       1.00      0.97      0.99        35\n",
      "           3       1.00      1.00      1.00        95\n",
      "           4       1.00      1.00      1.00        13\n",
      "           5       1.00      1.00      1.00      1231\n",
      "           6       0.99      0.96      0.98       105\n",
      "           7       1.00      1.00      1.00       208\n",
      "           8       1.00      0.91      0.95        11\n",
      "           9       0.99      1.00      1.00       117\n",
      "          10       1.00      0.99      0.99        84\n",
      "          11       1.00      1.00      1.00       487\n",
      "          12       1.00      1.00      1.00       107\n",
      "          13       0.98      0.99      0.99       197\n",
      "          14       0.78      0.75      0.76        28\n",
      "          15       1.00      1.00      1.00        67\n",
      "          16       0.83      0.85      0.84        41\n",
      "          17       1.00      1.00      1.00        27\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3098\n",
      "   macro avg       0.97      0.97      0.97      3098\n",
      "weighted avg       0.99      0.99      0.99      3098\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9903163331181407"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled, y_resampled = sa.SMOTE(originTrainFeatures,y_train)\n",
    "sa.SVC(X_resampled,originTestFeatures,y_resampled,y_test,4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = SamplingApproach(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- OPEN Combine data ----- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train,y_train,X_test,y_test = sa.openFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Convert train data and test data to vector ----- \n",
      "\n",
      "----- Total # features: 9848 ----- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "originTrainFeatures,originTestFeatures,total_feature = sa.tfidfConvert(X_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Select Best 6000 features ----- \n",
      "\n",
      "----- CNBC fitting -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       191\n",
      "           1       0.91      0.45      0.60        92\n",
      "           2       0.96      0.48      0.64        94\n",
      "           3       0.93      0.83      0.88       145\n",
      "           4       0.94      0.98      0.96       346\n",
      "           5       0.97      0.97      0.97      2536\n",
      "           6       0.95      0.95      0.95       613\n",
      "           7       0.91      0.97      0.94      1635\n",
      "           8       0.97      0.73      0.84        52\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      5704\n",
      "   macro avg       0.94      0.81      0.86      5704\n",
      "weighted avg       0.95      0.95      0.94      5704\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.947054698457223"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa.MNBC(originTrainFeatures,originTestFeatures,y_train,y_test,6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Select Best 6000 features ----- \n",
      "\n",
      "----- CNBC fitting -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91       191\n",
      "           1       0.47      0.86      0.61        92\n",
      "           2       0.36      0.88      0.51        94\n",
      "           3       0.73      0.96      0.83       145\n",
      "           4       0.88      0.98      0.93       346\n",
      "           5       0.99      0.92      0.95      2536\n",
      "           6       0.96      0.90      0.93       613\n",
      "           7       0.97      0.87      0.92      1635\n",
      "           8       0.41      0.98      0.58        52\n",
      "\n",
      "   micro avg       0.91      0.91      0.91      5704\n",
      "   macro avg       0.74      0.92      0.80      5704\n",
      "weighted avg       0.94      0.91      0.92      5704\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9079593267882188"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled, y_resampled = sa.ros(originTrainFeatures,y_train)\n",
    "sa.MNBC(X_resampled,originTestFeatures,y_resampled,y_test,6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Select Best 6000 features ----- \n",
      "\n",
      "----- CNBC fitting -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       191\n",
      "           1       0.87      0.45      0.59        92\n",
      "           2       0.96      0.48      0.64        94\n",
      "           3       0.95      0.75      0.84       145\n",
      "           4       0.94      0.97      0.96       346\n",
      "           5       0.96      0.98      0.97      2536\n",
      "           6       0.96      0.93      0.94       613\n",
      "           7       0.93      0.95      0.94      1635\n",
      "           8       0.57      0.98      0.72        52\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      5704\n",
      "   macro avg       0.90      0.82      0.83      5704\n",
      "weighted avg       0.94      0.94      0.94      5704\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9412692847124825"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled, y_resampled = sa.SMOTE(originTrainFeatures,y_train)\n",
    "sa.MNBC(X_resampled,originTestFeatures,y_resampled,y_test,6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Select Best 6000 features ----- \n",
      "\n",
      "----- SVC fitting -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       191\n",
      "           1       0.82      0.76      0.79        92\n",
      "           2       0.88      0.86      0.87        94\n",
      "           3       0.97      0.96      0.96       145\n",
      "           4       0.98      0.99      0.98       346\n",
      "           5       0.99      0.99      0.99      2536\n",
      "           6       0.98      0.98      0.98       613\n",
      "           7       0.97      0.98      0.97      1635\n",
      "           8       0.98      0.94      0.96        52\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      5704\n",
      "   macro avg       0.95      0.94      0.94      5704\n",
      "weighted avg       0.98      0.98      0.98      5704\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.978085553997195"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa.SVC(originTrainFeatures,originTestFeatures,y_train,y_test,6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Select Best 6000 features ----- \n",
      "\n",
      "----- SVC fitting -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       191\n",
      "           1       0.82      0.74      0.78        92\n",
      "           2       0.84      0.89      0.87        94\n",
      "           3       0.96      0.96      0.96       145\n",
      "           4       0.98      0.99      0.98       346\n",
      "           5       0.99      0.99      0.99      2536\n",
      "           6       0.97      0.98      0.97       613\n",
      "           7       0.97      0.98      0.97      1635\n",
      "           8       0.91      0.92      0.91        52\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      5704\n",
      "   macro avg       0.94      0.94      0.94      5704\n",
      "weighted avg       0.98      0.98      0.98      5704\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9761570827489481"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled, y_resampled = sa.ros(originTrainFeatures,y_train)\n",
    "sa.SVC(X_resampled,originTestFeatures,y_resampled,y_test,6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Select Best 6000 features ----- \n",
      "\n",
      "----- SVC fitting -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       191\n",
      "           1       0.83      0.75      0.79        92\n",
      "           2       0.90      0.87      0.89        94\n",
      "           3       0.97      0.96      0.96       145\n",
      "           4       0.98      0.99      0.98       346\n",
      "           5       0.99      0.99      0.99      2536\n",
      "           6       0.97      0.98      0.98       613\n",
      "           7       0.97      0.97      0.97      1635\n",
      "           8       0.72      0.98      0.83        52\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      5704\n",
      "   macro avg       0.92      0.94      0.93      5704\n",
      "weighted avg       0.98      0.98      0.98      5704\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9756311360448808"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled, y_resampled = sa.SMOTE(originTrainFeatures,y_train)\n",
    "sa.SVC(X_resampled,originTestFeatures,y_resampled,y_test,6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = SamplingApproach(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- OPEN Walmart data ----- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train,y_train,X_test,y_test = sa.openFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Convert train data and test data to vector ----- \n",
      "\n",
      "----- Total # features: 24650 ----- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "originTrainFeatures,originTestFeatures,total_feature = sa.tfidfConvert(X_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Select Best 24000 features ----- \n",
      "\n",
      "----- CNBC fitting -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.79      0.58       114\n",
      "           1       0.81      0.55      0.66       277\n",
      "           2       0.86      0.97      0.91      2404\n",
      "           3       0.88      0.88      0.88      2047\n",
      "           4       0.72      0.87      0.79      1031\n",
      "           5       0.87      0.93      0.90      5988\n",
      "           6       0.91      0.58      0.71        36\n",
      "           7       1.00      0.08      0.15        50\n",
      "           8       0.79      0.43      0.56       573\n",
      "           9       0.83      0.41      0.55       362\n",
      "          10       0.76      0.34      0.47        38\n",
      "          11       0.77      0.20      0.32       239\n",
      "          12       0.88      0.96      0.92      4572\n",
      "          13       0.80      0.62      0.70       129\n",
      "          14       0.00      0.00      0.00        10\n",
      "          15       0.80      0.87      0.83      1567\n",
      "          16       0.82      0.89      0.85       190\n",
      "          17       0.89      0.51      0.65       123\n",
      "          18       0.86      0.83      0.85       193\n",
      "          19       0.80      0.43      0.56       669\n",
      "          20       0.00      0.00      0.00        30\n",
      "          21       0.76      0.72      0.74       282\n",
      "          22       0.82      0.90      0.86       814\n",
      "          23       0.78      0.72      0.75       207\n",
      "          24       0.85      0.37      0.52       222\n",
      "          25       0.77      0.69      0.73       999\n",
      "          26       0.71      0.08      0.14       152\n",
      "          27       0.00      0.00      0.00        13\n",
      "          28       0.00      0.00      0.00         4\n",
      "          29       0.83      0.50      0.62        70\n",
      "          30       0.00      0.00      0.00        11\n",
      "          31       0.70      0.58      0.63        69\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     23485\n",
      "   macro avg       0.68      0.52      0.56     23485\n",
      "weighted avg       0.84      0.84      0.83     23485\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/justin/classification/app/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8417713434106877"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa.MNBC(originTrainFeatures,originTestFeatures,y_train,y_test,24000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Select Best 24000 features ----- \n",
      "\n",
      "----- CNBC fitting -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.92      0.33       114\n",
      "           1       0.41      0.71      0.52       277\n",
      "           2       0.93      0.95      0.94      2404\n",
      "           3       0.92      0.73      0.81      2047\n",
      "           4       0.83      0.69      0.76      1031\n",
      "           5       0.96      0.64      0.77      5988\n",
      "           6       0.24      0.75      0.36        36\n",
      "           7       0.28      0.36      0.32        50\n",
      "           8       0.56      0.62      0.59       573\n",
      "           9       0.58      0.62      0.60       362\n",
      "          10       0.11      0.84      0.19        38\n",
      "          11       0.19      0.90      0.31       239\n",
      "          12       0.96      0.71      0.82      4572\n",
      "          13       0.42      0.90      0.57       129\n",
      "          14       0.02      0.60      0.04        10\n",
      "          15       0.89      0.73      0.80      1567\n",
      "          16       0.60      0.90      0.72       190\n",
      "          17       0.42      0.77      0.54       123\n",
      "          18       0.59      0.89      0.71       193\n",
      "          19       0.65      0.57      0.61       669\n",
      "          20       0.08      0.77      0.14        30\n",
      "          21       0.68      0.71      0.69       282\n",
      "          22       0.83      0.83      0.83       814\n",
      "          23       0.44      0.87      0.58       207\n",
      "          24       0.50      0.62      0.55       222\n",
      "          25       0.80      0.58      0.68       999\n",
      "          26       0.31      0.59      0.41       152\n",
      "          27       0.03      0.92      0.06        13\n",
      "          28       0.05      1.00      0.09         4\n",
      "          29       0.23      0.84      0.37        70\n",
      "          30       0.03      0.55      0.06        11\n",
      "          31       0.29      0.81      0.42        69\n",
      "\n",
      "   micro avg       0.72      0.72      0.72     23485\n",
      "   macro avg       0.47      0.75      0.51     23485\n",
      "weighted avg       0.85      0.72      0.76     23485\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7179050457738982"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled, y_resampled = sa.ros(originTrainFeatures,y_train)\n",
    "sa.MNBC(X_resampled,originTestFeatures,y_resampled,y_test,24000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Select Best 24000 features ----- \n",
      "\n",
      "----- CNBC fitting -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.77      0.58       114\n",
      "           1       0.81      0.44      0.57       277\n",
      "           2       0.87      0.97      0.92      2404\n",
      "           3       0.89      0.85      0.87      2047\n",
      "           4       0.72      0.86      0.78      1031\n",
      "           5       0.84      0.94      0.89      5988\n",
      "           6       0.95      0.58      0.72        36\n",
      "           7       1.00      0.08      0.15        50\n",
      "           8       0.80      0.42      0.55       573\n",
      "           9       0.86      0.38      0.52       362\n",
      "          10       0.69      0.24      0.35        38\n",
      "          11       0.83      0.16      0.27       239\n",
      "          12       0.89      0.91      0.90      4572\n",
      "          13       0.85      0.61      0.71       129\n",
      "          14       0.01      0.50      0.02        10\n",
      "          15       0.80      0.87      0.83      1567\n",
      "          16       0.83      0.88      0.85       190\n",
      "          17       0.92      0.48      0.63       123\n",
      "          18       0.87      0.82      0.85       193\n",
      "          19       0.80      0.41      0.54       669\n",
      "          20       0.00      0.00      0.00        30\n",
      "          21       0.76      0.70      0.73       282\n",
      "          22       0.84      0.90      0.87       814\n",
      "          23       0.80      0.68      0.73       207\n",
      "          24       0.85      0.26      0.39       222\n",
      "          25       0.80      0.63      0.71       999\n",
      "          26       0.69      0.07      0.13       152\n",
      "          27       0.00      0.00      0.00        13\n",
      "          28       0.00      0.00      0.00         4\n",
      "          29       0.88      0.50      0.64        70\n",
      "          30       0.00      0.00      0.00        11\n",
      "          31       0.69      0.54      0.60        69\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     23485\n",
      "   macro avg       0.69      0.51      0.54     23485\n",
      "weighted avg       0.84      0.82      0.82     23485\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/justin/classification/app/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8232488822652757"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled, y_resampled = sa.SMOTE(originTrainFeatures,y_train)\n",
    "sa.MNBC(X_resampled,originTestFeatures,y_resampled,y_test,24000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Select Best 24000 features ----- \n",
      "\n",
      "----- SVC fitting -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88       114\n",
      "           1       0.71      0.76      0.73       277\n",
      "           2       0.97      0.98      0.97      2404\n",
      "           3       0.90      0.95      0.92      2047\n",
      "           4       0.86      0.89      0.88      1031\n",
      "           5       0.96      0.91      0.93      5988\n",
      "           6       0.80      0.89      0.84        36\n",
      "           7       0.34      0.42      0.38        50\n",
      "           8       0.71      0.74      0.72       573\n",
      "           9       0.68      0.73      0.71       362\n",
      "          10       0.79      0.71      0.75        38\n",
      "          11       0.62      0.77      0.69       239\n",
      "          12       0.96      0.95      0.95      4572\n",
      "          13       0.82      0.88      0.85       129\n",
      "          14       0.67      0.20      0.31        10\n",
      "          15       0.90      0.87      0.89      1567\n",
      "          16       0.87      0.92      0.89       190\n",
      "          17       0.65      0.72      0.68       123\n",
      "          18       0.80      0.93      0.86       193\n",
      "          19       0.71      0.72      0.72       669\n",
      "          20       0.31      0.53      0.39        30\n",
      "          21       0.80      0.78      0.79       282\n",
      "          22       0.94      0.93      0.94       814\n",
      "          23       0.80      0.86      0.83       207\n",
      "          24       0.68      0.67      0.67       222\n",
      "          25       0.79      0.77      0.78       999\n",
      "          26       0.60      0.59      0.60       152\n",
      "          27       0.46      0.46      0.46        13\n",
      "          28       1.00      1.00      1.00         4\n",
      "          29       0.75      0.71      0.73        70\n",
      "          30       0.13      0.36      0.20        11\n",
      "          31       0.66      0.78      0.72        69\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     23485\n",
      "   macro avg       0.73      0.76      0.74     23485\n",
      "weighted avg       0.90      0.89      0.89     23485\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/justin/classification/app/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8930806898020013"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa.SVC(originTrainFeatures,originTestFeatures,y_train,y_test,24000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Select Best 24000 features ----- \n",
      "\n",
      "----- SVC fitting -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       114\n",
      "           1       0.65      0.75      0.69       277\n",
      "           2       0.98      0.97      0.97      2404\n",
      "           3       0.92      0.87      0.90      2047\n",
      "           4       0.84      0.88      0.86      1031\n",
      "           5       0.95      0.89      0.92      5988\n",
      "           6       0.84      0.86      0.85        36\n",
      "           7       0.13      0.58      0.21        50\n",
      "           8       0.67      0.73      0.70       573\n",
      "           9       0.65      0.70      0.68       362\n",
      "          10       0.50      0.66      0.57        38\n",
      "          11       0.51      0.83      0.63       239\n",
      "          12       0.95      0.93      0.94      4572\n",
      "          13       0.80      0.86      0.83       129\n",
      "          14       0.50      0.30      0.37        10\n",
      "          15       0.87      0.86      0.87      1567\n",
      "          16       0.87      0.88      0.87       190\n",
      "          17       0.60      0.67      0.63       123\n",
      "          18       0.80      0.90      0.85       193\n",
      "          19       0.68      0.70      0.69       669\n",
      "          20       0.29      0.53      0.38        30\n",
      "          21       0.76      0.74      0.75       282\n",
      "          22       0.93      0.91      0.92       814\n",
      "          23       0.80      0.84      0.82       207\n",
      "          24       0.66      0.62      0.64       222\n",
      "          25       0.75      0.75      0.75       999\n",
      "          26       0.62      0.53      0.57       152\n",
      "          27       0.17      0.54      0.26        13\n",
      "          28       0.57      1.00      0.73         4\n",
      "          29       0.61      0.73      0.66        70\n",
      "          30       0.15      0.36      0.22        11\n",
      "          31       0.72      0.77      0.74        69\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     23485\n",
      "   macro avg       0.67      0.75      0.70     23485\n",
      "weighted avg       0.88      0.87      0.88     23485\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.870300191611667"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled, y_resampled = sa.ros(originTrainFeatures,y_train)\n",
    "sa.SVC(X_resampled,originTestFeatures,y_resampled,y_test,24000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Select Best 24000 features ----- \n",
      "\n",
      "----- SVC fitting -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87       114\n",
      "           1       0.71      0.75      0.73       277\n",
      "           2       0.97      0.97      0.97      2404\n",
      "           3       0.90      0.95      0.92      2047\n",
      "           4       0.86      0.89      0.88      1031\n",
      "           5       0.96      0.91      0.93      5988\n",
      "           6       0.80      0.89      0.84        36\n",
      "           7       0.36      0.42      0.39        50\n",
      "           8       0.71      0.73      0.72       573\n",
      "           9       0.68      0.73      0.71       362\n",
      "          10       0.79      0.71      0.75        38\n",
      "          11       0.63      0.76      0.69       239\n",
      "          12       0.96      0.95      0.95      4572\n",
      "          13       0.82      0.87      0.85       129\n",
      "          14       0.67      0.40      0.50        10\n",
      "          15       0.90      0.88      0.89      1567\n",
      "          16       0.87      0.92      0.89       190\n",
      "          17       0.65      0.71      0.68       123\n",
      "          18       0.80      0.93      0.86       193\n",
      "          19       0.71      0.73      0.72       669\n",
      "          20       0.30      0.53      0.39        30\n",
      "          21       0.80      0.78      0.79       282\n",
      "          22       0.94      0.93      0.94       814\n",
      "          23       0.82      0.86      0.84       207\n",
      "          24       0.69      0.66      0.67       222\n",
      "          25       0.79      0.78      0.78       999\n",
      "          26       0.62      0.58      0.60       152\n",
      "          27       0.46      0.46      0.46        13\n",
      "          28       1.00      1.00      1.00         4\n",
      "          29       0.77      0.71      0.74        70\n",
      "          30       0.14      0.36      0.20        11\n",
      "          31       0.68      0.77      0.72        69\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     23485\n",
      "   macro avg       0.74      0.76      0.75     23485\n",
      "weighted avg       0.90      0.89      0.89     23485\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/justin/classification/app/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8936342346178412"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled, y_resampled = sa.SMOTE(originTrainFeatures,y_train)\n",
    "sa.SVC(X_resampled,originTestFeatures,y_resampled,y_test,24000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
